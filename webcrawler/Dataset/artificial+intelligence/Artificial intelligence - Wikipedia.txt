 Title:Start  You have reached the cached page for  https://en.wikipedia.org/wiki/Artificial_intelligence  Title:End   Content:Start  Below is a snapshot of the Web page as it appeared on  2020-07-30  (the last time our crawler visited it). This is the version of the page that was used for ranking your search results. The page may have changed since we last cached it. To see what might have changed (without the highlights),  go to the current page .  Content:End   Hit:Start  You searched for:  HitHighlight:Start artificial   intelligence HitHighlight:End  We have highlighted matching words that appear in the page below.  Hit:End   Disclaimer:Start  Bing is not responsible for the content of this page.  Disclaimer:End   Banner:End  
 html 
 Artificial intelligence - Wikipedia 
 
 
 
 
  CentralNotice  
 
 
 
 Artificial   intelligence 
 
 From Wikipedia, the free encyclopedia 
 
 
 
 Jump to navigation 
 Jump to search 
 Intelligence  demonstrated by machines 
 "AI" redirects here. For other uses, see  AI (disambiguation)  and  Artificial   intelligence  (disambiguation) . 
 
 
 Part on a series on Artificial   intelligence 
 Major goals 
 Knowledge reasoning 
 Planning 
 Machine learning 
 Natural language processing 
 Computer vision 
 Robotics 
 Artificial  general  intelligence 
 
 Approaches 
 Symbolic 
 Deep learning 
 Bayesian networks 
 Evolutionary algorithms 
 
 Philosophy 
 Ethics 
 Existential risk 
 Turing test 
 Chinese room 
 Control problem 
 Friendly AI 
 
 History 
 Timeline 
 Progress 
 AI winter 
 
 Technology 
 Applications 
 Projects 
 Programming languages 
 
 Glossary 
 Glossary 
 v t e 
 Artificial   intelligence  ( AI ), sometimes called  machine  intelligence , is  intelligence  demonstrated by  machines , unlike the  natural  intelligence  displayed by  humans  and  animals . Leading AI textbooks define the field as the study of " intelligent agents ": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. [1]  Colloquially, the term " artificial   intelligence " is often used to describe machines (or computers) that mimic "cognitive" functions that humans associate with the  human mind , such as "learning" and "problem solving". [2] 
 As machines become increasingly capable, tasks considered to require " intelligence " are often removed from the definition of AI, a phenomenon known as the  AI effect . [3]  A quip in Tesler's Theorem says "AI is whatever hasn't been done yet." [4]  For instance,  optical character recognition  is frequently excluded from things considered to be AI, [5]  having become a routine technology. [6]  Modern machine capabilities generally classified as AI include successfully  understanding human speech , [7]  competing at the highest level in  strategic game  systems (such as  chess  and  Go ), [8]   autonomously operating cars , intelligent routing in  content delivery networks , and  military simulations . [9] 
 Artificial   intelligence  was founded as an academic discipline in 1955, and in the years since has experienced several waves of optimism, [10] [11]  followed by disappointment and the loss of funding (known as an " AI winter "), [12] [13]  followed by new approaches, success and renewed funding. [11] [14]  For most of its history, AI research has been divided into sub-fields that often fail to communicate with each other. [15]  These sub-fields are based on technical considerations, such as particular goals (e.g. " robotics " or " machine learning "), [16]  the use of particular tools (" logic " or  artificial  neural networks ), or deep philosophical differences. [17] [18] [19]  Sub-fields have also been based on social factors (particular institutions or the work of particular researchers). [15] 
 The traditional problems (or goals) of AI research include  reasoning ,  knowledge representation ,  planning ,  learning ,  natural language processing ,  perception  and the ability to move and manipulate objects. [16]   General  intelligence  is among the field's long-term goals. [20]  Approaches include  statistical methods ,  computational  intelligence , and  traditional symbolic AI . Many tools are used in AI, including versions of  search and mathematical optimization ,  artificial  neural networks , and  methods based on statistics, probability and economics . The AI field draws upon  computer science ,  information engineering ,  mathematics ,  psychology ,  linguistics ,  philosophy , and many other fields.
 The field was founded on the assumption that  human  intelligence  "can be so precisely described that a machine can be made to simulate it". [21]  This raises philosophical arguments about the mind and the ethics of creating  artificial  beings endowed with human-like  intelligence . These issues have been explored by  myth ,  fiction  and  philosophy  since  antiquity . [22]  Some people also consider AI to be  a danger to humanity  if it progresses unabated. [23] [24]  Others believe that AI, unlike previous technological revolutions, will create a  risk of mass unemployment . [25] 
 In the twenty-first century, AI techniques have experienced a resurgence following concurrent advances in  computer power , large amounts of  data , and theoretical understanding; and AI techniques have become an essential part of the  technology industry , helping to solve many challenging problems in computer science,  software engineering  and  operations research . [26] [14] 
 
 Contents 
 
 1   History 
 2   Definitions 
 3   Basics 
 4   Challenges 
 
 4.1   Reasoning, problem solving 
 4.2   Knowledge representation 
 4.3   Planning 
 4.4   Learning 
 4.5   Natural language processing 
 4.6   Perception 
 4.7   Motion and manipulation 
 4.8   Social  intelligence 
 4.9   General  intelligence 
 
 
 5   Approaches 
 
 5.1   Cybernetics and brain simulation 
 5.2   Symbolic 
 
 5.2.1   Cognitive simulation 
 5.2.2   Logic-based 
 5.2.3   Anti-logic or scruffy 
 5.2.4   Knowledge-based 
 
 
 5.3   Sub-symbolic 
 
 5.3.1   Embodied  intelligence 
 5.3.2   Computational  intelligence  and soft computing 
 
 
 5.4   Statistical learning 
 5.5   Integrating the approaches 
 
 
 6   Tools 
 
 6.1   Search and optimization 
 6.2   Logic 
 6.3   Probabilistic methods for uncertain reasoning 
 6.4   Classifiers and statistical learning methods 
 6.5   Artificial  neural networks 
 
 6.5.1   Deep feedforward neural networks 
 6.5.2   Deep recurrent neural networks 
 
 
 6.6   Evaluating progress 
 
 6.6.1   Hardware improvements 
 
 
 
 
 7   Applications 
 
 7.1   Healthcare 
 7.2   Automotive 
 7.3   Finance and economics 
 7.4   Cybersecurity 
 7.5   Government 
 7.6   Law-related professions 
 7.7   Video games 
 7.8   Military 
 7.9   Hospitality 
 7.10   Audit 
 7.11   Advertising 
 7.12   Art 
 
 
 8   Philosophy and ethics 
 
 8.1   The limits of  artificial  general  intelligence 
 8.2   Potential harm 
 
 8.2.1   Existential risk 
 8.2.2   Devaluation of humanity 
 8.2.3   Social justice 
 8.2.4   Decrease in demand for human labor 
 8.2.5   Autonomous weapons 
 
 
 8.3   Ethical machines 
 
 8.3.1   Artificial  moral agents 
 8.3.2   Machine ethics 
 8.3.3   Malevolent and friendly AI 
 
 
 8.4   Machine consciousness, sentience and mind 
 
 8.4.1   Consciousness 
 8.4.2   Computationalism and functionalism 
 8.4.3   Strong AI hypothesis 
 8.4.4   Robot rights 
 
 
 8.5   Superintelligence 
 
 8.5.1   Technological singularity 
 8.5.2   Transhumanism 
 
 
 
 
 9   Economics 
 10   Regulation 
 11   In fiction 
 12   See also 
 13   Explanatory notes 
 14   References 
 
 14.1   AI textbooks 
 14.2   History of AI 
 14.3   Other sources 
 
 
 15   Further reading 
 16   External links 
 
 
 
 History 
 Main articles:  History of  artificial   intelligence  and  Timeline of  artificial   intelligence 
   Silver  didrachma  from  Crete  depicting  Talos , an ancient mythical  automaton  with  artificial   intelligence 
 Thought-capable  artificial  beings  appeared as  storytelling devices  in antiquity, [27]  and have been common in fiction, as in  Mary Shelley 's  Frankenstein  or  Karel Čapek 's  R.U.R. (Rossum's Universal Robots) . [28]  These characters and their fates raised many of the same issues now discussed in the  ethics of  artificial   intelligence . [22] 
 The study of mechanical or  "formal" reasoning  began with  philosophers  and mathematicians in antiquity. The study of mathematical logic led directly to  Alan Turing 's  theory of computation , which suggested that a machine, by shuffling symbols as simple as "0" and "1", could simulate any conceivable act of mathematical deduction. This insight, that digital computers can simulate any process of formal reasoning, is known as the  Church–Turing thesis . [29]  Along with concurrent discoveries in  neurobiology ,  information theory  and  cybernetics , this led researchers to consider the possibility of building an electronic brain. Turing proposed changing the question from whether a machine was intelligent, to "whether or not it is possible for machinery to show intelligent behaviour". [30]  The first work that is now generally recognized as AI was  McCullouch  and  Pitts ' 1943 formal design for  Turing-complete  " artificial  neurons". [31] 
 The field of AI research was born at  a workshop  at  Dartmouth College  in 1956, [32]  where the term " Artificial   Intelligence " was coined by  John McCarthy  to distinguish the field from cybernetics and escape the influence of the cyberneticist  Norbert Wiener . [33]  Attendees  Allen Newell  ( CMU ),  Herbert Simon  (CMU), John McCarthy ( MIT ),  Marvin Minsky  (MIT) and  Arthur Samuel  ( IBM ) became the founders and leaders of AI research. [34]  They and their students produced programs that the press described as "astonishing": [35]  computers were learning  checkers  strategies (c. 1954) [36]  (and by 1959 were reportedly playing better than the average human), [37]  solving word problems in algebra, proving  logical theorems  ( Logic Theorist , first run c. 1956) and speaking English. [38]  By the middle of the 1960s, research in the U.S. was heavily funded by the  Department of Defense [39]  and laboratories had been established around the world. [40]  AI's founders were optimistic about the future:  Herbert Simon  predicted, "machines will be capable, within twenty years, of doing any work a man can do".  Marvin Minsky  agreed, writing, "within a generation ... the problem of creating ' artificial   intelligence ' will substantially be solved". [10] 
 They failed to recognize the difficulty of some of the remaining tasks. Progress slowed and in 1974, in response to the criticism of  Sir James Lighthill [41]  and ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI. The next few years would later be called an " AI winter ", [12]  a period when obtaining funding for AI projects was difficult.
 In the early 1980s, AI research was revived by the commercial success of  expert systems , [42]  a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's  fifth generation computer  project inspired the U.S and British governments to restore funding for  academic research . [11]  However, beginning with the collapse of the  Lisp Machine  market in 1987, AI once again fell into disrepute, and a second, longer-lasting hiatus began. [13] 
 The development of  metal–oxide–semiconductor  (MOS)  very-large-scale integration  (VLSI), in the form of  complementary MOS  (CMOS)  transistor  technology, enabled the development of practical  artificial  neural network  (ANN) technology in the 1980s. A landmark publication in the field was the 1989 book  Analog VLSI Implementation of Neural Systems  by Carver A. Mead and Mohammed Ismail. [43] 
 In the late 1990s and early 21st century, AI began to be used for logistics,  data mining ,  medical diagnosis  and other areas. [26]  The success was due to increasing computational power (see  Moore's law  and  transistor count ), greater emphasis on solving specific problems, new ties between AI and other fields (such as  statistics ,  economics  and  mathematics ), and a commitment by researchers to mathematical methods and scientific standards. [44]   Deep Blue  became the first computer chess-playing system to beat a reigning world chess champion,  Garry Kasparov , on 11 May 1997. [45] 
 In 2011, a  Jeopardy!   quiz show  exhibition match,  IBM 's  question answering system ,  Watson , defeated the two greatest  Jeopardy!  champions,  Brad Rutter  and  Ken Jennings , by a significant margin. [46]   Faster computers , algorithmic improvements, and access to  large amounts of data  enabled advances in  machine learning  and perception; data-hungry  deep learning  methods started to dominate accuracy benchmarks  around 2012 . [47]  The  Kinect , which provides a 3D body–motion interface for the  Xbox 360  and the  Xbox One , uses algorithms that emerged from lengthy AI research [48]  as do  intelligent personal assistants  in  smartphones . [49]  In March 2016,  AlphaGo  won 4 out of 5 games of  Go  in a match with Go champion  Lee Sedol , becoming the first  computer Go-playing system  to beat a professional Go player without  handicaps . [8] [50]  In the 2017  Future of Go Summit ,  AlphaGo  won a  three-game match  with  Ke Jie , [51]  who at the time continuously held the world No. 1 ranking for two years. [52] [53]  This marked the completion of a significant milestone in the development of  Artificial   Intelligence  as Go is a relatively complex game, more so than Chess.
 According to  Bloomberg's  Jack Clark, 2015 was a landmark year for  artificial   intelligence , with the number of software projects that use AI  Google  increased from a "sporadic usage" in 2012 to more than 2,700 projects. Clark also presents factual data indicating the improvements of AI since 2012 supported by lower error rates in image processing tasks. [54]  He attributes this to an increase in affordable  neural networks , due to a rise in cloud computing infrastructure and to an increase in research tools and datasets. [14]  Other cited examples include Microsoft's development of a Skype system that can automatically translate from one language to another and Facebook's system that can describe images to blind people. [54]  In a 2017 survey, one in five companies reported they had "incorporated AI in some offerings or processes". [55] [56]  Around 2016,  China  greatly accelerated its government funding; given its large supply of data and its rapidly increasing research output, some observers believe it may be on track to becoming an "AI superpower". [57] [58]  However, it has been acknowledged that reports regarding  artificial   intelligence  have tended to be exaggerated. [59] [60] [61] 
 
 Definitions 
 Computer science defines AI research as the study of " intelligent agents ": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. [1]  A more elaborate definition characterizes AI as "a system's ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation." [62] 
 
 Basics 
 A typical AI analyzes its environment and takes actions that maximize its chance of success. [1]  An AI's intended  utility function (or goal)  can be simple ("1 if the AI wins a game of  Go , 0 otherwise") or complex ("Perform actions mathematically similar to ones that succeeded in the past"). Goals can be explicitly defined or induced. If the AI is programmed for " reinforcement learning ", goals can be implicitly induced by rewarding some types of behavior or punishing others. [a]  Alternatively, an evolutionary system can induce goals by using a " fitness function " to mutate and preferentially replicate high-scoring AI systems, similar to how animals evolved to innately desire certain goals such as finding food. [63]  Some AI systems, such as nearest-neighbor, instead of reason by analogy, these systems are not generally given goals, except to the degree that goals are implicit in their training data. [64]  Such systems can still be benchmarked if the non-goal system is framed as a system whose "goal" is to successfully accomplish its narrow classification task. [65] 
 AI often revolves around the use of  algorithms . An algorithm is a set of unambiguous instructions that a mechanical computer can execute. [b]  A complex algorithm is often built on top of other, simpler, algorithms. A simple example of an algorithm is the following (optimal for first player) recipe for play at  tic-tac-toe : [66] 
 
 If someone has a "threat" (that is, two in a row), take the remaining square. Otherwise, 
 if a move "forks" to create two threats at once, play that move. Otherwise, 
 take the center square if it is free. Otherwise, 
 if your opponent has played in a corner, take the opposite corner. Otherwise, 
 take an empty corner if one exists. Otherwise, 
 take any empty square. 
 Many AI algorithms are capable of learning from data; they can enhance themselves by learning new  heuristics  (strategies, or "rules of thumb", that have worked well in the past), or can themselves write other algorithms. Some of the "learners" described below, including Bayesian networks, decision trees, and nearest-neighbor, could theoretically, (given infinite data, time, and memory) learn to approximate any  function , including which combination of mathematical functions would best describe the world [ citation needed ] . These learners could therefore derive all possible knowledge, by considering every possible hypothesis and matching them against the data. In practice, it is seldom possible to consider every possibility, because of the phenomenon of " combinatorial explosion ", where the time needed to solve a problem grows exponentially. Much of AI research involves figuring out how to identify and avoid considering a broad range of possibilities unlikely to be beneficial. [67] [68]  For example, when viewing a map and looking for the shortest driving route from  Denver  to  New York  in the East, one can in most cases skip looking at any path through  San Francisco  or other areas far to the West; thus, an AI wielding a pathfinding algorithm like  A*  can avoid the combinatorial explosion that would ensue if every possible route had to be ponderously considered. [69] 
 The earliest (and easiest to understand) approach to AI was symbolism (such as formal logic): "If an otherwise healthy adult has a fever, then they may have  influenza ". A second, more general, approach is  Bayesian inference : "If the current patient has a fever, adjust the probability they have influenza in such-and-such way". The third major approach, extremely popular in routine business AI applications, are analogizers such as  SVM  and  nearest-neighbor : "After examining the records of known past patients whose temperature, symptoms, age, and other factors mostly match the current patient, X% of those patients turned out to have influenza". A fourth approach is harder to intuitively understand, but is inspired by how the brain's machinery works: the  artificial  neural network  approach uses  artificial  " neurons " that can learn by comparing itself to the desired output and altering the strengths of the connections between its internal neurons to "reinforce" connections that seemed to be useful. These four main approaches can overlap with each other and with evolutionary systems; for example, neural nets can learn to make inferences, to generalize, and to make analogies. Some systems implicitly or explicitly use multiple of these approaches, alongside many other AI and non-AI algorithms; the best approach is often different depending on the problem. [70] [71] 
 Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can be obvious, such as "since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well". They can be nuanced, such as "X% of  families  have geographically separate species with color variants, so there is a Y% chance that undiscovered  black swans  exist". Learners also work on the basis of " Occam's razor ": The simplest theory that explains the data is the likeliest. Therefore, according to Occam's razor principle, a learner must be designed such that it prefers simpler theories to complex theories, except in cases where the complex theory is proven substantially better.
 
   The blue line could be an example of  overfitting  a linear function due to random noise. 
 Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as  overfitting . Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data, but penalizing the theory in accordance with how complex the theory is. [72]  Besides classic overfitting, learners can also disappoint by "learning the wrong lesson". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses. [73]  A real-world example is that, unlike humans, current image classifiers don't determine the spatial relationship between components of the picture; instead, they learn abstract patterns of pixels that humans are oblivious to, but that linearly correlate with images of certain types of real objects. Faintly superimposing such a pattern on a legitimate image results in an "adversarial" image that the system misclassifies. [c] [74] [75] [76] 
 
   A self-driving car system may use a neural network to determine which parts of the picture seem to match previous training images of pedestrians, and then model those areas as slow-moving but somewhat unpredictable rectangular prisms that must be avoided. [77] [78] 
 Compared with humans, existing AI lacks several features of human " commonsense reasoning "; most notably, humans have powerful mechanisms for reasoning about " naïve physics " such as space, time, and physical interactions. This enables even young children to easily make inferences like "If I roll this pen off a table, it will fall on the floor". Humans also have a powerful mechanism of " folk psychology " that helps them to interpret natural-language sentences such as "The city councilmen refused the demonstrators a permit because they advocated violence". (A generic AI has difficulty discerning whether the ones alleged to be advocating violence are the councilmen or the demonstrators.) [79] [80] [81]  This lack of "common knowledge" means that AI often makes different mistakes than humans make, in ways that can seem incomprehensible. For example, existing self-driving cars cannot reason about the location nor the intentions of pedestrians in the exact way that humans do, and instead must use non-human modes of reasoning to avoid accidents. [82] [83] [84] 
 
 Challenges 
 The cognitive capabilities of current architectures are very limited, using only a simplified version of what  intelligence  is really capable of. For instance, the human mind has come up with ways to reason beyond measure and logical explanations to different occurrences in life. What would have been otherwise straightforward, an equivalently difficult problem may be challenging to solve computationally as opposed to using the human mind. This gives rise to two classes of models: structuralist and functionalist. The structural models aim to loosely mimic the basic  intelligence  operations of the mind such as reasoning and logic. The functional model refers to the correlating data to its computed counterpart. [85] 
 The overall research goal of  artificial   intelligence  is to create technology that allows computers and machines to function in an intelligent manner. The general problem of simulating (or creating)  intelligence  has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention. [16] 
 
 Reasoning, problem solving 
 Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. [86]  By the late 1980s and 1990s, AI research had developed methods for dealing with  uncertain  or incomplete information, employing concepts from  probability  and  economics . [87] 
 These algorithms proved to be insufficient for solving large reasoning problems because they experienced a "combinatorial explosion": they became exponentially slower as the problems grew larger. [67]  Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. [88] 
 
 Knowledge representation 
   An ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts. 
 Main articles:  Knowledge representation  and  Commonsense knowledge 
 Knowledge representation [89]  and  knowledge engineering [90]  are central to classical AI research. Some "expert systems" attempt to gather explicit knowledge possessed by experts in some narrow domain. In addition, some projects attempt to gather the "commonsense knowledge" known to the average person into a database containing extensive knowledge about the world. Among the things a comprehensive commonsense knowledge base would contain are: objects, properties, categories and relations between objects; [91]  situations, events, states and time; [92]  causes and effects; [93]  knowledge about knowledge (what we know about what other people know); [94]  and many other, less well researched domains. A representation of "what exists" is an  ontology : the set of objects, relations, concepts, and properties formally described so that software agents can interpret them. The  semantics  of these are captured as  description logic  concepts, roles, and individuals, and typically implemented as classes, properties, and individuals in the  Web Ontology Language . [95]  The most general ontologies are called  upper ontologies , which attempt to provide a foundation for all other knowledge [96]  by acting as mediators between  domain ontologies  that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). Such formal knowledge representations can be used in content-based indexing and retrieval, [97]  scene interpretation, [98]  clinical decision support, [99]  knowledge discovery (mining "interesting" and actionable inferences from large databases), [100]  and other areas. [101] 
 Among the most difficult problems in knowledge representation are:
 
 Default reasoning  and the  qualification problem 
 Many of the things people know take the form of "working assumptions". For example, if a bird comes up in conversation, people typically picture a fist-sized animal that sings and flies. None of these things are true about all birds.  John McCarthy  identified this problem in 1969 [102]  as the qualification problem: for any commonsense rule that AI researchers care to represent, there tend to be a huge number of exceptions. Almost nothing is simply true or false in the way that abstract logic requires. AI research has explored a number of solutions to this problem. [103] 
 Breadth of commonsense knowledge 
 The number of atomic facts that the average person knows is very large. Research projects that attempt to build a complete knowledge base of  commonsense knowledge  (e.g.,  Cyc ) require enormous amounts of laborious  ontological engineering —they must be built, by hand, one complicated concept at a time. [104] 
 Subsymbolic form of some commonsense knowledge 
 Much of what people know is not represented as "facts" or "statements" that they could express verbally. For example, a chess master will avoid a particular chess position because it "feels too exposed" [105]  or an art critic can take one look at a statue and realize that it is a fake. [106]  These are non-conscious and sub-symbolic intuitions or tendencies in the human brain. [107]  Knowledge like this informs, supports and provides a context for symbolic, conscious knowledge. As with the related problem of sub-symbolic reasoning, it is hoped that  situated AI ,  computational  intelligence , or  statistical AI  will provide ways to represent this knowledge. [107] 
 Planning 
   A  hierarchical control system  is a form of  control system  in which a set of devices and governing software is arranged in a hierarchy. 
 Main article:  Automated planning and scheduling 
 Intelligent agents must be able to set goals and achieve them. [108]  They need a way to visualize the future—a representation of the state of the world and be able to make predictions about how their actions will change it—and be able to make choices that maximize the  utility  (or "value") of available choices. [109] 
 In classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions. [110]  However, if the agent is not the only actor, then it requires that the agent can reason under uncertainty. This calls for an agent that can not only assess its environment and make predictions but also evaluate its predictions and adapt based on its assessment. [111] 
 Multi-agent planning  uses the  cooperation  and competition of many agents to achieve a given goal.  Emergent behavior  such as this is used by  evolutionary algorithms  and  swarm  intelligence . [112] 
 
 Learning 
 Main article:  Machine learning 
 Machine learning (ML), a fundamental concept of AI research since the field's inception, [113]  is the study of computer algorithms that improve automatically through experience. [114] [115] 
 Unsupervised learning  is the ability to find patterns in a stream of input, without requiring a human to label the inputs first.  Supervised learning  includes both  classification  and numerical  regression , which requires a human to label the input data first. Classification is used to determine what category something belongs in, and occurs after a program sees a number of examples of things from several categories. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change. [115]  Both classifiers and regression learners can be viewed as "function approximators" trying to learn an unknown (possibly implicit) function; for example, a spam classifier can be viewed as learning a function that maps from the text of an email to one of two categories, "spam" or "not spam".  Computational learning theory  can assess learners by  computational complexity , by  sample complexity  (how much data is required), or by other notions of  optimization . [116]  In  reinforcement learning [117]  the agent is rewarded for good responses and punished for bad ones. The agent uses this sequence of rewards and punishments to form a strategy for operating in its problem space.
 
 Natural language processing 
   A  parse tree  represents the  syntactic  structure of a sentence according to some  formal grammar . 
 Main article:  Natural language processing 
 Natural language processing [118]  (NLP) allows machines to read and  understand  human language. A sufficiently powerful natural language processing system would enable  natural-language user interfaces  and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of natural language processing include  information retrieval ,  text mining ,  question answering [119]  and  machine translation . [120]  Many current approaches use word co-occurrence frequencies to construct syntactic representations of text. "Keyword spotting" strategies for search are popular and scalable but dumb; a search query for "dog" might only match documents with the literal word "dog" and miss a document with the word "poodle". "Lexical affinity" strategies use the occurrence of words such as "accident" to  assess the sentiment  of a document. Modern statistical NLP approaches can combine all these strategies as well as others, and often achieve acceptable accuracy at the page or paragraph level. Beyond semantic NLP, the ultimate goal of "narrative" NLP is to embody a full understanding of commonsense reasoning. [121]  By 2019,  transformer -based deep learning architectures could generate coherent text. [122] 
 
 Perception 
 Main articles:  Machine perception ,  Computer vision , and  Speech recognition 
   Feature detection  (pictured:  edge detection ) helps AI compose informative abstract structures out of raw data. 
 Machine perception [123]  is the ability to use input from sensors (such as cameras (visible spectrum or infrared), microphones, wireless signals, and active  lidar , sonar, radar, and  tactile sensors ) to deduce aspects of the world. Applications include  speech recognition , [124]   facial recognition , and  object recognition . [125]   Computer vision  is the ability to analyze visual input. Such input is usually ambiguous; a giant, fifty-meter-tall pedestrian far away may produce the same pixels as a nearby normal-sized pedestrian, requiring the AI to judge the relative likelihood and reasonableness of different interpretations, for example by using its "object model" to assess that fifty-meter pedestrians do not exist. [126] 
 
 Motion and manipulation 
 Main article:  Robotics 
 AI is heavily used in  robotics . [127]  Advanced  robotic arms  and other  industrial robots , widely used in modern factories, can learn from experience how to move efficiently despite the presence of friction and gear slippage. [128]  A modern mobile robot, when given a small, static, and visible environment, can easily determine its location and  map  its environment; however, dynamic environments, such as (in  endoscopy ) the interior of a patient's breathing body, pose a greater challenge.  Motion planning  is the process of breaking down a movement task into "primitives" such as individual joint movements. Such movement often involves compliant motion, a process where movement requires maintaining physical contact with an object. [129] [130] [131]   Moravec's paradox  generalizes that low-level sensorimotor skills that humans take for granted are, counterintuitively, difficult to program into a robot; the paradox is named after  Hans Moravec , who stated in 1988 that "it is comparatively easy to make computers exhibit adult level performance on  intelligence  tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility". [132] [133]  This is attributed to the fact that, unlike checkers, physical dexterity has been a direct target of  natural selection  for millions of years. [134] 
 
 Social  intelligence 
 Main article:  Affective computing 
   Kismet , a robot with rudimentary social skills [135] 
 Moravec's paradox can be extended to many forms of social  intelligence . [136] [137]  Distributed multi-agent coordination of autonomous vehicles remains a difficult problem. [138]   Affective computing  is an interdisciplinary umbrella that comprises systems which recognize, interpret, process, or simulate human  affects . [139] [140] [141]  Moderate successes related to affective computing include textual  sentiment analysis  and, more recently, multimodal affect analysis (see  multimodal sentiment analysis ), wherein AI classifies the affects displayed by a videotaped subject. [142] 
 In the long run, social skills and an understanding of human emotion and  game theory  would be valuable to a social agent. The ability to predict the actions of others by understanding their motives and emotional states would allow an agent to make better decisions. Some computer systems mimic human emotion and expressions to appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate  human–computer interaction . [143]  Similarly, some  virtual assistants  are programmed to speak conversationally or even to banter humorously; this tends to give naïve users an unrealistic conception of how intelligent existing computer agents actually are. [144] 
 
 General  intelligence 
 Main articles:  Artificial  general  intelligence  and  AI-complete 
 Historically, projects such as the Cyc knowledge base (1984–) and the massive Japanese  Fifth Generation Computer Systems  initiative (1982–1992) attempted to cover the breadth of human cognition. These early projects failed to escape the limitations of non-quantitative symbolic logic models and, in retrospect, greatly underestimated the difficulty of cross-domain AI. Nowadays, most current AI researchers work instead on tractable "narrow AI" applications (such as medical diagnosis or automobile navigation). [145]  Many researchers predict that such "narrow AI" work in different individual domains will eventually be incorporated into a machine with  artificial  general  intelligence  (AGI), combining most of the narrow skills mentioned in this article and at some point even exceeding human ability in most or all these areas. [20] [146]  Many advances have general, cross-domain significance. One high-profile example is that  DeepMind  in the 2010s developed a "generalized  artificial   intelligence " that could learn many diverse  Atari  games on its own, and later developed a variant of the system which succeeds at  sequential learning . [147] [148] [149]  Besides  transfer learning , [150]  hypothetical AGI breakthroughs could include the development of reflective architectures that can engage in decision-theoretic metareasoning, and figuring out how to "slurp up" a comprehensive knowledge base from the entire unstructured  Web . [7]  Some argue that some kind of (currently-undiscovered) conceptually straightforward, but mathematically difficult, "Master Algorithm" could lead to AGI. [151]  Finally, a few "emergent" approaches look to simulating human  intelligence  extremely closely, and believe that  anthropomorphic  features like an  artificial  brain  or simulated  child development  may someday reach a critical point where general  intelligence  emerges. [152] [153] 
 Many of the problems in this article may also require general  intelligence , if machines are to solve the problems as well as people do. For example, even specific straightforward tasks, like  machine translation , require that a machine read and write in both languages ( NLP ), follow the author's argument ( reason ), know what is being talked about ( knowledge ), and faithfully reproduce the author's original intent ( social  intelligence ). A problem like machine translation is considered " AI-complete ", because all of these problems need to be solved simultaneously in order to reach human-level machine performance.
 
 Approaches 
 No established unifying theory or  paradigm  guides AI research. Researchers disagree about many issues. [154]  A few of the most long standing questions that have remained unanswered are these: should  artificial   intelligence  simulate natural  intelligence  by studying  psychology  or  neurobiology ? Or is  human biology  as irrelevant to AI research as bird biology is to  aeronautical engineering ? [17] 
Can intelligent behavior be described using simple, elegant principles (such as  logic  or  optimization )? Or does it necessarily require solving a large number of unrelated problems? [18] 
 
 Cybernetics and brain simulation 
 Main articles:  Cybernetics  and  Computational neuroscience 
 In the 1940s and 1950s, a number of researchers explored the connection between  neurobiology ,  information theory , and  cybernetics . Some of them built machines that used electronic networks to exhibit rudimentary  intelligence , such as  W. Grey Walter 's  turtles  and the  Johns Hopkins Beast . Many of these researchers gathered for meetings of the Teleological Society at  Princeton University  and the  Ratio Club  in England. [155]  By 1960, this approach was largely abandoned, although elements of it would be revived in the 1980s.
 
 Symbolic 
 Main article:  Symbolic AI 
 When access to digital computers became possible in the mid-1950s, AI research began to explore the possibility that human  intelligence  could be reduced to symbol manipulation. The research was centered in three institutions:  Carnegie Mellon University ,  Stanford  and  MIT , and as described below, each one developed its own style of research.  John Haugeland  named these symbolic approaches to AI "good old fashioned AI" or " GOFAI ". [156]  During the 1960s, symbolic approaches had achieved great success at simulating high-level "thinking" in small demonstration programs. Approaches based on  cybernetics  or  artificial  neural networks  were abandoned or pushed into the background. [157] 
Researchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with  artificial  general  intelligence  and considered this the goal of their field.
 
 Cognitive simulation 
 Economist  Herbert Simon  and  Allen Newell  studied human problem-solving skills and attempted to formalize them, and their work laid the foundations of the field of  artificial   intelligence , as well as  cognitive science ,  operations research  and  management science . Their research team used the results of  psychological  experiments to develop programs that simulated the techniques that people used to solve problems. This tradition, centered at  Carnegie Mellon University  would eventually culminate in the development of the  Soar  architecture in the middle 1980s. [158] [159] 
 
 Logic-based 
 Unlike Simon and Newell,  John McCarthy  felt that machines did not need to simulate human thought, but should instead try to find the essence of abstract reasoning and problem-solving, regardless whether people used the same algorithms. [17]  His laboratory at  Stanford  ( SAIL ) focused on using formal  logic  to solve a wide variety of problems, including  knowledge representation ,  planning  and  learning . [160]  Logic was also the focus of the work at the  University of Edinburgh  and elsewhere in Europe which led to the development of the programming language  Prolog  and the science of  logic programming . [161] 
 
 Anti-logic or scruffy 
 Researchers at  MIT  (such as  Marvin Minsky  and  Seymour Papert ) [162]  found that solving difficult problems in  vision  and  natural language processing  required ad hoc solutions—they argued that no simple and general principle (like  logic ) would capture all the aspects of intelligent behavior.  Roger Schank  described their "anti-logic" approaches as " scruffy " (as opposed to the " neat " paradigms at  CMU  and Stanford). [18]   Commonsense knowledge bases  (such as  Doug Lenat 's  Cyc ) are an example of "scruffy" AI, since they must be built by hand, one complicated concept at a time. [163] 
 
 Knowledge-based 
 When computers with large memories became available around 1970, researchers from all three traditions began to build  knowledge  into AI applications. [164]  This "knowledge revolution" led to the development and deployment of  expert systems  (introduced by  Edward Feigenbaum ), the first truly successful form of AI software. [42]  A key component of the system architecture for all expert systems is the knowledge base, which stores facts and rules that illustrate AI. [165]  The knowledge revolution was also driven by the realization that enormous amounts of knowledge would be required by many simple AI applications.
 
 Sub-symbolic 
 By the 1980s, progress in symbolic AI seemed to stall and many believed that symbolic systems would never be able to imitate all the processes of human cognition, especially  perception ,  robotics ,  learning  and  pattern recognition . A number of researchers began to look into "sub-symbolic" approaches to specific AI problems. [19]  Sub-symbolic methods manage to approach  intelligence  without specific representations of knowledge.
 
 Embodied  intelligence 
 This includes  embodied ,  situated ,  behavior-based , and  nouvelle AI . Researchers from the related field of  robotics , such as  Rodney Brooks , rejected symbolic AI and focused on the basic engineering problems that would allow robots to move and survive. [166]  Their work revived the non-symbolic point of view of the early  cybernetics  researchers of the 1950s and reintroduced the use of  control theory  in AI. This coincided with the development of the  embodied mind thesis  in the related field of  cognitive science : the idea that aspects of the body (such as movement, perception and visualization) are required for higher  intelligence .
 Within  developmental robotics , developmental learning approaches are elaborated upon to allow robots to accumulate repertoires of novel skills through autonomous self-exploration, social interaction with human teachers, and the use of guidance mechanisms (active learning, maturation, motor synergies, etc.). [167] [168] [169] [170] 
 
 Computational  intelligence  and soft computing 
 Interest in  neural networks  and " connectionism " was revived by  David Rumelhart  and others in the middle of the 1980s. [171]   Artificial  neural networks  are an example of  soft computing —they are solutions to problems which cannot be solved with complete logical certainty, and where an approximate solution is often sufficient. Other  soft computing  approaches to AI include  fuzzy systems ,  Grey system theory ,  evolutionary computation  and many statistical tools. The application of soft computing to AI is studied collectively by the emerging discipline of  computational  intelligence . [172] 
 
 Statistical learning 
 Much of traditional  GOFAI  got bogged down on  ad hoc  patches to  symbolic computation  that worked on their own toy models but failed to generalize to real-world results. However, around the 1990s, AI researchers adopted sophisticated mathematical tools, such as  hidden Markov models  (HMM),  information theory , and normative Bayesian  decision theory  to compare or to unify competing architectures. The shared mathematical language permitted a high level of collaboration with more established fields (like  mathematics , economics or  operations research ). [d]  Compared with GOFAI, new "statistical learning" techniques such as HMM and neural networks were gaining higher levels of accuracy in many practical domains such as  data mining , without necessarily acquiring a semantic understanding of the datasets. The increased successes with real-world data led to increasing emphasis on comparing different approaches against shared test data to see which approach performed best in a broader context than that provided by idiosyncratic toy models; AI research was becoming more  scientific . Nowadays results of experiments are often rigorously measurable, and are sometimes (with difficulty) reproducible. [44] [173]  Different statistical learning techniques have different limitations; for example, basic HMM cannot model the infinite possible combinations of natural language. [174]  Critics note that the shift from GOFAI to statistical learning is often also a shift away from  explainable AI . In AGI research, some scholars caution against over-reliance on statistical learning, and argue that continuing research into GOFAI will still be necessary to attain general  intelligence . [175] [176] 
 
 Integrating the approaches 
 Intelligent agent paradigm 
 An  intelligent agent  is a system that perceives its environment and takes actions that maximize its chances of success. The simplest intelligent agents are programs that solve specific problems. More complicated agents include human beings and organizations of human beings (such as  firms ). The paradigm allows researchers to directly compare or even combine different approaches to isolated problems, by asking which agent is best at maximizing a given "goal function". An agent that solves a specific problem can use any approach that works—some agents are symbolic and logical, some are sub-symbolic  artificial  neural networks  and others may use new approaches. The paradigm also gives researchers a common language to communicate with other fields—such as  decision theory  and economics—that also use concepts of abstract agents. Building a complete agent requires researchers to address realistic problems of integration; for example, because sensory systems give uncertain information about the environment, planning systems must be able to function in the presence of uncertainty. The intelligent agent paradigm became widely accepted during the 1990s. [177] 
 Agent architectures  and  cognitive architectures 
 Researchers have designed systems to build intelligent systems out of interacting  intelligent agents  in a  multi-agent system . [178]  A  hierarchical control system  provides a bridge between sub-symbolic AI at its lowest, reactive levels and traditional symbolic AI at its highest levels, where relaxed time constraints permit planning and world modeling. [179]  Some cognitive architectures are custom-built to solve a narrow problem; others, such as  Soar , are designed to mimic human cognition and to provide insight into general  intelligence . Modern extensions of Soar are  hybrid intelligent systems  that include both symbolic and sub-symbolic components. [180] [181] [182] 
 Tools 
 AI has developed many tools to solve the most difficult problems in  computer science . A few of the most general of these methods are discussed below.
 
 Search and optimization 
 Main articles:  Search algorithm ,  Mathematical optimization , and  Evolutionary computation 
 Many problems in AI can be solved theoretically by intelligently searching through many possible solutions: [183]   Reasoning  can be reduced to performing a search. For example, logical proof can be viewed as searching for a path that leads from  premises  to  conclusions , where each step is the application of an  inference rule . [184]   Planning  algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called  means-ends analysis . [185]   Robotics  algorithms for moving limbs and grasping objects use  local searches  in  configuration space . [128]  Many  learning  algorithms use search algorithms based on  optimization .
 Simple exhaustive searches [186]  are rarely sufficient for most real-world problems: the  search space  (the number of places to search) quickly grows to  astronomical numbers . The result is a search that is  too slow  or never completes. The solution, for many problems, is to use " heuristics " or "rules of thumb" that prioritize choices in favor of those more likely to reach a goal and to do so in a shorter number of steps. In some search methodologies heuristics can also serve to entirely eliminate some choices unlikely to lead to a goal (called " pruning  the  search tree ").  Heuristics  supply the program with a "best guess" for the path on which the solution lies. [187]  Heuristics limit the search for solutions into a smaller sample size. [129] 
 A very different kind of search came to prominence in the 1990s, based on the mathematical theory of  optimization . For many problems, it is possible to begin the search with some form of a guess and then refine the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind  hill climbing : we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. Other optimization algorithms are  simulated annealing ,  beam search  and  random optimization . [188] 
 
   A  particle swarm  seeking the  global minimum 
 Evolutionary computation  uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine,  selecting  only the fittest to survive each generation (refining the guesses). Classic  evolutionary algorithms  include  genetic algorithms ,  gene expression programming , and  genetic programming . [189]  Alternatively, distributed search processes can coordinate via  swarm  intelligence  algorithms. Two popular swarm algorithms used in search are  particle swarm optimization  (inspired by bird  flocking ) and  ant colony optimization  (inspired by  ant trails ). [190] [191] 
 
 Logic 
 Main articles:  Logic programming  and  Automated reasoning 
 Logic [192]  is used for knowledge representation and problem solving, but it can be applied to other problems as well. For example, the  satplan  algorithm uses logic for  planning [193]  and  inductive logic programming  is a method for  learning . [194] 
 Several different forms of logic are used in AI research.  Propositional logic [195]  involves  truth functions  such as "or" and "not".  First-order logic [196]  adds  quantifiers  and  predicates , and can express facts about objects, their properties, and their relations with each other.  Fuzzy set theory  assigns a "degree of truth" (between 0 and 1) to vague statements such as "Alice is old" (or rich, or tall, or hungry) that are too linguistically imprecise to be completely true or false.  Fuzzy logic  is successfully used in  control systems  to allow experts to contribute vague rules such as "if you are close to the destination station and moving fast, increase the train's brake pressure"; these vague rules can then be numerically refined within the system. Fuzzy logic fails to scale well in knowledge bases; many AI researchers question the validity of chaining fuzzy-logic inferences. [e] [198] [199] 
 Default logics ,  non-monotonic logics  and  circumscription [103]  are forms of logic designed to help with default reasoning and the  qualification problem . Several extensions of logic have been designed to handle specific domains of  knowledge , such as:  description logics ; [91]   situation calculus ,  event calculus  and  fluent calculus  (for representing events and time); [92]   causal calculus ; [93]   belief calculus (belief revision) ; [200]  and  modal logics . [94]  Logics to model contradictory or inconsistent statements arising in multi-agent systems have also been designed, such as  paraconsistent logics .
 
 Probabilistic methods for uncertain reasoning 
 Main articles:  Bayesian network ,  Hidden Markov model ,  Kalman filter ,  Particle filter ,  Decision theory , and  Utility theory 
   Expectation-maximization  clustering of  Old Faithful  eruption data starts from a random guess but then successfully converges on an accurate clustering of the two physically distinct modes of eruption. 
 Many problems in AI (in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of powerful tools to solve these problems using methods from  probability  theory and economics. [201] 
 Bayesian networks [202]  are a very general tool that can be used for various problems: reasoning (using the  Bayesian inference  algorithm), [203]   learning  (using the  expectation-maximization algorithm ), [f] [205]   planning  (using  decision networks ) [206]  and  perception  (using  dynamic Bayesian networks ). [207]  Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping  perception  systems to analyze processes that occur over time (e.g.,  hidden Markov models  or  Kalman filters ). [207]  Compared with symbolic logic, formal Bayesian inference is computationally expensive. For inference to be tractable, most observations must be  conditionally independent  of one another. Complicated graphs with diamonds or other "loops" (undirected  cycles ) can require a sophisticated method such as  Markov chain Monte Carlo , which spreads an ensemble of  random walkers  throughout the Bayesian network and attempts to converge to an assessment of the conditional probabilities. Bayesian networks are used on  Xbox Live  to rate and match players; wins and losses are "evidence" of how good a player is [ citation needed ] .  AdSense  uses a Bayesian network with over 300 million edges to learn which ads to serve. [208] 
 A key concept from the science of economics is " utility ": a measure of how valuable something is to an intelligent agent. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using  decision theory ,  decision analysis , [209]  and  information value theory . [109]  These tools include models such as  Markov decision processes , [210]  dynamic  decision networks , [207]   game theory  and  mechanism design . [211] 
 
 Classifiers and statistical learning methods 
 Main articles:  Classifier (mathematics) ,  Statistical classification , and  Machine learning 
 The simplest AI applications can be divided into two types: classifiers ("if shiny then diamond") and controllers ("if shiny then pick up"). Controllers do, however, also classify conditions before inferring actions, and therefore classification forms a central part of many AI systems.  Classifiers  are functions that use  pattern matching  to determine a closest match. They can be tuned according to examples, making them very attractive for use in AI. These examples are known as observations or patterns. In supervised learning, each pattern belongs to a certain predefined class. A class is a decision that has to be made. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience. [212] 
 A classifier can be trained in various ways; there are many statistical and  machine learning  approaches. The  decision tree [213]  is perhaps the most widely used machine learning algorithm. [214]  Other widely used classifiers are the  neural network , [215] 
 k-nearest neighbor algorithm , [g] [217] 
 kernel methods  such as the  support vector machine  (SVM), [h] [219] 
 Gaussian mixture model , [220]  and the extremely popular  naive Bayes classifier . [i] [222]  Classifier performance depends greatly on the characteristics of the data to be classified, such as the dataset size, distribution of samples across classes, the dimensionality, and the level of noise. Model-based classifiers perform well if the assumed model is an extremely good fit for the actual data. Otherwise, if no matching model is available, and if accuracy (rather than speed or scalability) is the sole concern, conventional wisdom is that discriminative classifiers (especially SVM) tend to be more accurate than model-based classifiers such as "naive Bayes" on most practical data sets. [223] [224] 
 
 Artificial  neural networks 
 Main articles:  Artificial  neural network  and  Connectionism 
   A neural network is an interconnected group of nodes, akin to the vast network of  neurons  in the  human brain . 
 Neural networks were inspired by the architecture of neurons in the human brain. A simple "neuron"  N  accepts input from other neurons, each of which, when activated (or "fired"), casts a weighted "vote" for or against whether neuron  N  should itself activate. Learning requires an algorithm to adjust these weights based on the training data; one simple algorithm (dubbed " fire together, wire together ") is to increase the weight between two connected neurons when the activation of one triggers the successful activation of another. The neural network forms "concepts" that are distributed among a subnetwork of shared [j]  neurons that tend to fire together; a concept meaning "leg" might be coupled with a subnetwork meaning "foot" that includes the sound for "foot". Neurons have a continuous spectrum of activation; in addition, neurons can process inputs in a nonlinear way rather than weighing straightforward votes. Modern neural networks can learn both continuous functions and, surprisingly, digital logical operations. Neural networks' early successes included predicting the stock market and (in 1995) a mostly self-driving car. [k] [225]  In the 2010s, advances in neural networks using deep learning thrust AI into widespread public consciousness and contributed to an enormous upshift in corporate AI spending; for example, AI-related  M&A  in 2017 was over 25 times as large as in 2015. [226] [227] 
 The study of non-learning  artificial  neural networks [215]  began in the decade before the field of AI research was founded, in the work of  Walter Pitts  and  Warren McCullouch .  Frank Rosenblatt  invented the  perceptron , a learning network with a single layer, similar to the old concept of  linear regression . Early pioneers also include  Alexey Grigorevich Ivakhnenko ,  Teuvo Kohonen ,  Stephen Grossberg ,  Kunihiko Fukushima ,  Christoph von der Malsburg , David Willshaw,  Shun-Ichi Amari ,  Bernard Widrow ,  John Hopfield ,  Eduardo R. Caianiello , and others [ citation needed ] .
 The main categories of networks are acyclic or  feedforward neural networks  (where the signal passes in only one direction) and  recurrent neural networks  (which allow feedback and short-term memories of previous input events). Among the most popular feedforward networks are  perceptrons ,  multi-layer perceptrons  and  radial basis networks . [228]  Neural networks can be applied to the problem of  intelligent control  (for robotics) or  learning , using such techniques as  Hebbian learning  ("fire together, wire together"),  GMDH  or  competitive learning . [229] 
 Today, neural networks are often trained by the  backpropagation  algorithm, which has been around since 1970 as the reverse mode of  automatic differentiation  published by  Seppo Linnainmaa , [230] [231]  and was introduced to neural networks by  Paul Werbos . [232] [233] [234] 
 Hierarchical temporal memory  is an approach that models some of the structural and algorithmic properties of the  neocortex . [235] 
 To summarize, most neural networks use some form of  gradient descent  on a hand-created neural topology. However, some research groups, such as  Uber , argue that simple  neuroevolution  to mutate new neural network topologies and weights may be competitive with sophisticated gradient descent approaches [ citation needed ] . One advantage of neuroevolution is that it may be less prone to get caught in "dead ends". [236] 
 
 Deep feedforward neural networks 
 Main article:  Deep learning 
 Deep learning  is the use of  artificial  neural networks  which have several layers of neurons between the network's inputs and outputs. Deep learning has transformed many important subfields of  artificial   intelligence [ why? ] , including  computer vision ,  speech recognition ,  natural language processing  and others. [237] [238] [239] 
 According to one overview, [240]  the expression "Deep Learning" was introduced to the  machine learning  community by  Rina Dechter  in 1986 [241]  and gained traction after
Igor Aizenberg and colleagues introduced it to  artificial  neural networks  in 2000. [242]  The first functional Deep Learning networks were published by  Alexey Grigorevich Ivakhnenko  and V. G. Lapa in 1965. [243] [ page needed ]  These networks are trained one layer at a time. Ivakhnenko's 1971 paper [244]  describes the learning of a deep feedforward multilayer perceptron with eight layers, already much deeper than many later networks. In 2006, a publication by  Geoffrey Hinton  and Ruslan Salakhutdinov introduced another way of pre-training many-layered  feedforward neural networks  (FNNs) one layer at a time, treating each layer in turn as an  unsupervised   restricted Boltzmann machine , then using  supervised   backpropagation  for fine-tuning. [245]  Similar to shallow  artificial  neural networks, deep neural networks can model complex non-linear relationships.
 Deep learning often uses  convolutional neural networks  (CNNs), whose origins can be traced back to the  Neocognitron  introduced by  Kunihiko Fukushima  in 1980. [246]  In 1989,  Yann LeCun  and colleagues applied  backpropagation  to such an architecture. In the early 2000s, in an industrial application, CNNs already processed an estimated 10% to 20% of all the checks written in the US. [247] 
Since 2011, fast implementations of CNNs on GPUs have
won many visual pattern recognition competitions. [239] 
 CNNs with 12 convolutional layers were used with  reinforcement learning  by Deepmind's " AlphaGo  Lee", the program that beat a top  Go  champion in 2016. [248] 
 
 Deep recurrent neural networks 
 Main article:  Recurrent neural networks 
 Early on, deep learning was also applied to sequence learning with  recurrent neural networks  (RNNs) [249]  which are theoretically Turing complete [250]  and can run arbitrary programs to process arbitrary sequences of inputs. The depth of an RNN is unlimited and depends on the length of its input sequence; thus, an RNN is an example of deep learning. [239]  RNNs can be trained by  gradient descent [251] [252] [253]  but suffer from the  vanishing gradient problem . [237] [254]  In 1992, it was shown that unsupervised pre-training of a stack of  recurrent neural networks  can speed up subsequent supervised learning of deep sequential problems. [255] 
 Numerous researchers now use variants of a deep learning recurrent NN called the  long short-term memory  (LSTM) network published by Hochreiter & Schmidhuber in 1997. [256]  LSTM is often trained by  Connectionist Temporal Classification  (CTC). [257]  At Google, Microsoft and Baidu this approach has revolutionized  speech recognition . [258] [259] [260]  For example, in 2015, Google's speech recognition experienced a dramatic performance jump of 49% through CTC-trained LSTM, which is now available through  Google Voice  to billions of smartphone users. [261]  Google also used LSTM to improve machine translation, [262]  Language Modeling [263]  and Multilingual Language Processing. [264]  LSTM combined with CNNs also improved automatic image captioning [265]  and a plethora of other applications.
 
 Evaluating progress 
 Further information:  Progress in  artificial   intelligence  and  Competitions and prizes in  artificial   intelligence 
 AI, like electricity or the steam engine, is a general purpose technology. There is no consensus on how to characterize which tasks AI tends to excel at. [266]  While projects such as  AlphaZero  have succeeded in generating their own knowledge from scratch, many other machine learning projects require large training datasets. [267] [268]  Researcher  Andrew Ng  has suggested, as a "highly imperfect rule of thumb", that "almost anything a typical human can do with less than one second of mental thought, we can probably now or in the near future automate using AI." [269]   Moravec's paradox  suggests that AI lags humans at many tasks that the human brain has specifically evolved to perform well. [134] 
 Games provide a well-publicized benchmark for assessing rates of progress.  AlphaGo  around 2016 brought the era of classical board-game benchmarks to a close. Games of imperfect knowledge provide new challenges to AI in  game theory . [270] [271]   E-sports  such as  StarCraft  continue to provide additional public benchmarks. [272] [273]  Many competitions and prizes, such as the  Imagenet Challenge , promote research in  artificial   intelligence . The most common areas of competition include general machine  intelligence , conversational behavior, data-mining,  robotic cars , and robot soccer as well as conventional games. [274] 
 The "imitation game" (an interpretation of the 1950  Turing test  that assesses whether a computer can imitate a human) is nowadays considered too exploitable to be a meaningful benchmark. [275]  A derivative of the Turing test is the Completely Automated Public Turing test to tell Computers and Humans Apart ( CAPTCHA ). As the name implies, this helps to determine that a user is an actual person and not a computer posing as a human. Unlike the standard Turing test, CAPTCHA is administered by a machine and targeted to a human as opposed to being administered by a human and targeted to a machine. A computer asks a user to complete a simple test then generates a grade for that test. Computers are unable to solve the problem, so correct solutions are deemed to be the result of a person taking the test. A common type of CAPTCHA is the test that requires the typing of distorted letters, numbers or symbols that appear in an image undecipherable by a computer. [276] 
 Proposed "universal  intelligence " tests aim to compare how well machines, humans, and even non-human animals perform on problem sets that are generic as possible. At an extreme, the test suite can contain every possible problem, weighted by  Kolmogorov complexity ; unfortunately, these problem sets tend to be dominated by impoverished pattern-matching exercises where a tuned AI can easily exceed human performance levels. [277] [278] 
 
 Hardware improvements 
 Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer. [279]  By 2019, graphic processing units ( GPUs ), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. [280]   OpenAI  estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months. [281] [282] 
 
 Applications 
   An  automated online assistant  providing customer service on a web page – one of many very primitive applications of  artificial   intelligence 
 Main article:  Applications of  artificial   intelligence 
 AI is relevant to any intellectual task. [283]  Modern  artificial   intelligence  techniques are pervasive [284]  and are too numerous to list here. Frequently, when a technique reaches mainstream use, it is no longer considered  artificial   intelligence ; this phenomenon is described as the  AI effect . [285] 
 High-profile examples of AI include autonomous vehicles (such as  drones  and  self-driving cars ), medical diagnosis, creating art (such as poetry), proving mathematical theorems, playing games (such as Chess or Go), search engines (such as  Google search ), online assistants (such as  Siri ), image recognition in photographs, spam filtering, predicting flight delays, [286]  prediction of judicial decisions, [287]  targeting online advertisements,  [283] [288] [289]  and  energy storage [290] 
 With social media sites overtaking TV as a source for news for young people and news organizations increasingly reliant on social media platforms for generating distribution, [291]  major publishers now use  artificial   intelligence  (AI) technology to post stories more effectively and generate higher volumes of traffic. [292] 
 AI can also produce  Deepfakes , a content-altering technology. ZDNet reports, "It presents something that did not actually occur," Though 88% of Americans believe Deepfakes can cause more harm than good, only 47% of them believe they can be targeted. The boom of election year also opens public discourse to threats of videos of falsified politician media. [293] 
 
 Healthcare 
 Main article:  Artificial   intelligence  in healthcare 
   A patient-side surgical arm of  Da Vinci Surgical System AI in healthcare is often used for classification, whether to automate initial evaluation of a CT scan or EKG or to identify high-risk patients for population health. The breadth of applications is rapidly increasing.
As an example, AI is being applied to the high-cost problem of dosage issues—where findings suggested that AI could save $16 billion. In 2016, a groundbreaking study in California found that a mathematical formula developed with the help of AI correctly determined the accurate dose of immunosuppressant drugs to give to organ patients. [294]     X-ray  of a hand, with automatic calculation of  bone age  by computer software 
 Artificial   intelligence  is assisting doctors. According to Bloomberg Technology, Microsoft has developed AI to help doctors find the right treatments for cancer. [295]  There is a great amount of research and drugs developed relating to cancer. In detail, there are more than 800 medicines and vaccines to treat cancer. This negatively affects the doctors, because there are too many options to choose from, making it more difficult to choose the right drugs for the patients. Microsoft is working on a project to develop a machine called "Hanover" [ citation needed ] . Its goal is to memorize all the papers necessary to cancer and help predict which combinations of drugs will be most effective for each patient. One project that is being worked on at the moment is fighting  myeloid leukemia , a fatal cancer where the treatment has not improved in decades. Another study was reported to have found that  artificial   intelligence  was as good as trained doctors in identifying skin cancers. [296]  Another study is using  artificial   intelligence  to try to monitor multiple high-risk patients, and this is done by asking each patient numerous questions based on data acquired from live doctor to patient interactions. [297]  One study was done with transfer learning, the machine performed a diagnosis similarly to a well-trained ophthalmologist, and could generate a decision within 30 seconds on whether or not the patient should be referred for treatment, with more than 95% accuracy. [298] 
 According to  CNN , a recent study by surgeons at the Children's National Medical Center in Washington successfully demonstrated surgery with an autonomous robot. The team supervised the robot while it performed soft-tissue surgery, stitching together a pig's bowel during open surgery, and doing so better than a human surgeon, the team claimed. [299]  IBM has created its own  artificial   intelligence  computer, the  IBM Watson , which has beaten human  intelligence  (at some levels). Watson has struggled to achieve success and adoption in healthcare. [300] 
 
 Automotive 
 Main article:  driverless cars 
 Advancements in AI have contributed to the growth of the automotive industry through the creation and evolution of self-driving vehicles. As of 2016 [update] , there are over 30 companies utilizing AI into the creation of  self-driving cars . A few companies involved with AI include  Tesla ,  Google , and  Apple . [301] 
 Many components contribute to the functioning of self-driving cars. These vehicles incorporate systems such as braking, lane changing, collision prevention, navigation and mapping. Together, these systems, as well as high-performance computers, are integrated into one complex vehicle. [302] 
 Recent developments in autonomous automobiles have made the innovation of self-driving trucks possible, though they are still in the testing phase. The UK government has passed legislation to begin testing of self-driving truck platoons in 2018. [303]  Self-driving truck platoons are a fleet of self-driving trucks following the lead of one non-self-driving truck, so the truck platoons aren't entirely autonomous yet. Meanwhile, the Daimler, a German automobile corporation, is testing the Freightliner Inspiration which is a semi-autonomous truck that will only be used on the highway. [304] 
 One main factor that influences the ability for a driverless automobile to function is mapping. In general, the vehicle would be pre-programmed with a map of the area being driven. This map would include data on the approximations of street light and curb heights in order for the vehicle to be aware of its surroundings. However, Google has been working on an algorithm with the purpose of eliminating the need for pre-programmed maps and instead, creating a device that would be able to adjust to a variety of new surroundings. [305]  Some self-driving cars are not equipped with steering wheels or brake pedals, so there has also been research focused on creating an algorithm that is capable of maintaining a safe environment for the passengers in the vehicle through awareness of speed and driving conditions. [306] 
 Another factor that is influencing the ability of a driverless automobile is the safety of the passenger. To make a driverless automobile, engineers must program it to handle high-risk situations. These situations could include a head-on collision with pedestrians. The car's main goal should be to make a decision that would avoid hitting the pedestrians and saving the passengers in the car. But there is a possibility the car would need to make a decision that would put someone in danger. In other words, the car would need to decide to save the pedestrians or the passengers. [307]  The programming of the car in these situations is crucial to a successful driverless automobile.
 
 Finance and economics 
 Financial institutions  have long used  artificial  neural network  systems to detect charges or claims outside of the norm, flagging these for human investigation. The use of AI in  banking  can be traced back to 1987 when  Security Pacific National Bank  in the US set-up a Fraud Prevention Task force to counter the unauthorized use of debit cards. [308]  Programs like Kasisto and Moneystream are using AI in financial services.
 Banks use  artificial   intelligence  systems today to organize operations, maintain book-keeping, invest in stocks, and manage properties. AI can react to changes overnight or when business is not taking place. [309]  In August 2001, robots beat humans in a simulated  financial trading  competition. [310]  AI has also reduced fraud and financial crimes by  monitoring   behavioral patterns  of users for any abnormal changes or anomalies. [311] [312] [313] 
 AI is increasingly being used by  corporations .  Jack Ma  has controversially predicted that AI  CEO 's are 30 years away. [314] [315] 
 The use of AI machines in the market in applications such as online trading and decision making has changed major economic theories. [316]  For example, AI-based buying and selling platforms have changed the law of  supply and demand  in that it is now possible to easily estimate individualized demand and supply curves and thus individualized pricing. Furthermore, AI machines reduce  information asymmetry  in the market and thus making markets more efficient while reducing the volume of trades [ citation needed ] . Furthermore, AI in the markets limits the consequences of behavior in the markets again making markets more efficient [ citation needed ] . Other theories where AI has had impact include in  rational choice ,  rational expectations ,  game theory ,  Lewis turning point ,  portfolio optimization  and  counterfactual thinking [ citation needed ] .. In August 2019, the  AICPA  introduced an AI training course for accounting professionals. [317] 
 
 Cybersecurity 
 This section  needs additional citations for  verification .  Please help  improve this article  by  adding citations to reliable sources . Unsourced material may be challenged and removed.   ( January 2020 )  ( Learn how and when to remove this template message ) 
 The  cybersecurity  arena faces significant challenges in the form of large-scale hacking attacks of different types that harm organizations of all kinds and create billions of dollars in business damage.  Artificial   intelligence  and Natural Language Processing (NLP) has begun to be used by security companies - for example, SIEM (Security Information and Event Management) solutions.  The more advanced of these solutions use AI and NLP to automatically sort the data in networks into high risk and low-risk information.  This enables security teams to focus on the attacks that have the potential to do real harm to the organization, and not become victims of attacks such as  Denial of Service (DoS) ,  Malware  and others.
 
 Government 
 Main article:  Artificial   intelligence  in government 
 Artificial   intelligence  in government consists of applications and regulation.  Artificial   intelligence  paired with  facial recognition systems  may be used for  mass surveillance . This is already the case in some parts of China. [318] [319]   Artificial   intelligence  has also competed in the Tama City  mayoral elections  in 2018.
 In 2019, the tech city of Bengaluru in India is set to deploy AI managed traffic signal systems across the 387 traffic signals in the city. This system will involve use of cameras to ascertain traffic density and accordingly calculate the time needed to clear the traffic volume which will determine the signal duration for vehicular traffic across streets. [320] 
 
 Law-related professions 
 Main article:  Legal informatics §  Artificial   intelligence 
 Artificial   intelligence  (AI) is becoming a mainstay component of law-related professions. In some circumstances, this analytics-crunching technology is using algorithms and machine learning to do work that was previously done by entry-level lawyers. [ citation needed ] 
 In  Electronic Discovery (eDiscovery) , the industry has been focused on machine learning (predictive coding/technology assisted review), which is a subset of AI. To add to the soup of applications, Natural Language Processing (NLP) and Automated Speech Recognition (ASR) are also in vogue in the industry. [321] 
 
 Video games 
 Main article:  Artificial   intelligence  (video games) 
 In video games,  artificial   intelligence  is routinely used to generate dynamic purposeful behavior in  non-player characters  (NPCs). In addition, well-understood AI techniques are routinely used for  pathfinding . Some researchers consider NPC AI in games to be a "solved problem" for most production tasks. Games with more atypical AI include the AI director of  Left 4 Dead  (2008) and the neuroevolutionary training of platoons in  Supreme Commander 2  (2010). [322] [323] 
 
 Military 
 Further information:  Artificial   intelligence  arms race ,  Lethal autonomous weapon , and  Unmanned combat aerial vehicle 
 The United States and other nations are developing AI applications for a range of military functions. [324]  The main military applications of  Artificial   Intelligence  and Machine Learning are to enhance C2, Communications, Sensors, Integration and Interoperability. [325]  AI research is underway in the fields of  intelligence  collection and analysis, logistics, cyber operations, information operations, command and control, and in a variety of semiautonomous and autonomous vehicles. [324]   Artificial   Intelligence  technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Join Fires between networked combat vehicles and tanks also inside Manned and Unmanned Teams (MUM-T). [325]  AI has been incorporated into military operations in Iraq and Syria. [324] 
 Worldwide annual military spending on robotics rose from US$5.1 billion in 2010 to US$7.5 billion in 2015. [326] [327]  Military drones capable of autonomous action are widely considered a useful asset. [328]  Many  artificial   intelligence  researchers seek to distance themselves from military applications of AI. [329] 
 
 Hospitality 
 In the hospitality industry,  Artificial   Intelligence  based solutions are used to reduce staff load and increase efficiency [330]  by cutting repetitive tasks frequency, trends analysis, guest interaction, and customer needs prediction. [331]  Hotel services backed by  Artificial   Intelligence  are represented in the form of a chatbot, [332]  application, virtual voice assistant and service robots.
 
 Audit 
 For financial statements audit, AI makes continuous audit possible. AI tools could analyze many sets of different information immediately. The potential benefit would be the overall audit risk will be reduced, the level of assurance will be increased and the time duration of audit will be reduced. [333] 
 
 Advertising 
 It is possible to use AI to predict or generalize the behavior of customers from their  digital footprints  in order to target them with personalized promotions or build customer personas automatically. [334]  A documented case reports that online gambling companies were using AI to improve customer targeting. [335] 
 Moreover, the application of  Personality computing  AI models can help reduce the cost of advertising campaigns by adding psychological targeting to more traditional sociodemographic or behavioral targeting. [336] 
 
 Art 
 Further information:  Computer art 
 Artificial   Intelligence  has inspired numerous creative applications including its usage to produce visual art. The exhibition "Thinking Machines: Art and Design in the Computer Age, 1959–1989" at MoMA [337]  provides a good overview of the historical applications of AI for art, architecture, and design. Recent exhibitions showcasing the usage of AI to produce art include the Google-sponsored benefit and auction at the Gray Area Foundation in San Francisco, where artists experimented with the  DeepDream  algorithm [338]  and the exhibition "Unhuman: Art in the Age of AI," which took place in Los Angeles and Frankfurt in the fall of 2017. [339] [340]  In the spring of 2018, the Association of Computing Machinery dedicated a special magazine issue to the subject of computers and art highlighting the role of machine learning in the arts. [341]  The Austrian  Ars Electronica  and  Museum of Applied Arts, Vienna  opened exhibitions on AI in 2019. [342] [343]  The Ars Electronica's 2019 festival "Out of the box" extensively thematized the role of arts for a sustainable societal transformation with AI. [344] 
 
 Philosophy and ethics 
 Main articles:  Philosophy of  artificial   intelligence  and  Ethics of  artificial   intelligence 
 There are three philosophical questions related to AI [ citation needed ] :
 
 Whether  artificial  general  intelligence  is possible; whether a machine can solve any problem that a human being can solve using  intelligence , or if there are hard limits to what a machine can accomplish. 
 Whether intelligent machines are dangerous; how humans can ensure that machines behave ethically and that they are used ethically. 
 Whether a machine can have a  mind ,  consciousness  and  mental states  in the same sense that human beings do; if a machine can be  sentient , and thus deserve certain rights − and if a machine can  intentionally  cause harm. 
 The limits of  artificial  general  intelligence 
 Main articles:  Philosophy of  artificial   intelligence ,  Turing test ,  Physical symbol systems hypothesis ,  Dreyfus' critique of  artificial   intelligence ,  The Emperor's New Mind , and  AI effect 
 Alan Turing's "polite convention" 
 One need not decide if a machine can "think"; one need only decide if a machine can act as intelligently as a human being. This approach to the philosophical problems associated with  artificial   intelligence  forms the basis of the  Turing test . [345] 
 The  Dartmouth proposal 
 "Every aspect of learning or any other feature of  intelligence  can be so precisely described that a machine can be made to simulate it." This conjecture was printed in the proposal for the Dartmouth Conference of 1956. [346] 
 Newell and Simon's physical symbol system hypothesis 
 "A physical symbol system has the necessary and sufficient means of general intelligent action." Newell and Simon argue that  intelligence  consists of formal operations on symbols. [347]   Hubert Dreyfus  argues that, on the contrary, human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a "feel" for the situation, rather than explicit symbolic knowledge. (See  Dreyfus' critique of AI .) [348] [349] 
 Gödelian arguments 
 Gödel  himself, [350]   John Lucas  (in 1961) and  Roger Penrose  (in a more detailed argument from 1989 onwards) made highly technical arguments that human mathematicians can consistently see the truth of their own "Gödel statements" and therefore have computational abilities beyond that of mechanical Turing machines. [351]  However, some people do not agree with the "Gödelian arguments". [352] [353] [354] 
 The  artificial  brain  argument 
 An argument asserting that the brain can be simulated by machines and, because brains exhibit  intelligence , these simulated brains must also exhibit  intelligence  − ergo, machines can be intelligent.  Hans Moravec ,  Ray Kurzweil  and others have argued that it is technologically feasible to copy the brain directly into hardware and software, and that such a simulation will be essentially identical to the original. [152] 
 The  AI effect 
 A hypothesis claiming that machines are  already  intelligent, but observers have failed to recognize it. For example, when  Deep Blue  beat  Garry Kasparov  in chess, the machine could be described as exhibiting  intelligence . However, onlookers commonly discount the behavior of an  artificial   intelligence  program by arguing that it is not "real"  intelligence , with "real"  intelligence  being in effect defined as whatever behavior machines cannot do. 
 Potential harm 
 Widespread use of  artificial   intelligence  could have  unintended consequences  that are dangerous or undesirable. Scientists from the  Future of Life Institute , among others, described some short-term research goals to see how AI influences the economy, the laws and ethics that are involved with AI and how to minimize AI security risks. In the long-term, the scientists have proposed to continue optimizing function while minimizing possible security risks that come along with new technologies. [355] 
 The potential negative effects of AI and automation were a major issue for  Andrew Yang 's  2020 presidential campaign  in the United States. [356]  Irakli Beridze, Head of the Centre for  Artificial   Intelligence  and Robotics at UNICRI, United Nations, has expressed that "I think the dangerous applications for AI, from my point of view, would be criminals or large terrorist organizations using it to disrupt large processes or simply do pure harm. [Terrorists could cause harm] via digital warfare, or it could be a combination of robotics, drones, with AI and other things as well that could be really dangerous. And, of course, other risks come from things like job losses. If we have massive numbers of people losing jobs and don't find a solution, it will be extremely dangerous. Things like lethal autonomous weapons systems should be properly governed — otherwise there's massive potential of misuse." [357] 
 
 Existential risk 
 Main article:  Existential risk from  artificial  general  intelligence 
 Physicist  Stephen Hawking ,  Microsoft  founder  Bill Gates , and  SpaceX  founder  Elon Musk  have expressed concerns about the possibility that AI could evolve to the point that humans could not control it, with Hawking theorizing that this could " spell the end of the human race ". [358] [359] [360] 
 
 The development of full  artificial   intelligence  could spell the end of the human race. Once humans develop  artificial   intelligence , it will take off on its own and redesign itself at an ever-increasing rate. Humans, who are limited by slow biological evolution, couldn't compete and would be superseded. —  Stephen Hawking [361] 
 In his book  Superintelligence , philosopher  Nick Bostrom  provides an argument that  artificial   intelligence  will pose a threat to humankind. He argues that sufficiently intelligent AI, if it chooses actions based on achieving some goal, will exhibit  convergent  behavior such as acquiring resources or protecting itself from being shut down. If this AI's goals do not fully reflect humanity's—one example is an AI told to compute as many digits of pi as possible—it might harm humanity in order to acquire more resources or prevent itself from being shut down, ultimately to better achieve its goal.  Bostrom also emphasizes the difficulty of fully conveying humanity's values to an advanced AI.  He uses the hypothetical example of giving an AI the goal to make humans smile to illustrate a misguided attempt.  If the AI in that scenario were to become superintelligent, Bostrom argues, it may resort to methods that most humans would find horrifying, such as inserting "electrodes into the facial muscles of humans to cause constant, beaming grins" because that would be an efficient way to achieve its goal of making humans smile. [362]   In his book  Human Compatible , AI researcher  Stuart J. Russell  echoes some of Bostrom's concerns while also proposing  an approach  to developing provably beneficial machines focused on uncertainty and deference to humans, [363] : 173  possibly involving  inverse reinforcement learning . [363] : 191–193 
 Concern over risk from  artificial   intelligence  has led to some high-profile donations and investments. A group of prominent tech titans including  Peter Thiel , Amazon Web Services and Musk have committed $1 billion to  OpenAI , a nonprofit company aimed at championing responsible AI development. [364]  The opinion of experts within the field of  artificial   intelligence  is mixed, with sizable fractions both concerned and unconcerned by risk from eventual superhumanly-capable AI. [365]  Other technology industry leaders believe that  artificial   intelligence  is helpful in its current form and will continue to assist humans. Oracle CEO  Mark Hurd  has stated that AI "will actually create more jobs, not less jobs" as humans will be needed to manage AI systems. [366]  Facebook CEO  Mark Zuckerberg  believes AI will "unlock a huge amount of positive things," such as curing disease and increasing the safety of autonomous cars. [367]  In January 2015, Musk donated $10 million to the  Future of Life Institute  to fund research on understanding AI decision making. The goal of the institute is to "grow wisdom with which we manage" the growing power of technology. Musk also funds companies developing  artificial   intelligence  such as  DeepMind  and  Vicarious  to "just keep an eye on what's going on with  artificial   intelligence . [368]  I think there is potentially a dangerous outcome there." [369] [370] 
 For the danger of uncontrolled advanced AI to be realized, the hypothetical AI would have to overpower or out-think all of humanity, which a minority of experts argue is a possibility far enough in the future to not be worth researching. [371] [372]  Other counterarguments revolve around humans being either intrinsically or convergently valuable from the perspective of an  artificial   intelligence . [373] 
 
 Devaluation of humanity 
 Main article:  Computer Power and Human Reason 
 Joseph Weizenbaum  wrote that AI applications cannot, by definition, successfully simulate genuine human empathy and that the use of AI technology in fields such as  customer service  or  psychotherapy [374]  was deeply misguided. Weizenbaum was also bothered that AI researchers (and some philosophers) were willing to view the human mind as nothing more than a computer program (a position now known as  computationalism ). To Weizenbaum these points suggest that AI research devalues human life. [375] 
 
 Social justice 
 Further information:  Algorithmic bias 
 Some are concerned that AI programs may unintentionally become biased after processing data that exhibits bias. [376] 
 Algorithms already have numerous applications in legal systems. An example of this is  COMPAS , a commercial program widely used by  U.S. courts  to assess the likelihood of a  defendant  becoming a  recidivist .  ProPublica  claims that the average COMPAS-assigned recidivism risk level of black defendants is significantly higher than the average COMPAS-assigned risk level of white defendants. [377] 
 
 Decrease in demand for human labor 
 Further information:  Technological unemployment § 21st century 
 The relationship between automation and employment is complicated. While automation eliminates old jobs, it also creates new jobs through micro-economic and macro-economic effects. [378]  Unlike previous waves of automation, many middle-class jobs may be eliminated by  artificial   intelligence ;  The Economist  states that "the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution" is "worth taking seriously". [379]  Subjective estimates of the risk vary widely; for example, Michael Osborne and  Carl Benedikt Frey  estimate 47% of U.S. jobs are at "high risk" of potential automation, while an OECD report classifies only 9% of U.S. jobs as "high risk". [380] [381] [382]  Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy. [383]  Author  Martin Ford  and others go further and argue that many jobs are routine, repetitive and (to an AI) predictable; Ford warns that these jobs may be automated in the next couple of decades, and that many of the new jobs may not be "accessible to people with average capability", even with retraining. Economists point out that in the past technology has tended to increase rather than reduce total employment, but acknowledge that "we're in uncharted territory" with AI. [25] 
 
 Autonomous weapons 
 See also:  Lethal autonomous weapon 
 Currently, 50+ countries are researching battlefield robots, including the United States, China, Russia, and the United Kingdom. Many people concerned about risk from superintelligent AI also want to limit the use of  artificial  soldiers and drones. [384] 
 
 Ethical machines 
 Machines with  intelligence  have the potential to use their  intelligence  to prevent harm and minimize the risks; they may have the ability to use  ethical reasoning  to better choose their actions in the world. As such, there is a need for policy making to devise policies for and regulate  artificial   intelligence  and robotics. [385]  Research in this area includes  machine ethics ,  artificial  moral agents ,  friendly AI  and discussion towards building a  human rights  framework is also in talks. [386] 
 
 Artificial  moral agents 
 Wendell Wallach introduced the concept of  artificial  moral agents  (AMA) in his book  Moral Machines [387]  For Wallach, AMAs have become a part of the research landscape of  artificial   intelligence  as guided by its two central questions which he identifies as "Does Humanity Want Computers Making Moral Decisions" [388]  and "Can (Ro)bots Really Be Moral". [389]  For Wallach, the question is not centered on the issue of  whether  machines can demonstrate the equivalent of moral behavior, unlike the  constraints  which society may place on the development of AMAs. [390] 
 
 Machine ethics 
 Main article:  Machine ethics 
 The field of machine ethics is concerned with giving machines ethical principles, or a procedure for discovering a way to resolve the ethical dilemmas they might encounter, enabling them to function in an ethically responsible manner through their own ethical decision making. [391]  The field was delineated in the AAAI Fall 2005 Symposium on Machine Ethics: "Past research concerning the relationship between technology and ethics has largely focused on responsible and irresponsible use of technology by human beings, with a few people being interested in how human beings ought to treat machines. In all cases, only human beings have engaged in ethical reasoning. The time has come for adding an ethical dimension to at least some machines. Recognition of the ethical ramifications of behavior involving machines, as well as recent and potential developments in machine autonomy, necessitate this. In contrast to computer hacking, software property issues, privacy issues and other topics normally ascribed to computer ethics, machine ethics is concerned with the behavior of machines towards human users and other machines. Research in machine ethics is key to alleviating concerns with autonomous systems—it could be argued that the notion of autonomous machines without such a dimension is at the root of all fear concerning machine  intelligence . Further, investigation of machine ethics could enable the discovery of problems with current ethical theories, advancing our thinking about Ethics." [392]  Machine ethics is sometimes referred to as machine morality, computational ethics or computational morality. A variety of perspectives of this nascent field can be found in the collected edition "Machine Ethics" [391]  that stems from the AAAI Fall 2005 Symposium on Machine Ethics. [392] 
 
 Malevolent and friendly AI 
 Main article:  Friendly AI 
 Political scientist  Charles T. Rubin  believes that AI can be neither designed nor guaranteed to be benevolent. [393]  He argues that "any sufficiently advanced benevolence may be indistinguishable from malevolence." Humans should not assume machines or robots would treat us favorably because there is no  a priori  reason to believe that they would be sympathetic to our system of morality, which has evolved along with our particular biology (which AIs would not share). Hyper-intelligent software may not necessarily decide to support the continued existence of humanity and would be extremely difficult to stop. This topic has also recently begun to be discussed in academic publications as a real source of risks to civilization, humans, and planet Earth.
 One proposal to deal with this is to ensure that the first generally intelligent AI is ' Friendly AI ' and will be able to control subsequently developed AIs. Some question whether this kind of check could actually remain in place.
 Leading AI researcher  Rodney Brooks  writes, "I think it is a mistake to be worrying about us developing malevolent AI anytime in the next few hundred years. I think the worry stems from a fundamental error in not distinguishing the difference between the very real recent advances in a particular aspect of AI and the enormity and complexity of building sentient volitional  intelligence ." [394] 
 
 Machine consciousness, sentience and mind 
 Main article:  Artificial  consciousness 
 If an AI system replicates all key aspects of human  intelligence , will that system also be  sentient —will it have a  mind  which has  conscious experiences ? This question is closely related to the philosophical problem as to the nature of human consciousness, generally referred to as the  hard problem of consciousness .
 
 Consciousness 
 Main articles:  Hard problem of consciousness  and  Theory of mind 
 David Chalmers  identified two problems in understanding the mind, which he named the "hard" and "easy" problems of consciousness. [395]  The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this  feels  or why it should feel like anything at all. Human  information processing  is easy to explain, however human  subjective experience  is difficult to explain.
 For example, consider what happens when a person is shown a color swatch and identifies it, saying "it's red". The easy problem only requires understanding the machinery in the brain that makes it possible for a person to know that the color swatch is red. The hard problem is that people also know something else—they also know  what red looks like . (Consider that a person born blind can know that something is red without knowing what red looks like.) [l]  Everyone knows subjective experience exists, because they do it every day (e.g., all sighted people know what red looks like). The hard problem is explaining how the brain creates it, why it exists, and how it is different from knowledge and other aspects of the brain.
 
 Computationalism and functionalism 
 Main articles:  Computationalism  and  Functionalism (philosophy of mind) 
 Computationalism is the position in the  philosophy of mind  that the human mind or the human brain (or both) is an information processing system and that thinking is a form of computing. [396]  Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the  mind-body problem . This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers  Jerry Fodor  and  Hilary Putnam .
 
 Strong AI hypothesis 
 Main article:  Chinese room 
 The philosophical position that  John Searle  has named  "strong AI"  states: "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds." [397]  Searle counters this assertion with his  Chinese room  argument, which asks us to look  inside  the computer and try to find where the "mind" might be. [398] 
 
 Robot rights 
 Main article:  Robot rights 
 If a machine can be created that has  intelligence , could it also  feel ? If it can feel, does it have the same rights as a human? This issue, now known as " robot rights ", is currently being considered by, for example, California's  Institute for the Future , although many critics believe that the discussion is premature. [399]  Some critics of  transhumanism  argue that any hypothetical robot rights would lie on a spectrum with  animal rights  and human rights.  [400]  The subject is profoundly discussed in the 2010 documentary film  Plug & Pray , [401]  and many sci fi media such as  Star Trek  Next Generation, with the character of  Commander Data , who fought being disassembled for research, and wanted to "become human", and the robotic holograms in Voyager.
 
 Superintelligence 
 Main article:  Superintelligence 
 Are there limits to how intelligent machines—or human-machine hybrids—can be? A superintelligence, hyperintelligence, or superhuman  intelligence  is a hypothetical agent that would possess  intelligence  far surpassing that of the brightest and most gifted human mind.  Superintelligence  may also refer to the form or degree of  intelligence  possessed by such an agent. [146] 
 
 Technological singularity 
 Main articles:  Technological singularity  and  Moore's law 
 If research into  Strong AI  produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to  recursive self-improvement . [402]  The new  intelligence  could thus increase exponentially and dramatically surpass humans. Science fiction writer  Vernor Vinge  named this scenario " singularity ". [403]  Technological singularity is when accelerating progress in technologies will cause a runaway effect wherein  artificial   intelligence  will exceed human intellectual capacity and control, thus radically changing or even ending civilization. Because the capabilities of such an  intelligence  may be impossible to comprehend, the technological singularity is an occurrence beyond which events are unpredictable or even unfathomable. [403] [146] 
 Ray Kurzweil  has used  Moore's law  (which describes the relentless exponential improvement in digital technology) to calculate that  desktop computers  will have the same processing power as human brains by the year 2029, and predicts that the singularity will occur in 2045. [403] 
 
 Transhumanism 
 Main article:  Transhumanism 
 Robot designer  Hans Moravec , cyberneticist  Kevin Warwick  and inventor  Ray Kurzweil  have predicted that humans and machines will merge in the future into  cyborgs  that are more capable and powerful than either. [404]  This idea, called  transhumanism , has roots in  Aldous Huxley  and  Robert Ettinger .
 Edward Fredkin  argues that " artificial   intelligence  is the next stage in evolution", an idea first proposed by  Samuel Butler 's " Darwin among the Machines " as far back as 1863, and expanded upon by  George Dyson  in his book of the same name in 1998. [405] 
 
 Economics 
 The long-term economic effects of AI are uncertain. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term  unemployment , but they generally agree that it could be a net benefit, if  productivity  gains are  redistributed . [406]  A February 2020 European Union white paper on  artificial   intelligence  advocated for  artificial   intelligence  for economic benefits, including "improving healthcare (e.g. making diagnosis more  precise,  enabling  better  prevention  of  diseases), increasing  the  efficiency  of  farming, contributing  to climate  change mitigation  and  adaptation, [and] improving  the  efficiency  of production systems through predictive maintenance", while acknowledging potential risks. [284] 
 
 Regulation 
 Main articles:  Regulation of  artificial   intelligence  and  Regulation of algorithms 
 The development of public sector policies for promoting and regulating  artificial   intelligence  (AI) is considered necessary to both encourage AI and manage associated risks, but challenging. [407]  In 2017  Elon Musk  called for regulation of AI development. [408]  Multiple states now have national policies under development or in place, [409]  and in February 2020, the European Union published its draft strategy paper for promoting and regulating AI. [410] 
 
 In fiction 
 Main article:  Artificial   intelligence  in fiction 
   The word "robot" itself was coined by  Karel Čapek  in his 1921 play  R.U.R. , the title standing for " Rossum's Universal Robots " 
 Thought-capable  artificial  beings appeared as storytelling devices since antiquity, [27] 
and have been a persistent theme in  science fiction .
 A common  trope  in these works began with  Mary Shelley 's  Frankenstein , where a human creation becomes a threat to its masters. This includes such works as  Arthur C. Clarke's  and  Stanley Kubrick's   2001: A Space Odyssey  (both 1968), with  HAL 9000 , the murderous computer in charge of the  Discovery One  spaceship, as well as  The Terminator  (1984) and  The Matrix  (1999). In contrast, the rare loyal robots such as Gort from  The Day the Earth Stood Still  (1951) and Bishop from  Aliens  (1986) are less prominent in popular culture. [411] 
 Isaac Asimov  introduced the  Three Laws of Robotics  in many books and stories, most notably the "Multivac" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics; [412]  while almost all  artificial   intelligence  researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity. [413] 
 Transhumanism  (the merging of humans and machines) is explored in the  manga   Ghost in the Shell  and the science-fiction series  Dune . In the 1980s, artist  Hajime Sorayama 's Sexy Robots series were painted and published in Japan depicting the actual organic human form with lifelike muscular metallic skins and later "the Gynoids" book followed that was used by or influenced movie makers including  George Lucas  and other creatives. Sorayama never considered these organic robots to be real part of nature but always an unnatural product of the human mind, a fantasy existing in the mind even when realized in actual form.
 Several works use AI to force us to confront the fundamental question of what makes us human, showing us  artificial  beings that have  the ability to feel , and thus to suffer. This appears in  Karel Čapek 's  R.U.R. , the films  A.I.  Artificial   Intelligence  and  Ex Machina , as well as the novel  Do Androids Dream of Electric Sheep? , by  Philip K. Dick . Dick considers the idea that our understanding of human subjectivity is altered by technology created with  artificial   intelligence . [414] 
 
 See also 
 
 
 Computer programming portal 
 
 A.I. Rising 
 Artificial   intelligence  arms race 
 Behavior selection algorithm 
 Business process automation 
 Case-based reasoning 
 Citizen Science 
 Emergent algorithm 
 Female gendering of AI technologies 
 Glossary of  artificial   intelligence 
 Regulation of  artificial   intelligence 
 Robotic process automation 
 Universal basic income 
 Weak AI 
 
 Explanatory notes 
 
 
 ^   The act of doling out rewards can itself be formalized or automated into a " reward function ". 
 
 ^   Terminology varies; see  algorithm characterizations . 
 
 ^   Adversarial vulnerabilities can also result in nonlinear systems, or from non-pattern perturbations. Some systems are so brittle that changing a single adversarial pixel predictably induces misclassification. 
 
 ^   While such a "victory of the neats" may be a consequence of the field becoming more mature,  AIMA  states that in practice both  neat and scruffy  approaches continue to be necessary in AI research. 
 
 ^   "There exist many different types of uncertainty, vagueness, and ignorance... [We] independently confirm the inadequacy of systems for reasoning about uncertainty that propagates numerical factors according to only to which connectives appear in assertions." [197] 
 
 ^   Expectation-maximization, one of the most popular algorithms in machine learning, allows clustering in the presence of unknown  latent variables [204] 
 
 ^   The most widely used analogical AI until the mid-1990s [216] 
 
 ^   SVM displaced k-nearest neighbor in the 1990s [218] 
 
 ^   Naive Bayes is reportedly the "most widely used learner" at Google, due in part to its scalability. [221] 
 
 ^   Each individual neuron is likely to participate in more than one concept. 
 
 ^   Steering for the 1995 " No Hands Across America " required "only a few human assists". 
 
 ^   This is based on  Mary's Room , a thought experiment first proposed by  Frank Jackson  in 1982 
 
 
 References 
 
 
 ^  a   b   c   
Definition of AI as the study of  intelligent agents :
 Poole, Mackworth & Goebel 1998 ,  p. 1 , which provides the version that is used in this article. Note that they use the term "computational  intelligence " as a synonym for  artificial   intelligence . 
 Russell & Norvig (2003)  harvtxt error: no target: CITEREFRussellNorvig2003 ( help )  (who prefer the term "rational agent") and write "The whole-agent view is now widely accepted in the field" ( Russell & Norvig 2003 , p. 55)  harv error: no target: CITEREFRussellNorvig2003 ( help ) . 
 Nilsson 1998 
 Legg & Hutter 2007 . 
 
 ^   Russell & Norvig 2009 , p. 2. 
 
 ^   McCorduck 2004 , p. 204  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 
 ^   Maloof, Mark.  " Artificial   Intelligence : An Introduction, p. 37"   (PDF) .  georgetown.edu . 
 
 ^   "How AI Is Getting Groundbreaking Changes In Talent Management And HR Tech" . Hackernoon. 
 
 ^   Schank, Roger C. (1991). "Where's the AI".  AI magazine . Vol. 12 no. 4. p. 38. 
 
 ^  a   b   Russell & Norvig 2009 . 
 
 ^  a   b   "AlphaGo – Google DeepMind" .  Archived  from the original on 10 March 2016. 
 
 ^   Allen, Gregory (April 2020).  "Department of Defense Joint AI Center - Understanding AI Technology"   (PDF) .  AI.mil - The official site of the Department of Defense Joint  Artificial   Intelligence  Center . Retrieved  25 April  2020 . 
 
 ^  a   b   
Optimism of early AI:
 Herbert Simon  quote:  Simon 1965 , p. 96 quoted in  Crevier 1993 , p. 109  harvnb error: no target: CITEREFCrevier1993 ( help ) . 
 Marvin Minsky  quote:  Minsky 1967 , p. 2 quoted in  Crevier 1993 , p. 109  harvnb error: no target: CITEREFCrevier1993 ( help ) . 
 
 ^  a   b   c   
Boom of the 1980s: rise of  expert systems ,  Fifth Generation Project ,  Alvey ,  MCC ,  SCI :
 McCorduck 2004 , pp. 426–441  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , pp. 161–162,197–203, 211, 240  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 Russell & Norvig 2003 , p. 24  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 NRC 1999 , pp. 210–211 
 Newquist 1994 , pp. 235–248 
 
 ^  a   b   
First  AI Winter ,  Mansfield Amendment ,  Lighthill report 
 Crevier 1993 , pp. 115–117  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 Russell & Norvig 2003 , p. 22  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 NRC 1999 , pp. 212–213 
 Howe 1994 
 Newquist 1994 , pp. 189–201 
 
 ^  a   b   
Second  AI winter :
 McCorduck 2004 , pp. 430–435  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , pp. 209–210  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 NRC 1999 , pp. 214–216 
 Newquist 1994 , pp. 301–318 
 
 ^  a   b   c   
AI becomes hugely successful in the early 21st century
 Clark 2015  harvnb error: multiple targets (2×): CITEREFClark2015 ( help ) 
 
 ^  a   b   
Pamela  McCorduck (2004 , p. 424)  harvtxt error: no target: CITEREFMcCorduck2004 ( help )  writes of "the rough shattering of AI in subfields—vision, natural language, decision theory, genetic algorithms, robotics ... and these with own sub-subfield—that would hardly have anything to say to each other." 
 
 ^  a   b   c   
This list of intelligent traits is based on the topics covered by the major AI textbooks, including:
 Russell & Norvig 2003  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Luger & Stubblefield 2004 
 Poole, Mackworth & Goebel 1998 
 Nilsson 1998 
 
 ^  a   b   c   
Biological  intelligence  vs.  intelligence  in general:
 Russell & Norvig 2003 , pp. 2–3  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , who make the analogy with  aeronautical engineering . 
 McCorduck 2004 , pp. 100–101  harvnb error: no target: CITEREFMcCorduck2004 ( help ) , who writes that there are "two major branches of  artificial   intelligence : one aimed at producing intelligent behavior regardless of how it was accomplished, and the other aimed at modeling intelligent processes found in nature, particularly human ones." 
 Kolata 1982 , a paper in  Science , which describes  McCarthy's  indifference to biological models. Kolata quotes McCarthy as writing: "This is AI, so we don't care if it's psychologically real" "Science" . August 1982. . McCarthy recently reiterated his position at the  AI@50  conference where he said " Artificial   intelligence  is not, by definition, simulation of human  intelligence " ( Maker 2006 ). 
 
 ^  a   b   c   
 Neats vs. scruffies :
 McCorduck 2004 , pp. 421–424, 486–489  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , p. 168  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 Nilsson 1983 , pp. 10–11 
 
 ^  a   b   
Symbolic vs. sub-symbolic AI:
 Nilsson (1998 , p. 7), who uses the term "sub-symbolic". 
 
 ^  a   b   
General  intelligence  ( strong AI ) is discussed in popular introductions to AI:
 Kurzweil 1999  and  Kurzweil 2005 
 
 ^   See the  Dartmouth proposal , under  Philosophy , below. 
 
 ^  a   b   
This is a central idea of  Pamela McCorduck 's  Machines Who Think . She writes: "I like to think of  artificial   intelligence  as the scientific apotheosis of a venerable cultural tradition." ( McCorduck 2004 , p. 34)  harv error: no target: CITEREFMcCorduck2004 ( help )  " Artificial   intelligence  in one form or another is an idea that has pervaded Western intellectual history, a dream in urgent need of being realized." ( McCorduck 2004 , p. xviii)  harv error: no target: CITEREFMcCorduck2004 ( help )  "Our history is full of attempts—nutty, eerie, comical, earnest, legendary and real—to make  artificial  intelligences, to reproduce what is the essential us—bypassing the ordinary means. Back and forth between myth and reality, our imaginations supplying what our workshops couldn't, we have engaged for a long time in this odd form of self-reproduction." ( McCorduck 2004 , p. 3)  harv error: no target: CITEREFMcCorduck2004 ( help )  She traces the desire back to its  Hellenistic  roots and calls it the urge to "forge the Gods." ( McCorduck 2004 , pp. 340–400)  harv error: no target: CITEREFMcCorduck2004 ( help ) 
 
 ^   "Stephen Hawking believes AI could be mankind's last accomplishment" .  BetaNews . 21 October 2016.  Archived  from the original on 28 August 2017. 
 
 ^   Lombardo P, Boehm I, Nairz K (2020).  "RadioComics – Santa Claus and the future of radiology" .  Eur J Radiol .  122  (1): 108771.  doi : 10.1016/j.ejrad.2019.108771 .  PMID   31835078 . 
 
 ^  a   b   Ford, Martin; Colvin, Geoff (6 September 2015).  "Will robots create more jobs than they destroy?" .  The Guardian . Retrieved  13 January  2018 . 
 
 ^  a   b   
AI applications widely used behind the scenes:
 Russell & Norvig 2003 , p. 28  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Kurzweil 2005 , p. 265 
 NRC 1999 , pp. 216–222 
 Newquist 1994 , pp. 189–201 
 
 ^  a   b   
AI in myth:
 McCorduck 2004 , pp. 4–5  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Russell & Norvig 2003 , p. 939  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
AI in early science fiction.
 McCorduck 2004 , pp. 17–25  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 
 ^   
Formal reasoning:
 Berlinski, David  (2000).  The Advent of the Algorithm . Harcourt Books.  ISBN   978-0-15-601391-8 .  OCLC   46890682 . 
 
 ^   Turing, Alan  (1948), "Machine  Intelligence ",  in Copeland, B. Jack (ed.),  The Essential Turing: The ideas that gave birth to the computer age , Oxford: Oxford University Press, p. 412,  ISBN   978-0-19-825080-7 
 
 ^   Russell & Norvig 2009 , p. 16. 
 
 ^   
 Dartmouth conference :
 McCorduck 2004 , pp. 111–136  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , pp. 47–49  harvnb error: no target: CITEREFCrevier1993 ( help ) , who writes "the conference is generally recognized as the official birthdate of the new science." 
 Russell & Norvig 2003 , p. 17  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , who call the conference "the birth of  artificial   intelligence ." 
 NRC 1999 , pp. 200–201 
 
 ^   McCarthy, John  (1988). "Review of  The Question of  Artificial   Intelligence ".  Annals of the History of Computing .  10  (3): 224–229. , collected in  McCarthy, John  (1996). "10. Review of  The Question of  Artificial   Intelligence ".  Defending AI Research: A Collection of Essays and Reviews . CSLI. , p. 73, "[O]ne of the reasons for inventing the term " artificial   intelligence " was to escape association with "cybernetics". Its concentration on analog feedback seemed misguided, and I wished to avoid having either to accept Norbert (not Robert) Wiener as a guru or having to argue with him." 
 
 ^   
Hegemony of the Dartmouth conference attendees:
 Russell & Norvig 2003 , p. 17  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , who write "for the next 20 years the field would be dominated by these people and their students." 
 McCorduck 2004 , pp. 129–130  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 
 ^   Russell & Norvig 2003 , p. 18.  sfn error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   Schaeffer J. (2009) Didn't Samuel Solve That Game?. In: One Jump Ahead. Springer, Boston, MA 
 
 ^   Samuel, A. L. (July 1959). "Some Studies in Machine Learning Using the Game of Checkers".  IBM Journal of Research and Development .  3  (3): 210–229.  CiteSeerX   10.1.1.368.2254 .  doi : 10.1147/rd.33.0210 . 
 
 ^   
" Golden years " of AI (successful symbolic reasoning programs 1956–1973):
 McCorduck 2004 , pp. 243–252  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , pp. 52–107  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 Moravec 1988 , p. 9  harvnb error: multiple targets (2×): CITEREFMoravec1988 ( help ) 
 Russell & Norvig 2003 , pp. 18–21  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
The programs described are  Arthur Samuel 's checkers program for the  IBM 701 ,  Daniel Bobrow 's  STUDENT ,  Newell  and  Simon 's  Logic Theorist  and  Terry Winograd 's  SHRDLU . 
 
 ^   
 DARPA  pours money into undirected pure research into AI during the 1960s:
 McCorduck 2004 , p. 131  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , pp. 51, 64–65  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 NRC 1999 , pp. 204–205 
 
 ^   
AI in England:
 Howe 1994 
 
 ^   Lighthill 1973 . 
 
 ^  a   b   
Expert systems:
 ACM 1998 , I.2.1 
 Russell & Norvig 2003 , pp. 22–24  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Luger & Stubblefield 2004 , pp. 227–331 
 Nilsson 1998 , chpt. 17.4 
 McCorduck 2004 , pp. 327–335, 434–435  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , pp. 145–62, 197–203  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 Newquist 1994 , pp. 155–183 
 
 ^   Mead, Carver A.; Ismail, Mohammed (8 May 1989).  Analog VLSI Implementation of Neural Systems   (PDF) . The Kluwer International Series in Engineering and Computer Science.  80 . Norwell, MA:  Kluwer Academic Publishers .  doi : 10.1007/978-1-4613-1639-8 .  ISBN   978-1-4613-1639-8 . Archived from  the original   (PDF)  on 6 November 2019 . Retrieved  24 January  2020 . 
 
 ^  a   b   
Formal methods are now preferred ("Victory of the  neats "):
 Russell & Norvig 2003 , pp. 25–26  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 McCorduck 2004 , pp. 486–487  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 
 ^   McCorduck 2004 , pp. 480–483.  sfn error: no target: CITEREFMcCorduck2004 ( help ) 
 
 ^   Markoff 2011 . 
 
 ^   "Ask the AI experts: What's driving today's progress in AI?" .  McKinsey & Company . Retrieved  13 April  2018 . 
 
 ^   Administrator.  "Kinect's AI breakthrough explained" .  i-programmer.info .  Archived  from the original on 1 February 2016. 
 
 ^   Rowinski, Dan (15 January 2013).  "Virtual Personal Assistants & The Future Of Your Smartphone [Infographic]" .  ReadWrite .  Archived  from the original on 22 December 2015. 
 
 ^   " Artificial   intelligence : Google's AlphaGo beats Go master Lee Se-dol" .  BBC News . 12 March 2016.  Archived  from the original on 26 August 2016 . Retrieved  1 October  2016 . 
 
 ^   Metz, Cade (27 May 2017).  "After Win in China, AlphaGo's Designers Explore New AI" .  Wired .  Archived  from the original on 2 June 2017. 
 
 ^   "World's Go Player Ratings" . May 2017.  Archived  from the original on 1 April 2017. 
 
 ^   "柯洁迎19岁生日 雄踞人类世界排名第一已两年"  (in Chinese). May 2017.  Archived  from the original on 11 August 2017. 
 
 ^  a   b   Clark, Jack (8 December 2015).  "Why 2015 Was a Breakthrough Year in  Artificial   Intelligence " .  Bloomberg News .  Archived  from the original on 23 November 2016 . Retrieved  23 November  2016 .  After a half-decade of quiet breakthroughs in  artificial   intelligence , 2015 has been a landmark year. Computers are smarter and learning faster than ever. 
 
 ^   "Reshaping Business With  Artificial   Intelligence " .  MIT Sloan Management Review . Retrieved  2 May  2018 . 
 
 ^   Lorica, Ben (18 December 2017).  "The state of AI adoption" .  O'Reilly Media . Retrieved  2 May  2018 . 
 
 ^   Allen, Gregory (6 February 2019).  "Understanding China's AI Strategy" .  Center for a New American Security . 
 
 ^   "Review | How two AI superpowers – the U.S. and China – battle for supremacy in the field" .  Washington Post . 2 November 2018 . Retrieved  4 November  2018 . 
 
 ^   at 10:11, Alistair Dabbs 22 Feb 2019.  " Artificial   Intelligence : You know it isn't real, yeah?" .  www.theregister.co.uk . 
 
 ^   "Stop Calling it  Artificial   Intelligence " . 
 
 ^   "AI isn't taking over the world – it doesn't exist yet" .  GBG Global website . 
 
 ^   Kaplan, Andreas; Haenlein, Michael (1 January 2019). "Siri, Siri, in my hand: Who's the fairest in the land? On the interpretations, illustrations, and implications of  artificial   intelligence ".  Business Horizons .  62  (1): 15–25.  doi : 10.1016/j.bushor.2018.08.004 . 
 
 ^   Domingos 2015 , Chapter 5. 
 
 ^   Domingos 2015 , Chapter 7. 
 
 ^   Lindenbaum, M., Markovitch, S., & Rusakov, D. (2004). Selective sampling for nearest neighbor classifiers. Machine learning, 54(2), 125–152. 
 
 ^   Domingos 2015 , Chapter 1. 
 
 ^  a   b   
 Intractability and efficiency  and the  combinatorial explosion :
 Russell & Norvig 2003 , pp. 9, 21–22  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   Domingos 2015 , Chapter 2, Chapter 3. 
 
 ^   Hart, P. E.; Nilsson, N. J.; Raphael, B. (1972). "Correction to "A Formal Basis for the Heuristic Determination of Minimum Cost Paths " ".  SIGART Newsletter  (37): 28–29.  doi : 10.1145/1056777.1056779 . 
 
 ^   Domingos 2015 , Chapter 2, Chapter 4, Chapter 6. 
 
 ^   "Can neural network computers learn from experience, and if so, could they ever become what we would call 'smart'?" .  Scientific American . 2018 . Retrieved  24 March  2018 . 
 
 ^   Domingos 2015 , Chapter 6, Chapter 7. 
 
 ^   Domingos 2015 , p. 286. 
 
 ^   "Single pixel change fools AI programs" .  BBC News . 3 November 2017 . Retrieved  12 March  2018 . 
 
 ^   "AI Has a Hallucination Problem That's Proving Tough to Fix" .  WIRED . 2018 . Retrieved  12 March  2018 . 
 
 ^   Goodfellow, Ian J.; Shlens, Jonathon; Szegedy, Christian (2014). "Explaining and Harnessing Adversarial Examples".  arXiv : 1412.6572  [ stat.ML ]. 
 
 ^   Matti, D.; Ekenel, H. K.; Thiran, J. P. (2017).  Combining LiDAR space clustering and convolutional neural networks for pedestrian detection .  2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS) . pp. 1–6.  arXiv : 1710.06160 .  doi : 10.1109/AVSS.2017.8078512 .  ISBN   978-1-5386-2939-0 . 
 
 ^   Ferguson, Sarah; Luders, Brandon; Grande, Robert C.; How, Jonathan P. (2015).  Real-Time Predictive Modeling and Robust Avoidance of Pedestrians with Uncertain, Changing Intentions .  Algorithmic Foundations of Robotics XI . Springer Tracts in Advanced Robotics.  107 . Springer, Cham. pp. 161–177.  arXiv : 1405.5581 .  doi : 10.1007/978-3-319-16595-0_10 .  ISBN   978-3-319-16594-3 . 
 
 ^   "Cultivating Common Sense | DiscoverMagazine.com" .  Discover Magazine . 2017. Archived from  the original  on 25 March 2018 . Retrieved  24 March  2018 . 
 
 ^   Davis, Ernest; Marcus, Gary (24 August 2015).  "Commonsense reasoning and commonsense knowledge in  artificial   intelligence " .  Communications of the ACM .  58  (9): 92–103.  doi : 10.1145/2701413 . 
 
 ^   Winograd, Terry (January 1972). "Understanding natural language".  Cognitive Psychology .  3  (1): 1–191.  doi : 10.1016/0010-0285(72)90002-3 . 
 
 ^   "Don't worry: Autonomous cars aren't coming tomorrow (or next year)" .  Autoweek . 2016 . Retrieved  24 March  2018 . 
 
 ^   Knight, Will (2017).  "Boston may be famous for bad drivers, but it's the testing ground for a smarter self-driving car" .  MIT Technology Review . Retrieved  27 March  2018 . 
 
 ^   Prakken, Henry (31 August 2017).  "On the problem of making autonomous vehicles conform to traffic law" .  Artificial   Intelligence  and Law .  25  (3): 341–363.  doi : 10.1007/s10506-017-9210-0 . 
 
 ^   Lieto, Antonio (May 2018). "The knowledge level in cognitive architectures: Current limitations and possible developments".  Cognitive Systems Research .  48 : 39–55.  doi : 10.1016/j.cogsys.2017.05.001 .  hdl : 2318/1665207 . 
 
 ^   
Problem solving, puzzle solving, game playing and deduction:
 Russell & Norvig 2003 , chpt. 3–9  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , chpt. 2,3,7,9, 
 Luger & Stubblefield 2004 , chpt. 3,4,6,8, 
 Nilsson 1998 , chpt. 7–12 
 
 ^   
Uncertain reasoning:
 Russell & Norvig 2003 , pp. 452–644  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 345–395, 
 Luger & Stubblefield 2004 , pp. 333–381, 
 Nilsson 1998 , chpt. 19 
 
 ^   
Psychological evidence of sub-symbolic reasoning:
 Wason & Shapiro (1966)  showed that people do poorly on completely abstract problems, but if the problem is restated to allow the use of intuitive  social  intelligence , performance dramatically improves. (See  Wason selection task ) 
 Kahneman, Slovic & Tversky (1982)  have shown that people are terrible at elementary problems that involve uncertain reasoning. (See  list of cognitive biases  for several examples). 
 Lakoff & Núñez (2000)  have controversially argued that even our skills at mathematics depend on knowledge and skills that come from "the body", i.e. sensorimotor and perceptual skills. (See  Where Mathematics Comes From ) 
 
 ^   
 Knowledge representation :
 ACM 1998 , I.2.4, 
 Russell & Norvig 2003 , pp. 320–363  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 23–46, 69–81, 169–196, 235–277, 281–298, 319–345, 
 Luger & Stubblefield 2004 , pp. 227–243, 
 Nilsson 1998 , chpt. 18 
 
 ^   
 Knowledge engineering :
 Russell & Norvig 2003 , pp. 260–266  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 199–233, 
 Nilsson 1998 , chpt. ≈17.1–17.4 
 
 ^  a   b   
Representing categories and relations:  Semantic networks ,  description logics ,  inheritance  (including  frames  and  scripts ):
 Russell & Norvig 2003 , pp. 349–354  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 174–177, 
 Luger & Stubblefield 2004 , pp. 248–258, 
 Nilsson 1998 , chpt. 18.3 
 
 ^  a   b   
Representing events and time: Situation calculus ,  event calculus ,  fluent calculus  (including solving the  frame problem ):
 Russell & Norvig 2003 , pp. 328–341  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 281–298, 
 Nilsson 1998 , chpt. 18.2 
 
 ^  a   b   
 Causal calculus :
 Poole, Mackworth & Goebel 1998 , pp. 335–337 
 
 ^  a   b   
Representing knowledge about knowledge: Belief calculus,  modal logics :
 Russell & Norvig 2003 , pp. 341–344  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 275–277 
 
 ^   Sikos, Leslie F. (June 2017).  Description Logics in Multimedia Reasoning . Cham: Springer.  doi : 10.1007/978-3-319-54066-5 .  ISBN   978-3-319-54066-5 .  Archived  from the original on 29 August 2017. 
 
 ^   
 Ontology :
 Russell & Norvig 2003 , pp. 320–328  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   Smoliar, Stephen W.; Zhang, HongJiang (1994). "Content based video indexing and retrieval".  IEEE Multimedia .  1  (2): 62–72.  doi : 10.1109/93.311653 . 
 
 ^   Neumann, Bernd; Möller, Ralf (January 2008). "On scene interpretation with description logics".  Image and Vision Computing .  26  (1): 82–101.  doi : 10.1016/j.imavis.2007.08.013 . 
 
 ^   Kuperman, G. J.; Reichley, R. M.; Bailey, T. C. (1 July 2006).  "Using Commercial Knowledge Bases for Clinical Decision Support: Opportunities, Hurdles, and Recommendations" .  Journal of the American Medical Informatics Association .  13  (4): 369–371.  doi : 10.1197/jamia.M2055 .  PMC   1513681 .  PMID   16622160 . 
 
 ^   MCGARRY, KEN (1 December 2005). "A survey of interestingness measures for knowledge discovery".  The Knowledge Engineering Review .  20  (1): 39–61.  doi : 10.1017/S0269888905000408 .  S2CID   14987656 . 
 
 ^   Bertini, M; Del Bimbo, A; Torniai, C (2006). "Automatic annotation and semantic retrieval of video sequences using multimedia ontologies".  MM '06 Proceedings of the 14th ACM international conference on Multimedia . 14th ACM international conference on Multimedia. Santa Barbara: ACM. pp. 679–682. 
 
 ^   
 Qualification problem :
 McCarthy & Hayes 1969 
 Russell & Norvig 2003  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) [ page needed ] 
While McCarthy was primarily concerned with issues in the logical representation of actions,  Russell & Norvig 2003  harvnb error: no target: CITEREFRussellNorvig2003 ( help )  apply the term to the more general issue of default reasoning in the vast network of assumptions underlying all our commonsense knowledge. 
 
 ^  a   b   
Default reasoning and  default logic ,  non-monotonic logics ,  circumscription ,  closed world assumption ,  abduction  (Poole  et al.  places abduction under "default reasoning". Luger  et al.  places this under "uncertain reasoning"):
 Russell & Norvig 2003 , pp. 354–360  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 248–256, 323–335, 
 Luger & Stubblefield 2004 , pp. 335–363, 
 Nilsson 1998 , ~18.3.3 
 
 ^   
Breadth of commonsense knowledge:
 Russell & Norvig 2003 , p. 21  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Crevier 1993 , pp. 113–114  harvnb error: no target: CITEREFCrevier1993 ( help ) , 
 Moravec 1988 , p. 13  harvnb error: multiple targets (2×): CITEREFMoravec1988 ( help ) , 
 Lenat & Guha 1989  (Introduction) 
 
 ^   Dreyfus & Dreyfus 1986 . 
 
 ^   Gladwell 2005 . 
 
 ^  a   b   
Expert knowledge as  embodied  intuition:
 Dreyfus & Dreyfus 1986  ( Hubert Dreyfus  is a philosopher and critic of AI who was among the first to argue that most useful human knowledge was encoded sub-symbolically. See  Dreyfus' critique of AI ) 
 Gladwell 2005  (Gladwell's  Blink  is a popular introduction to sub-symbolic reasoning and knowledge.) 
 Hawkins & Blakeslee 2005  (Hawkins argues that sub-symbolic knowledge should be the primary focus of AI research.) 
 
 ^   
 Planning :
 ACM 1998 , ~I.2.8, 
 Russell & Norvig 2003 , pp. 375–459  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 281–316, 
 Luger & Stubblefield 2004 , pp. 314–329, 
 Nilsson 1998 , chpt. 10.1–2, 22 
 
 ^  a   b   
 Information value theory :
 Russell & Norvig 2003 , pp. 600–604  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
Classical planning:
 Russell & Norvig 2003 , pp. 375–430  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 281–315, 
 Luger & Stubblefield 2004 , pp. 314–329, 
 Nilsson 1998 , chpt. 10.1–2, 22 
 
 ^   
Planning and acting in non-deterministic domains: conditional planning, execution monitoring, replanning and continuous planning:
 Russell & Norvig 2003 , pp. 430–449  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
Multi-agent planning and emergent behavior:
 Russell & Norvig 2003 , pp. 449–455  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   Alan Turing  discussed the centrality of learning as early as 1950, in his classic paper " Computing Machinery and  Intelligence ".( Turing 1950 )  harv error: no target: CITEREFTuring1950 ( help )  In 1956, at the original Dartmouth AI summer conference,  Ray Solomonoff  wrote a report on unsupervised probabilistic machine learning: "An Inductive Inference Machine".( Solomonoff 1956 ) 
 
 ^   This is a form of  Tom Mitchell 's widely quoted definition of machine learning: "A computer program is set to learn from an experience  E  with respect to some task  T  and some performance measure  P  if its performance on  T  as measured by  P  improves with experience  E ." 
 
 ^  a   b   
 Learning :
 ACM 1998 , I.2.6, 
 Russell & Norvig 2003 , pp. 649–788  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 397–438, 
 Luger & Stubblefield 2004 , pp. 385–542, 
 Nilsson 1998 , chpt. 3.3, 10.3, 17.5, 20 
 
 ^   Jordan, M. I.; Mitchell, T. M. (16 July 2015). "Machine learning: Trends, perspectives, and prospects".  Science .  349  (6245): 255–260.  Bibcode : 2015Sci...349..255J .  doi : 10.1126/science.aaa8415 .  PMID   26185243 . 
 
 ^   
 Reinforcement learning :
 Russell & Norvig 2003 , pp. 763–788  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Luger & Stubblefield 2004 , pp. 442–449 
 
 ^   
 Natural language processing :
 ACM 1998 , I.2.7 
 Russell & Norvig 2003 , pp. 790–831  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Poole, Mackworth & Goebel 1998 , pp. 91–104 
 Luger & Stubblefield 2004 , pp. 591–632 
 
 ^   "Versatile question answering systems: seeing in synthesis"   Archived  1 February 2016 at the  Wayback Machine , Mittal et al., IJIIDS, 5(2), 119–142, 2011 
 
 ^   
Applications of natural language processing, including  information retrieval  (i.e.  text mining ) and  machine translation :
 Russell & Norvig 2003 , pp. 840–857  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Luger & Stubblefield 2004 , pp. 623–630 
 
 ^   Cambria, Erik; White, Bebo (May 2014). "Jumping NLP Curves: A Review of Natural Language Processing Research [Review Article]".  IEEE Computational  Intelligence  Magazine .  9  (2): 48–57.  doi : 10.1109/MCI.2014.2307227 . 
 
 ^   Vincent, James (7 November 2019).  "OpenAI has published the text-generating AI it said was too dangerous to share" .  The Verge . Retrieved  11 June  2020 . 
 
 ^   
 Machine perception :
 Russell & Norvig 2003 , pp. 537–581, 863–898  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Nilsson 1998 , ~chpt. 6 
 
 ^   
 Speech recognition :
 ACM 1998 , ~I.2.7 
 Russell & Norvig 2003 , pp. 568–578  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
 Object recognition :
 Russell & Norvig 2003 , pp. 885–892  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
 Computer vision :
 ACM 1998 , I.2.10 
 Russell & Norvig 2003 , pp. 863–898  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Nilsson 1998 , chpt. 6 
 
 ^   
 Robotics :
 ACM 1998 , I.2.9, 
 Russell & Norvig 2003 , pp. 901–942  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 443–460 
 
 ^  a   b   
Moving and  configuration space :
 Russell & Norvig 2003 , pp. 916–932  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^  a   b   Tecuci 2012 . 
 
 ^   
 Robotic mapping  (localization, etc):
 Russell & Norvig 2003 , pp. 908–915  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   Cadena, Cesar; Carlone, Luca; Carrillo, Henry; Latif, Yasir; Scaramuzza, Davide; Neira, Jose; Reid, Ian; Leonard, John J. (December 2016). "Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age".  IEEE Transactions on Robotics .  32  (6): 1309–1332.  arXiv : 1606.05830 .  Bibcode : 2016arXiv160605830C .  doi : 10.1109/TRO.2016.2624754 . 
 
 ^   Moravec, Hans  (1988).  Mind Children . Harvard University Press. p. 15. 
 
 ^   Chan, Szu Ping (15 November 2015).  "This is what will happen when robots take over the world" . Retrieved  23 April  2018 . 
 
 ^  a   b   "IKEA furniture and the limits of AI" .  The Economist . 2018 . Retrieved  24 April  2018 . 
 
 ^   Kismet . 
 
 ^   Thompson, Derek (2018).  "What Jobs Will the Robots Take?" .  The Atlantic . Retrieved  24 April  2018 . 
 
 ^   Scassellati, Brian (2002). "Theory of mind for a humanoid robot".  Autonomous Robots .  12  (1): 13–24.  doi : 10.1023/A:1013298507114 . 
 
 ^   Cao, Yongcan; Yu, Wenwu; Ren, Wei; Chen, Guanrong (February 2013). "An Overview of Recent Progress in the Study of Distributed Multi-Agent Coordination".  IEEE Transactions on Industrial Informatics .  9  (1): 427–438.  arXiv : 1207.3231 .  doi : 10.1109/TII.2012.2219061 . 
 
 ^   Thro 1993 . 
 
 ^   Edelson 1991 . 
 
 ^   Tao & Tan 2005 . 
 
 ^   Poria, Soujanya; Cambria, Erik; Bajpai, Rajiv; Hussain, Amir (September 2017). "A review of affective computing: From unimodal analysis to multimodal fusion".  Information Fusion .  37 : 98–125.  doi : 10.1016/j.inffus.2017.02.003 .  hdl : 1893/25490 . 
 
 ^   
Emotion and  affective computing :
 Minsky 2006 
 
 ^   Waddell, Kaveh (2018).  "Chatbots Have Entered the Uncanny Valley" .  The Atlantic . Retrieved  24 April  2018 . 
 
 ^   Pennachin, C.; Goertzel, B. (2007).  Contemporary Approaches to  Artificial  General  Intelligence .  Artificial  General  Intelligence . Cognitive Technologies . Cognitive Technologies. Berlin, Heidelberg: Springer.  doi : 10.1007/978-3-540-68677-4_1 .  ISBN   978-3-540-23733-4 . 
 
 ^  a   b   c   Roberts, Jacob (2016).  "Thinking Machines: The Search for  Artificial   Intelligence " .  Distillations . Vol. 2 no. 2. pp. 14–23. Archived from  the original  on 19 August 2018 . Retrieved  20 March  2018 . 
 
 ^   "The superhero of  artificial   intelligence : can this genius keep it in check?" .  the Guardian . 16 February 2016 . Retrieved  26 April  2018 . 
 
 ^   Mnih, Volodymyr; Kavukcuoglu, Koray; Silver, David; Rusu, Andrei A.; Veness, Joel; Bellemare, Marc G.; Graves, Alex; Riedmiller, Martin; Fidjeland, Andreas K.; Ostrovski, Georg; Petersen, Stig; Beattie, Charles; Sadik, Amir; Antonoglou, Ioannis; King, Helen; Kumaran, Dharshan; Wierstra, Daan; Legg, Shane; Hassabis, Demis (26 February 2015). "Human-level control through deep reinforcement learning".  Nature .  518  (7540): 529–533.  Bibcode : 2015Natur.518..529M .  doi : 10.1038/nature14236 .  PMID   25719670 . 
 
 ^   Sample, Ian (14 March 2017).  "Google's DeepMind makes AI program that can learn like a human" .  the Guardian . Retrieved  26 April  2018 . 
 
 ^   "From not working to neural networking" .  The Economist . 2016 . Retrieved  26 April  2018 . 
 
 ^   Domingos 2015 . 
 
 ^  a   b   
 Artificial  brain  arguments: AI requires a simulation of the operation of the human brain
 Russell & Norvig 2003 , p. 957  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Crevier 1993 , pp. 271 and 279  harvnb error: no target: CITEREFCrevier1993 ( help ) 
A few of the people who make some form of the argument:
 Moravec 1988  harvnb error: multiple targets (2×): CITEREFMoravec1988 ( help ) 
 Kurzweil 2005 , p. 262 
 Hawkins & Blakeslee 2005 
The most extreme form of this argument (the brain replacement scenario) was put forward by  Clark Glymour  in the mid-1970s and was touched on by  Zenon Pylyshyn  and  John Searle  in 1980. 
 
 ^   Goertzel, Ben; Lian, Ruiting; Arel, Itamar; de Garis, Hugo; Chen, Shuo (December 2010). "A world survey of  artificial  brain projects, Part II: Biologically inspired cognitive architectures".  Neurocomputing .  74  (1–3): 30–49.  doi : 10.1016/j.neucom.2010.08.012 . 
 
 ^   Nils Nilsson  writes: "Simply put, there is wide disagreement in the field about what AI is all about" ( Nilsson 1983 , p. 10). 
 
 ^   
AI's immediate precursors:
 McCorduck 2004 , pp. 51–107  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , pp. 27–32  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 Russell & Norvig 2003 , pp. 15, 940  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Moravec 1988 , p. 3  harvnb error: multiple targets (2×): CITEREFMoravec1988 ( help ) 
 
 ^   
 Haugeland 1985 , pp. 112–117 
 
 ^   The most dramatic case of sub-symbolic AI being pushed into the background was the devastating critique of  perceptrons  by  Marvin Minsky  and  Seymour Papert  in 1969. See  History of AI ,  AI winter , or  Frank Rosenblatt . 
 
 ^   
Cognitive simulation,  Newell  and  Simon , AI at  CMU  (then called  Carnegie Tech ):
 McCorduck 2004 , pp. 139–179, 245–250, 322–323 (EPAM)  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , pp. 145–149  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 
 ^   
 Soar  (history):
 McCorduck 2004 , pp. 450–451  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , pp. 258–263  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 
 ^   
 McCarthy  and AI research at  SAIL  and  SRI International :
 McCorduck 2004 , pp. 251–259  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 
 ^   
AI research at  Edinburgh  and in France, birth of  Prolog :
 Crevier 1993 , pp. 193–196  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 Howe 1994 
 
 ^   
AI at  MIT  under  Marvin Minsky  in the 1960s :
 McCorduck 2004 , pp. 259–305  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , pp. 83–102, 163–176  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 Russell & Norvig 2003 , p. 19  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
 Cyc :
 McCorduck 2004 , p. 489  harvnb error: no target: CITEREFMcCorduck2004 ( help ) , who calls it "a determinedly scruffy enterprise" 
 Crevier 1993 , pp. 239–243  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 Russell & Norvig 2003 , p. 363−365  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Lenat & Guha 1989 
 
 ^   
Knowledge revolution:
 McCorduck 2004 , pp. 266–276, 298–300, 314, 421  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Russell & Norvig 2003 , pp. 22–23  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   Frederick, Hayes-Roth; William, Murray; Leonard, Adelman. "Expert systems".  AccessScience .  doi : 10.1036/1097-8542.248550 . 
 
 ^   
 Embodied  approaches to AI:
 McCorduck 2004 , pp. 454–462  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Brooks 1990 
 Moravec 1988  harvnb error: multiple targets (2×): CITEREFMoravec1988 ( help ) 
 
 ^   Weng et al. 2001 . 
 
 ^   Lungarella et al. 2003 . 
 
 ^   Asada et al. 2009 . 
 
 ^   Oudeyer 2010 . 
 
 ^   
Revival of  connectionism :
 Crevier 1993 , pp. 214–215  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 Russell & Norvig 2003 , p. 25  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
 Computational  intelligence 
 IEEE Computational  Intelligence  Society   Archived  9 May 2008 at the  Wayback Machine 
 
 ^   Hutson, Matthew (16 February 2018).  " Artificial   intelligence  faces reproducibility crisis" .  Science . pp. 725–726.  Bibcode : 2018Sci...359..725H .  doi : 10.1126/science.359.6377.725 . Retrieved  28 April  2018 . 
 
 ^   Norvig 2012 . 
 
 ^   Langley 2011 . 
 
 ^   Katz 2012 . 
 
 ^   
The  intelligent agent  paradigm:
 Russell & Norvig 2003 , pp. 27, 32–58, 968–972  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Poole, Mackworth & Goebel 1998 , pp. 7–21 
 Luger & Stubblefield 2004 , pp. 235–240 
 Hutter 2005 , pp. 125–126 
The definition used in this article, in terms of goals, actions, perception and environment, is due to  Russell & Norvig (2003)  harvtxt error: no target: CITEREFRussellNorvig2003 ( help ) . Other definitions also include knowledge and learning as additional criteria. 
 
 ^   
 Agent architectures ,  hybrid intelligent systems :
 Russell & Norvig (2003 , pp. 27, 932, 970–972)  harvtxt error: no target: CITEREFRussellNorvig2003 ( help ) 
 Nilsson (1998 , chpt. 25) 
 
 ^   
 Hierarchical control system :
 Albus 2002 
 
 ^   Laird, John (2008). "Extending the Soar cognitive architecture".  Frontiers in  Artificial   Intelligence  and Applications .  171 : 224.  CiteSeerX   10.1.1.77.2473 . 
 
 ^   Lieto, Antonio; Lebiere, Christian; Oltramari, Alessandro (May 2018). "The knowledge level in cognitive architectures: Current limitations and possibile developments".  Cognitive Systems Research .  48 : 39–55.  doi : 10.1016/j.cogsys.2017.05.001 .  hdl : 2318/1665207 . 
 
 ^   Lieto, Antonio; Bhatt, Mehul; Oltramari, Alessandro; Vernon, David (May 2018). "The role of cognitive architectures in general  artificial   intelligence ".  Cognitive Systems Research .  48 : 1–3.  doi : 10.1016/j.cogsys.2017.08.003 .  hdl : 2318/1665249 . 
 
 ^   
 Search algorithms :
 Russell & Norvig 2003 , pp. 59–189  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Poole, Mackworth & Goebel 1998 , pp. 113–163 
 Luger & Stubblefield 2004 , pp. 79–164, 193–219 
 Nilsson 1998 , chpt. 7–12 
 
 ^   
 Forward chaining ,  backward chaining ,  Horn clauses , and logical deduction as search:
 Russell & Norvig 2003 , pp. 217–225, 280–294  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Poole, Mackworth & Goebel 1998 , pp. ~46–52 
 Luger & Stubblefield 2004 , pp. 62–73 
 Nilsson 1998 , chpt. 4.2, 7.2 
 
 ^   
 State space search  and  planning :
 Russell & Norvig 2003 , pp. 382–387  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Poole, Mackworth & Goebel 1998 , pp. 298–305 
 Nilsson 1998 , chpt. 10.1–2 
 
 ^   
Uninformed searches ( breadth first search ,  depth first search  and general  state space search ):
 Russell & Norvig 2003 , pp. 59–93  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Poole, Mackworth & Goebel 1998 , pp. 113–132 
 Luger & Stubblefield 2004 , pp. 79–121 
 Nilsson 1998 , chpt. 8 
 
 ^   
 Heuristic  or informed searches (e.g., greedy  best first  and  A* ):
 Russell & Norvig 2003 , pp. 94–109  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. pp. 132–147, 
 Luger & Stubblefield 2004 , pp. 133–150, 
 Nilsson 1998 , chpt. 9, 
 Poole & Mackworth 2017 , Section 3.6 
 
 ^   
 Optimization  searches:
 Russell & Norvig 2003 , pp. 110–116,120–129  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Poole, Mackworth & Goebel 1998 , pp. 56–163 
 Luger & Stubblefield 2004 , pp. 127–133 
 
 ^   
 Genetic programming  and  genetic algorithms :
 Luger & Stubblefield 2004 , pp. 509–530, 
 Nilsson 1998 , chpt. 4.2, 
 Holland 1975 , 
 Koza 1992 , 
 Poli, Langdon & McPhee 2008 . 
 
 ^   
 Artificial  life  and society based learning:
 Luger & Stubblefield 2004 , pp. 530–541 
 
 ^   Daniel Merkle; Martin Middendorf (2013). "Swarm  Intelligence ".  In Burke, Edmund K.; Kendall, Graham (eds.).  Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques . Springer Science & Business Media.  ISBN   978-1-4614-6940-7 . 
 
 ^   
 Logic :
 ACM 1998 , ~I.2.3, 
 Russell & Norvig 2003 , pp. 194–310  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Luger & Stubblefield 2004 , pp. 35–77, 
 Nilsson 1998 , chpt. 13–16 
 
 ^   
 Satplan :
 Russell & Norvig 2003 , pp. 402–407  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 300–301, 
 Nilsson 1998 , chpt. 21 
 
 ^   
 Explanation based learning , relevance based learning,  inductive logic programming ,  case based reasoning :
 Russell & Norvig 2003 , pp. 678–710  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 414–416, 
 Luger & Stubblefield 2004 , pp. ~422–442, 
 Nilsson 1998 , chpt. 10.3, 17.5 
 
 ^   
 Propositional logic :
 Russell & Norvig 2003 , pp. 204–233  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Luger & Stubblefield 2004 , pp. 45–50 
 Nilsson 1998 , chpt. 13 
 
 ^   
 First-order logic  and features such as  equality :
 ACM 1998 , ~I.2.4, 
 Russell & Norvig 2003 , pp. 240–310  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 268–275, 
 Luger & Stubblefield 2004 , pp. 50–62, 
 Nilsson 1998 , chpt. 15 
 
 ^   Elkan, Charles (1994). "The paradoxical success of fuzzy logic".  IEEE Expert .  9  (4): 3–49.  CiteSeerX   10.1.1.100.8402 .  doi : 10.1109/64.336150 . 
 
 ^   
 Fuzzy logic :
 Russell & Norvig 2003 , pp. 526–527  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   "What is 'fuzzy logic'? Are there computers that are inherently fuzzy and do not apply the usual binary logic?" .  Scientific American . Retrieved  5 May  2018 . 
 
 ^   "The Belief Calculus and Uncertain Reasoning", Yen-Teh Hsia 
 
 ^   
Stochastic methods for uncertain reasoning:
 ACM 1998 , ~I.2.3, 
 Russell & Norvig 2003 , pp. 462–644  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 345–395, 
 Luger & Stubblefield 2004 , pp. 165–191, 333–381, 
 Nilsson 1998 , chpt. 19 
 
 ^   
 Bayesian networks :
 Russell & Norvig 2003 , pp. 492–523  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 361–381, 
 Luger & Stubblefield 2004 , pp. ~182–190, ≈363–379, 
 Nilsson 1998 , chpt. 19.3–4 
 
 ^   
 Bayesian inference  algorithm:
 Russell & Norvig 2003 , pp. 504–519  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 361–381, 
 Luger & Stubblefield 2004 , pp. ~363–379, 
 Nilsson 1998 , chpt. 19.4 & 7 
 
 ^   Domingos 2015 , p. 210. 
 
 ^   
 Bayesian learning  and the  expectation-maximization algorithm :
 Russell & Norvig 2003 , pp. 712–724  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 424–433, 
 Nilsson 1998 , chpt. 20 
 
 ^   
 Bayesian decision theory  and Bayesian  decision networks :
 Russell & Norvig 2003 , pp. 597–600  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^  a   b   c   
Stochastic temporal models:
 Russell & Norvig 2003 , pp. 537–581  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Dynamic Bayesian networks :
 Russell & Norvig 2003 , pp. 551–557  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Hidden Markov model :
 ( Russell & Norvig 2003 , pp. 549–551)  harv error: no target: CITEREFRussellNorvig2003 ( help ) 
 Kalman filters :
 Russell & Norvig 2003 , pp. 551–557  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   Domingos 2015 , chapter 6. 
 
 ^   
 decision theory  and  decision analysis :
 Russell & Norvig 2003 , pp. 584–597  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 381–394 
 
 ^   
 Markov decision processes  and dynamic  decision networks :
 Russell & Norvig 2003 , pp. 613–631  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
 Game theory  and  mechanism design :
 Russell & Norvig 2003 , pp. 631–643  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
Statistical learning methods and  classifiers :
 Russell & Norvig 2003 , pp. 712–754  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Luger & Stubblefield 2004 , pp. 453–541 
 
 ^   
 Decision tree :
 Russell & Norvig 2003 , pp. 653–664  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 403–408, 
 Luger & Stubblefield 2004 , pp. 408–417 
 
 ^   Domingos 2015 , p. 88. 
 
 ^  a   b   
Neural networks and connectionism:
 Russell & Norvig 2003 , pp. 736–748  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Poole, Mackworth & Goebel 1998 , pp. 408–414, 
 Luger & Stubblefield 2004 , pp. 453–505, 
 Nilsson 1998 , chpt. 3 
 
 ^   Domingos 2015 , p. 187. 
 
 ^   
 K-nearest neighbor algorithm :
 Russell & Norvig 2003 , pp. 733–736  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   Domingos 2015 , p. 188. 
 
 ^   
 kernel methods  such as the  support vector machine :
 Russell & Norvig 2003 , pp. 749–752  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
 Gaussian mixture model :
 Russell & Norvig 2003 , pp. 725–727  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   Domingos 2015 , p. 152. 
 
 ^   
 Naive Bayes classifier :
 Russell & Norvig 2003 , p. 718  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
Classifier performance:
 van der Walt & Bernard 2006 
 
 ^   Russell & Norvig 2009 , 18.12: Learning from Examples: Summary. 
 
 ^   Domingos 2015 , Chapter 4. 
 
 ^   "Why Deep Learning Is Suddenly Changing Your Life" .  Fortune . 2016 . Retrieved  12 March  2018 . 
 
 ^   "Google leads in the race to dominate  artificial   intelligence " .  The Economist . 2017 . Retrieved  12 March  2018 . 
 
 ^   
 Feedforward neural networks ,  perceptrons  and  radial basis networks :
 Russell & Norvig 2003 , pp. 739–748, 758  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Luger & Stubblefield 2004 , pp. 458–467 
 
 ^   
 Competitive learning ,  Hebbian  coincidence learning,  Hopfield networks  and attractor networks:
 Luger & Stubblefield 2004 , pp. 474–505 
 
 ^   Seppo Linnainmaa  (1970). The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors. Master's Thesis (in Finnish), Univ. Helsinki, 6–7. 
 
 ^   Griewank, Andreas (2012). Who Invented the Reverse Mode of Differentiation?. Optimization Stories, Documenta Matematica, Extra Volume ISMP (2012), 389–400. 
 
 ^   Paul Werbos , "Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences",  PhD thesis, Harvard University , 1974. 
 
 ^   Paul Werbos  (1982). Applications of advances in nonlinear sensitivity analysis. In System modeling and optimization (pp. 762–770). Springer Berlin Heidelberg.  Online   Archived  14 April 2016 at the  Wayback Machine 
 
 ^   
 Backpropagation :
 Russell & Norvig 2003 , pp. 744–748  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 Luger & Stubblefield 2004 , pp. 467–474, 
 Nilsson 1998 , chpt. 3.3 
 
 ^   
 Hierarchical temporal memory :
 Hawkins & Blakeslee 2005 
 
 ^   " Artificial   intelligence  can 'evolve' to solve problems" .  Science | AAAS . 10 January 2018 . Retrieved  7 February  2018 . 
 
 ^  a   b   Ian Goodfellow, Yoshua Bengio, and Aaron Courville (2016). Deep Learning. MIT Press.  Online   Archived  16 April 2016 at the  Wayback Machine 
 
 ^   Hinton, G.; Deng, L.; Yu, D.; Dahl, G.; Mohamed, A.; Jaitly, N.; Senior, A.; Vanhoucke, V.; Nguyen, P.; Sainath, T.; Kingsbury, B. (2012). "Deep Neural Networks for Acoustic Modeling in Speech Recognition – The shared views of four research groups".  IEEE Signal Processing Magazine .  29  (6): 82–97.  Bibcode : 2012ISPM...29...82H .  doi : 10.1109/msp.2012.2205597 . 
 
 ^  a   b   c   Schmidhuber, J. (2015). "Deep Learning in Neural Networks: An Overview".  Neural Networks .  61 : 85–117.  arXiv : 1404.7828 .  doi : 10.1016/j.neunet.2014.09.003 .  PMID   25462637 . 
 
 ^   Schmidhuber, Jürgen  (2015).  "Deep Learning" .  Scholarpedia .  10  (11): 32832.  Bibcode : 2015SchpJ..1032832S .  doi : 10.4249/scholarpedia.32832 . 
 
 ^   Rina Dechter  (1986). Learning while searching in constraint-satisfaction problems. University of California, Computer Science Department, Cognitive Systems Laboratory. Online   Archived  19 April 2016 at the  Wayback Machine 
 
 ^   Igor Aizenberg, Naum N. Aizenberg, Joos P.L. Vandewalle (2000). Multi-Valued and Universal Binary Neurons: Theory, Learning and Applications. Springer Science & Business Media. 
 
 ^   Ivakhnenko, Alexey (1965).  Cybernetic Predicting Devices . Kiev: Naukova Dumka. 
 
 ^   Ivakhnenko, A. G. (1971). "Polynomial Theory of Complex Systems".  IEEE Transactions on Systems, Man, and Cybernetics  (4): 364–378.  doi : 10.1109/TSMC.1971.4308320 .  S2CID   17606980 . 
 
 ^   Hinton 2007 . 
 
 ^   Fukushima, K. (1980). "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position".  Biological Cybernetics .  36  (4): 193–202.  doi : 10.1007/bf00344251 .  PMID   7370364 . 
 
 ^   Yann LeCun  (2016). Slides on Deep Learning  Online   Archived  23 April 2016 at the  Wayback Machine 
 
 ^   Silver, David ; Schrittwieser, Julian; Simonyan, Karen; Antonoglou, Ioannis;  Huang, Aja ; Guez, Arthur; Hubert, Thomas; Baker, Lucas; Lai, Matthew; Bolton, Adrian;  Chen, Yutian ; Lillicrap, Timothy;  Fan, Hui ; Sifre, Laurent; Driessche, George van den; Graepel, Thore;  Hassabis, Demis  (19 October 2017).  "Mastering the game of Go without human knowledge"   (PDF) .  Nature .  550  (7676): 354–359.  Bibcode : 2017Natur.550..354S .  doi : 10.1038/nature24270 .  ISSN   0028-0836 .  PMID   29052630 .  AlphaGo Lee... 12 convolutional layers 
 
 ^   
 Recurrent neural networks ,  Hopfield nets :
 Russell & Norvig 2003 , p. 758  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 Luger & Stubblefield 2004 , pp. 474–505 
 
 ^   Hyötyniemi, Heikki (1996). "Turing machines are recurrent neural networks".  Proceedings of STeP '96/Publications of the Finnish  Artificial   Intelligence  Society : 13–24. 
 
 ^   P. J. Werbos. Generalization of backpropagation with application to a recurrent gas market model"  Neural Networks  1, 1988. 
 
 ^   A. J. Robinson and F. Fallside. The utility driven dynamic error propagation network. Technical Report CUED/F-INFENG/TR.1, Cambridge University Engineering Department, 1987. 
 
 ^   R. J. Williams and D. Zipser. Gradient-based learning algorithms for recurrent networks and their computational complexity. In Back-propagation: Theory, Architectures and Applications. Hillsdale, NJ: Erlbaum, 1994. 
 
 ^   Sepp Hochreiter  (1991),  Untersuchungen zu dynamischen neuronalen Netzen   Archived  6 March 2015 at the  Wayback Machine , Diploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber. 
 
 ^   Schmidhuber, J. (1992). "Learning complex, extended sequences using the principle of history compression".  Neural Computation .  4  (2): 234–242.  CiteSeerX   10.1.1.49.3934 .  doi : 10.1162/neco.1992.4.2.234 . 
 
 ^   Hochreiter, Sepp ; and  Schmidhuber, Jürgen ;  Long Short-Term Memory , Neural Computation, 9(8):1735–1780, 1997 
 
 ^   Alex Graves, Santiago Fernandez, Faustino Gomez, and  Jürgen Schmidhuber  (2006). Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural nets. Proceedings of ICML'06, pp. 369–376. 
 
 ^   Hannun, Awni; Case, Carl; Casper, Jared; Catanzaro, Bryan; Diamos, Greg; Elsen, Erich; Prenger, Ryan; Satheesh, Sanjeev; Sengupta, Shubho; Coates, Adam;  Ng, Andrew Y.  (2014). "Deep Speech: Scaling up end-to-end speech recognition".  arXiv : 1412.5567  [ cs.CL ]. 
 
 ^   Hasim Sak and Andrew Senior and Francoise Beaufays (2014). Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling. Proceedings of Interspeech 2014. 
 
 ^   Li, Xiangang; Wu, Xihong (2015). "Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition".  arXiv : 1410.4281  [ cs.CL ]. 
 
 ^   Haşim Sak, Andrew Senior, Kanishka Rao, Françoise Beaufays and Johan Schalkwyk (September 2015):  Google voice search: faster and more accurate.   Archived  9 March 2016 at the  Wayback Machine 
 
 ^   Sutskever, Ilya; Vinyals, Oriol; Le, Quoc V. (2014). "Sequence to Sequence Learning with Neural Networks".  arXiv : 1409.3215  [ cs.CL ]. 
 
 ^   Jozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016). "Exploring the Limits of Language Modeling".  arXiv : 1602.02410  [ cs.CL ]. 
 
 ^   Gillick, Dan; Brunk, Cliff; Vinyals, Oriol; Subramanya, Amarnag (2015). "Multilingual Language Processing From Bytes".  arXiv : 1512.00103  [ cs.CL ]. 
 
 ^   Vinyals, Oriol; Toshev, Alexander; Bengio, Samy; Erhan, Dumitru (2015). "Show and Tell: A Neural Image Caption Generator".  arXiv : 1411.4555  [ cs.CV ]. 
 
 ^   Brynjolfsson, Erik; Mitchell, Tom (22 December 2017).  "What can machine learning do? Workforce implications" .  Science . pp. 1530–1534.  Bibcode : 2017Sci...358.1530B .  doi : 10.1126/science.aap8062 . Retrieved  7 May  2018 . 
 
 ^   Sample, Ian (18 October 2017).  " ' It's able to create knowledge itself': Google unveils AI that learns on its own" .  the Guardian . Retrieved  7 May  2018 . 
 
 ^   "The AI revolution in science" .  Science | AAAS . 5 July 2017 . Retrieved  7 May  2018 . 
 
 ^   "Will your job still exist in 10 years when the robots arrive?" .  South China Morning Post . 2017 . Retrieved  7 May  2018 . 
 
 ^   Borowiec, Tracey Lien, Steven (2016).  "AlphaGo beats human Go champ in milestone for  artificial   intelligence " .  latimes.com . Retrieved  7 May  2018 . 
 
 ^   Brown, Noam; Sandholm, Tuomas (26 January 2018).  "Superhuman AI for heads-up no-limit poker: Libratus beats top professionals" .  Science . pp. 418–424.  doi : 10.1126/science.aao1733 . Retrieved  7 May  2018 . 
 
 ^   Ontanon, Santiago; Synnaeve, Gabriel; Uriarte, Alberto; Richoux, Florian; Churchill, David; Preuss, Mike (December 2013). "A Survey of Real-Time Strategy Game AI Research and Competition in StarCraft".  IEEE Transactions on Computational  Intelligence  and AI in Games .  5  (4): 293–311.  CiteSeerX   10.1.1.406.2524 .  doi : 10.1109/TCIAIG.2013.2286295 . 
 
 ^   "Facebook Quietly Enters StarCraft War for AI Bots, and Loses" .  WIRED . 2017 . Retrieved  7 May  2018 . 
 
 ^   "ILSVRC2017" .  image-net.org . Retrieved  6 November  2018 . 
 
 ^   Schoenick, Carissa; Clark, Peter; Tafjord, Oyvind; Turney, Peter; Etzioni, Oren (23 August 2017). "Moving beyond the Turing Test with the Allen AI Science Challenge".  Communications of the ACM .  60  (9): 60–64.  arXiv : 1604.04315 .  doi : 10.1145/3122814 . 
 
 ^   O'Brien & Marakas 2011 . 
 
 ^   
Mathematical definitions of  intelligence :
 Hernandez-Orallo 2000 
 Dowe & Hajek 1997 
 Hernandez-Orallo & Dowe 2010 
 
 ^   Hernández-Orallo, José; Dowe, David L.; Hernández-Lloreda, M.Victoria (March 2014). "Universal psychometrics: Measuring cognitive abilities in the machine kingdom".  Cognitive Systems Research .  27 : 50–74.  doi : 10.1016/j.cogsys.2013.06.001 .  hdl : 10251/50244 . 
 
 ^   Research, AI (23 October 2015).  "Deep Neural Networks for Acoustic Modeling in Speech Recognition" .  airesearch.com . Retrieved  23 October  2015 . 
 
 ^   "GPUs Continue to Dominate the AI Accelerator Market for Now" .  InformationWeek . December 2019 . Retrieved  11 June  2020 . 
 
 ^   Ray, Tiernan (2019).  "AI is changing the entire nature of compute" .  ZDNet . Retrieved  11 June  2020 . 
 
 ^   "AI and Compute" .  OpenAI . 16 May 2018 . Retrieved  11 June  2020 . 
 
 ^  a   b   Russell & Norvig 2009 , p. 1. 
 
 ^  a   b   White Paper: On  Artificial   Intelligence  - A European approach to excellence and trust   (PDF) . Brussels: European Commission. 2020. p. 1. 
 
 ^   CNN  2006 . 
 
 ^   Using AI to predict flight delays , Ishti.org. 
 
 ^   N. Aletras; D. Tsarapatsanis; D. Preotiuc-Pietro; V. Lampos (2016).  "Predicting judicial decisions of the European Court of Human Rights: a Natural Language Processing perspective" .  PeerJ Computer Science .  2 : e93.  doi : 10.7717/peerj-cs.93 . 
 
 ^   "The Economist Explains: Why firms are piling into  artificial   intelligence " .  The Economist . 31 March 2016.  Archived  from the original on 8 May 2016 . Retrieved  19 May  2016 . 
 
 ^   Lohr, Steve (28 February 2016).  "The Promise of  Artificial   Intelligence  Unfolds in Small Steps" .  The New York Times .  Archived  from the original on 29 February 2016 . Retrieved  29 February  2016 . 
 
 ^   Frangoul, Anmar (14 June 2019).  "A Californian business is using A.I. to change the way we think about energy storage" .  CNBC . Retrieved  5 November  2019 . 
 
 ^   Wakefield, Jane (15 June 2016).  "Social media 'outstrips TV' as news source for young people" .  BBC News .  Archived  from the original on 24 June 2016. 
 
 ^   Smith, Mark (22 July 2016).  "So you think you chose to read this article?" .  BBC News .  Archived  from the original on 25 July 2016. 
 
 ^   Brown, Eileen.  "Half of Americans do not believe deepfake news could target them online" .  ZDNet . Retrieved  3 December  2019 . 
 
 ^   "10 Promising AI Applications in Health Care" .  Harvard Business Review . 10 May 2018. Archived from  the original  on 15 December 2018 . Retrieved  28 August  2018 . 
 
 ^   Dina Bass (20 September 2016).  "Microsoft Develops AI to Help Cancer Doctors Find the Right Treatments" .  Bloomberg.com . Bloomberg.  Archived  from the original on 11 May 2017. 
 
 ^   Gallagher, James (26 January 2017).  " Artificial   intelligence  'as good as cancer doctors ' " .  BBC News .  Archived  from the original on 26 January 2017 . Retrieved  26 January  2017 . 
 
 ^   Langen, Pauline A.; Katz, Jeffrey S.; Dempsey, Gayle, eds. (18 October 1994),  Remote monitoring of high-risk patients using  artificial   intelligence ,  archived  from the original on 28 February 2017 , retrieved  27 February  2017 
 
 ^   Kermany, D; Goldbaum, M; Zhang, Kang (2018).  "Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning"   (PDF) .  Cell .  172  (5): 1122–1131.e9.  doi : 10.1016/j.cell.2018.02.010 .  PMID   29474911 . Retrieved  18 December  2018 . 
 
 ^   Senthilingam, Meera (12 May 2016).  "Are Autonomous Robots Your next Surgeons?" .  CNN . Cable News Network.  Archived  from the original on 3 December 2016 . Retrieved  4 December  2016 . 
 
 ^   "Full Page Reload" .  IEEE Spectrum: Technology, Engineering, and Science News . Retrieved  3 September  2019 . 
 
 ^   "33 Corporations Working On Autonomous Vehicles". CB Insights. N.p., 11 August 2016. 12 November 2016. 
 
 ^   West, Darrell M. "Moving forward: Self-driving vehicles in China, Europe, Japan, Korea, and the United States". Center for Technology Innovation at Brookings. N.p., September 2016. 12 November 2016. 
 
 ^   Burgess, Matt (24 August 2017).  "The UK is about to Start Testing Self-Driving Truck Platoons" .  Wired UK .  Archived  from the original on 22 September 2017 . Retrieved  20 September  2017 . 
 
 ^   Davies, Alex (5 May 2015).  "World's First Self-Driving Semi-Truck Hits the Road" .  WIRED .  Archived  from the original on 28 October 2017 . Retrieved  20 September  2017 . 
 
 ^   McFarland, Matt. "Google's  artificial   intelligence  breakthrough may have a huge impact on self-driving cars and much more".  The Washington Post  25 February 2015. Infotrac Newsstand. 24 October 2016 
 
 ^   "Programming safety into self-driving cars". National Science Foundation. N.p., 2 February 2015. 24 October 2016. 
 
 ^   ArXiv, E. T. (26 October 2015). Why Self-Driving Cars Must Be Programmed to Kill. Retrieved 17 November 2017, from  https://www.technologyreview.com/s/542626/why-self-driving-cars-must-be-programmed-to-kill/ [ permanent dead link ] 
 
 ^   Christy, Charles A. (17 January 1990).  "Impact of  Artificial   Intelligence  on Banking" .  latimes.com . Retrieved  10 September  2019 . 
 
 ^   O'Neill, Eleanor (31 July 2016).  "Accounting, automation and AI" .  icas.com .  Archived  from the original on 18 November 2016 . Retrieved  18 November  2016 . 
 
 ^   Robots Beat Humans in Trading Battle.   Archived  9 September 2009 at the  Wayback Machine  BBC.com (8 August 2001) 
 
 ^   "CTO Corner:  Artificial   Intelligence  Use in Financial Services – Financial Services Roundtable" .  Financial Services Roundtable . 2 April 2015. Archived from  the original  on 18 November 2016 . Retrieved  18 November  2016 . 
 
 ^   " Artificial   Intelligence  Solutions, AI Solutions" .  www.sas.com . 
 
 ^   Chapman, Lizette (7 January 2019).  "Palantir once mocked the idea of salespeople. Now it's hiring them" .  latimes.com . Retrieved  28 February  2019 . 
 
 ^   Pham, Sherisse (24 April 2017).  "Jack Ma: In 30 years, the best CEO could be a robot" .  CNNMoney . 
 
 ^   "Can't find a perfect CEO? Create an AI one yourself" . 22 October 2016. 
 
 ^   Marwala, Tshilidzi; Hurwitz, Evan (2017).  Artificial   Intelligence  and Economic Theory: Skynet in the Market . London:  Springer .  ISBN   978-3-319-66104-9 . 
 
 ^   "Miles Education | Future Of Finance | Blockchain Fundamentals for F&A Professionals Certificate" .  www.mileseducation.com . Archived from  the original  on 26 September 2019 . Retrieved  26 September  2019 . 
 
 ^   Buckley, Chris; Mozur, Paul (22 May 2019).  "How China Uses High-Tech Surveillance to Subdue Minorities" .  The New York Times . 
 
 ^   "Security lapse exposed a Chinese smart city surveillance system" . 
 
 ^   "AI traffic signals to be installed in Bengaluru soon" .  NextBigWhat . 24 September 2019 . Retrieved  1 October  2019 . 
 
 ^   Croft, Jane (2 May 2019).  "AI learns to read Korean, so you don't have to" .  Financial Times . Retrieved  19 December  2019 . 
 
 ^   "Why AI researchers like video games" .  The Economist .  Archived  from the original on 5 October 2017. 
 
 ^   Yannakakis, G. N. (2012, May). Game AI revisited. In Proceedings of the 9th conference on Computing Frontiers (pp. 285–292). ACM. 
 
 ^  a   b   c   Congressional Research Service (2019).  Artificial   Intelligence  and National Security   (PDF) . Washington, DC: Congressional Research Service. PD-notice 
 
 ^  a   b   Slyusar, Vadym (2019).  " Artificial   intelligence  as the basis of future control networks" .  Preprint . 
 
 ^   "Getting to grips with military robotics" .  The Economist . 25 January 2018 . Retrieved  7 February  2018 . 
 
 ^   "Autonomous Systems: Infographic" .  siemens.com . Retrieved  7 February  2018 . 
 
 ^   Allen, Gregory (6 February 2019).  "Understanding China's AI Strategy" .  www.cnas.org/publications/reports/understanding-chinas-ai-strategy . Center for a New American Security. Archived from  the original  on 17 March 2019 . Retrieved  17 March  2019 . 
 
 ^   Metz, Cade (15 March 2018).  "Pentagon Wants Silicon Valley's Help on A.I."   The New York Times . Retrieved  19 March  2018 . 
 
 ^   "Role of AI in travel and Hospitality Industry"   (PDF) .  Infosys . 2018 . Retrieved  14 January  2020 . 
 
 ^   "Advanced analytics in hospitality" .  McKinsey & Company . 2017 . Retrieved  14 January  2020 . 
 
 ^   "Current applications of  Artificial   Intelligence  in tourism and hospitality" .  Sinteza . 2019 . Retrieved  14 January  2020 . 
 
 ^   Chang, Hsihui; Kao, Yi-Ching; Mashruwala, Raj; Sorensen, Susan M. (10 April 2017). "Technical Inefficiency, Allocative Inefficiency, and Audit Pricing".  Journal of Accounting, Auditing & Finance .  33  (4): 580–600.  doi : 10.1177/0148558X17696760 . 
 
 ^   Matz, S. C., et al. "Psychological targeting as an effective approach to digital mass persuasion." Proceedings of the National Academy of Sciences (2017): 201710966. 
 
 ^   Busby, Mattha (30 April 2018).  "Revealed: how bookies use AI to keep gamblers hooked" .  the Guardian . 
 
 ^   Celli, Fabio, Pietro Zani Massani, and Bruno Lepri. "Profilio: Psychometric Profiling to Boost Social Media Advertising." Proceedings of the 2017 ACM on Multimedia Conference. ACM, 2017   [1] 
 
 ^   "Thinking Machines: Art and Design in the Computer Age, 1959–1989" .  The Museum of Modern Art . Retrieved  23 July  2019 . 
 
 ^   Retrieved July 29 
 
 ^   "Unhuman: Art in the Age of AI – State Festival" . Statefestival.org . Retrieved  13 September  2018 . 
 
 ^   Chun, Rene (21 September 2017).  "It's Getting Hard to Tell If a Painting Was Made by a Computer or a Human" .  Artsy . Retrieved  23 July  2019 . 
 
 ^   Retrieved July 29 
 
 ^   "Understanding AI" . Retrieved September 2019 .   Check date values in:  |access-date=  ( help ) 
 
 ^   "MAK Wien - MAK Museum Wien" . Retrieved October 2019 .   Check date values in:  |access-date=  ( help ) 
 
 ^   "European Platform for Digital Humanism – A conference by the European  ARTificial   Intelligence  Lab" . Retrieved September 2019 .   Check date values in:  |access-date=  ( help ) 
 
 ^   
The  Turing test : 
Turing's original publication:
 Turing 1950  harvnb error: no target: CITEREFTuring1950 ( help ) 
Historical influence and philosophical implications:
 Haugeland 1985 , pp. 6–9 
 Crevier 1993 , p. 24  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 McCorduck 2004 , pp. 70–71  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Russell & Norvig 2003 , pp. 2–3 and 948  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
Dartmouth proposal:
 McCarthy et al. 1955  (the original proposal) 
 Crevier 1993 , p. 49  harvnb error: no target: CITEREFCrevier1993 ( help )  (historical significance) 
 
 ^   
The  physical symbol systems  hypothesis:
 Newell & Simon 1976 , p. 116 
 McCorduck 2004 , p. 153  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Russell & Norvig 2003 , p. 18  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
Dreyfus criticized the  necessary  condition of the  physical symbol system  hypothesis, which he called the "psychological assumption": "The mind can be viewed as a device operating on bits of information according to formal rules." ( Dreyfus 1992 , p. 156) 
 
 ^   
 Dreyfus' critique of  artificial   intelligence :
 Dreyfus 1972 ,  Dreyfus & Dreyfus 1986 
 Crevier 1993 , pp. 120–132  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 McCorduck 2004 , pp. 211–239  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Russell & Norvig 2003 , pp. 950–952  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) , 
 
 ^   
 Gödel 1951 : in this lecture,  Kurt Gödel  uses the incompleteness theorem to arrive at the following disjunction: (a) the human mind is not a consistent finite machine, or (b) there exist  Diophantine equations  for which it cannot decide whether solutions exist. Gödel finds (b) implausible, and thus seems to have believed the human mind was not equivalent to a finite machine, i.e., its power exceeded that of any finite machine. He recognized that this was only a conjecture, since one could never disprove (b). Yet he considered the disjunctive conclusion to be a "certain fact". 
 
 ^   
The Mathematical Objection:
 Russell & Norvig 2003 , p. 949  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 McCorduck 2004 , pp. 448–449  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
Making the Mathematical Objection:
 Lucas 1961 
 Penrose 1989 
Refuting Mathematical Objection:
 Turing 1950  harvnb error: no target: CITEREFTuring1950 ( help )  under "(2) The Mathematical Objection" 
 Hofstadter 1979 
Background:
 Gödel 1931, Church 1936, Kleene 1935, Turing 1937 
 
 ^   Graham Oppy  (20 January 2015).  "Gödel's Incompleteness Theorems" .  Stanford Encyclopedia of Philosophy . Retrieved  27 April  2016 .  These Gödelian anti-mechanist arguments are, however, problematic, and there is wide consensus that they fail. 
 
 ^   Stuart J. Russell ;  Peter Norvig  (2010). "26.1.2: Philosophical Foundations/Weak AI: Can Machines Act Intelligently?/The mathematical objection".  Artificial   Intelligence : A Modern Approach  (3rd ed.). Upper Saddle River, NJ:  Prentice Hall .  ISBN   978-0-13-604259-4 .  even if we grant that computers have limitations on what they can prove, there is no evidence that humans are immune from those limitations. 
 
 ^   Mark Colyvan. An introduction to the philosophy of mathematics.  Cambridge University Press , 2012. From 2.2.2, 'Philosophical significance of Gödel's incompleteness results': "The accepted wisdom (with which I concur) is that the Lucas-Penrose arguments fail." 
 
 ^   Russel, Stuart., Daniel Dewey, and Max Tegmark. Research Priorities for Robust and Beneficial  Artificial   Intelligence . AI Magazine 36:4 (2015). 8 December 2016. 
 
 ^   Simon, Matt (1 April 2019).  "Andrew Yang's Presidential Bid Is So Very 21st Century" .  Wired  – via www.wired.com. 
 
 ^   "Five experts share what scares them the most about AI" . 5 September 2018. 
 
 ^   Rawlinson, Kevin (29 January 2015).  "Microsoft's Bill Gates insists AI is a threat" .  BBC News .  Archived  from the original on 29 January 2015 . Retrieved  30 January  2015 . 
 
 ^   Holley, Peter (28 January 2015).  "Bill Gates on dangers of  artificial   intelligence : 'I don't understand why some people are not concerned ' " .  The Washington Post .  ISSN   0190-8286 .  Archived  from the original on 30 October 2015 . Retrieved  30 October  2015 . 
 
 ^   Gibbs, Samuel (27 October 2014).  "Elon Musk:  artificial   intelligence  is our biggest existential threat" .  The Guardian .  Archived  from the original on 30 October 2015 . Retrieved  30 October  2015 . 
 
 ^   Cellan-Jones, Rory (2 December 2014).  "Stephen Hawking warns  artificial   intelligence  could end mankind" .  BBC News .  Archived  from the original on 30 October 2015 . Retrieved  30 October  2015 . 
 
 ^   Bostrom, Nick (2015).  "What happens when our computers get smarter than we are?" .  TED (conference) . 
 
 ^  a   b   Russell, Stuart  (8 October 2019).  Human Compatible:  Artificial   Intelligence  and the Problem of Control . United States: Viking.  ISBN   978-0-525-55861-3 .  OCLC   1083694322 . 
 
 ^   Post, Washington.  "Tech titans like Elon Musk are spending $1 billion to save you from terminators" .  Archived  from the original on 7 June 2016. 
 
 ^   Müller, Vincent C.; Bostrom, Nick (2014).  "Future Progress in  Artificial   Intelligence : A Poll Among Experts"   (PDF) .  AI Matters .  1  (1): 9–11.  doi : 10.1145/2639475.2639478 .  Archived   (PDF)  from the original on 15 January 2016. 
 
 ^   "Oracle CEO Mark Hurd sees no reason to fear ERP AI" .  SearchERP . Retrieved  6 May  2019 . 
 
 ^   "Mark Zuckerberg responds to Elon Musk's paranoia about AI: 'AI is going to... help keep our communities safe. ' " .  Business Insider . 25 May 2018 . Retrieved  6 May  2019 . 
 
 ^   "The mysterious  artificial   intelligence  company Elon Musk invested in is developing game-changing smart computers" .  Tech Insider .  Archived  from the original on 30 October 2015 . Retrieved  30 October  2015 . 
 
 ^   Clark, Jack.  "Musk-Backed Group Probes Risks Behind  Artificial   Intelligence " .  Bloomberg.com .  Archived  from the original on 30 October 2015 . Retrieved  30 October  2015 . 
 
 ^   "Elon Musk Is Donating $10M Of His Own Money To  Artificial   Intelligence  Research" .  Fast Company . 15 January 2015.  Archived  from the original on 30 October 2015 . Retrieved  30 October  2015 . 
 
 ^   "Is  artificial   intelligence  really an existential threat to humanity?" .  Bulletin of the Atomic Scientists . 9 August 2015.  Archived  from the original on 30 October 2015 . Retrieved  30 October  2015 . 
 
 ^   "The case against killer robots, from a guy actually working on  artificial   intelligence " .  Fusion.net .  Archived  from the original on 4 February 2016 . Retrieved  31 January  2016 . 
 
 ^   "Will  artificial   intelligence  destroy humanity? Here are 5 reasons not to worry" .  Vox . 22 August 2014.  Archived  from the original on 30 October 2015 . Retrieved  30 October  2015 . 
 
 ^   In the early 1970s,  Kenneth Colby  presented a version of Weizenbaum's  ELIZA  known as DOCTOR which he promoted as a serious therapeutic tool. ( Crevier 1993 , pp. 132–144)  harv error: no target: CITEREFCrevier1993 ( help ) 
 
 ^   
 Joseph Weizenbaum 's critique of AI:
 Weizenbaum 1976 
 Crevier 1993 , pp. 132–144  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 McCorduck 2004 , pp. 356–373  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Russell & Norvig 2003 , p. 961  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
Weizenbaum (the AI researcher who developed the first  chatterbot  program,  ELIZA ) argued in 1976 that the misuse of  artificial   intelligence  has the potential to devalue human life. 
 
 ^   "Commentary: Bad news.  Artificial   intelligence  is biased" .  CNA . 12 January 2019 . Retrieved  19 June  2020 . 
 
 ^   Jeff Larson, Julia Angwin (23 May 2016).  "How We Analyzed the COMPAS Recidivism Algorithm" .  ProPublica . Retrieved  19 June  2020 . 
 
 ^   E McGaughey, 'Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy' (2018)  SSRN, part 2(3) 
 
 ^   "Automation and anxiety" .  The Economist . 9 May 2015 . Retrieved  13 January  2018 . 
 
 ^   Lohr, Steve (2017).  "Robots Will Take Jobs, but Not as Fast as Some Fear, New Report Says" .  The New York Times . Retrieved  13 January  2018 . 
 
 ^   Frey, Carl Benedikt; Osborne, Michael A (1 January 2017). "The future of employment: How susceptible are jobs to computerisation?".  Technological Forecasting and Social Change .  114 : 254–280.  CiteSeerX   10.1.1.395.416 .  doi : 10.1016/j.techfore.2016.08.019 .  ISSN   0040-1625 . 
 
 ^   Arntz, Melanie, Terry Gregory, and Ulrich Zierahn. "The risk of automation for jobs in OECD countries: A comparative analysis." OECD Social, Employment, and Migration Working Papers 189 (2016). p. 33. 
 
 ^   Mahdawi, Arwa (26 June 2017).  "What jobs will still be around in 20 years? Read this to prepare your future" .  The Guardian . Retrieved  13 January  2018 . 
 
 ^   "Stephen Hawking, Elon Musk, and Bill Gates Warn About  Artificial   Intelligence " .  Observer . 19 August 2015.  Archived  from the original on 30 October 2015 . Retrieved  30 October  2015 . 
 
 ^   Iphofen, Ron; Kritikos, Mihalis (3 January 2019). "Regulating  artificial   intelligence  and robotics: ethics by design in a digital society".  Contemporary Social Science : 1–15.  doi : 10.1080/21582041.2018.1563803 .  ISSN   2158-2041 . 
 
 ^   "Ethical AI Learns Human Rights Framework" .  Voice of America . Retrieved  10 November  2019 . 
 
 ^   Wendell Wallach (2010).  Moral Machines , Oxford University Press. 
 
 ^   Wallach, pp 37–54. 
 
 ^   Wallach, pp 55–73. 
 
 ^   Wallach, Introduction chapter. 
 
 ^  a   b   Michael Anderson and Susan Leigh Anderson (2011), Machine Ethics, Cambridge University Press. 
 
 ^  a   b   "Machine Ethics" .  aaai.org . Archived from  the original  on 29 November 2014. 
 
 ^   Rubin, Charles  (Spring 2003).  " Artificial   Intelligence  and Human Nature" .  The New Atlantis .  1 : 88–100. Archived from  the original  on 11 June 2012. 
 
 ^   Brooks, Rodney (10 November 2014).  " artificial   intelligence  is a tool, not a threat" . Archived from  the original  on 12 November 2014. 
 
 ^   Chalmers, David  (1995).  "Facing up to the problem of consciousness" .  Journal of Consciousness Studies .  2  (3): 200–219.  See also  this link 
 
 ^   Horst, Steven , (2005)  "The Computational Theory of Mind"  in  The Stanford Encyclopedia of Philosophy 
 
 ^   
This version is from  Searle (1999) , and is also quoted in  Dennett 1991 , p. 435. Searle's original formulation was "The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states." ( Searle 1980 , p. 1). Strong AI is defined similarly by  Russell & Norvig (2003 , p. 947)  harvtxt error: no target: CITEREFRussellNorvig2003 ( help ) : "The assertion that machines could possibly act intelligently (or, perhaps better, act as if they were intelligent) is called the 'weak AI' hypothesis by philosophers, and the assertion that machines that do so are actually thinking (as opposed to simulating thinking) is called the 'strong AI' hypothesis." 
 
 ^   
Searle's  Chinese room  argument:
 Searle 1980 . Searle's original presentation of the thought experiment. 
 Searle 1999 . 
Discussion:
 Russell & Norvig 2003 , pp. 958–960  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 McCorduck 2004 , pp. 443–445  harvnb error: no target: CITEREFMcCorduck2004 ( help ) 
 Crevier 1993 , pp. 269–271  harvnb error: no target: CITEREFCrevier1993 ( help ) 
 
 ^   
 Robot rights :
 Russell & Norvig 2003 , p. 964  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 BBC News  2006 
Prematurity of:
 Henderson 2007 
In fiction:
 McCorduck (2004 , pp. 190–25)  harvtxt error: no target: CITEREFMcCorduck2004 ( help )  discusses  Frankenstein  and identifies the key ethical issues as scientific hubris and the suffering of the monster, i.e.  robot rights . 
 
 ^   Evans, Woody  (2015).  "Posthuman Rights: Dimensions of Transhuman Worlds" .  Teknokultura .  12  (2).  doi : 10.5209/rev_TK.2015.v12.n2.49072 . 
 
 ^   maschafilm.  "Content: Plug & Pray Film –  Artificial   Intelligence  – Robots -" .  plugandpray-film.de .  Archived  from the original on 12 February 2016. 
 
 ^   
 Omohundro, Steve  (2008).  The Nature of Self-Improving  Artificial   Intelligence . presented and distributed at the 2007 Singularity Summit, San Francisco, CA. 
 
 ^  a   b   c   
 Technological singularity :
 Vinge 1993 
 Kurzweil 2005 
 Russell & Norvig 2003 , p. 963  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
 Transhumanism :
 Moravec 1988  harvnb error: multiple targets (2×): CITEREFMoravec1988 ( help ) 
 Kurzweil 2005 
 Russell & Norvig 2003 , p. 963  harvnb error: no target: CITEREFRussellNorvig2003 ( help ) 
 
 ^   
AI as evolution:
 Edward Fredkin  is quoted in  McCorduck (2004 , p. 401)  harvtxt error: no target: CITEREFMcCorduck2004 ( help ) . 
 Butler 1863 
 Dyson 1998 
 
 ^   "Robots and  Artificial   Intelligence " .  www.igmchicago.org . Retrieved  3 July  2019 . 
 
 ^   Wirtz, Bernd W.; Weyerer, Jan C.; Geyer, Carolin (24 July 2018). " Artificial   Intelligence  and the Public Sector—Applications and Challenges".  International Journal of Public Administration .  42  (7): 596–615.  doi : 10.1080/01900692.2018.1498103 .  ISSN   0190-0692 . 
 
 ^   "Elon Musk Warns Governors:  Artificial   Intelligence  Poses 'Existential Risk ' " .  NPR.org . Retrieved  27 November  2017 . 
 
 ^   Campbell, Thomas A. (2019).  Artificial   Intelligence : An Overview of State Initiatives   (PDF) . Evergreen, CO: FutureGrasp, LLC. [ permanent dead link ] 
 
 ^   White Paper: On  Artificial   Intelligence  - A European approach to excellence and trust   (PDF) . Brussels: European Commission. 2020. p. 1. 
 
 ^   Buttazzo, G. (July 2001). " Artificial  consciousness: Utopia or real possibility?".  Computer .  34  (7): 24–30.  doi : 10.1109/2.933500 . 
 
 ^   Anderson, Susan Leigh. "Asimov's "three laws of robotics" and machine metaethics." AI & Society 22.4 (2008): 477–493. 
 
 ^   McCauley, Lee (2007). "AI armageddon and the three laws of robotics".  Ethics and Information Technology .  9  (2): 153–164.  CiteSeerX   10.1.1.85.8904 .  doi : 10.1007/s10676-007-9138-2 . 
 
 ^   Galvan, Jill (1 January 1997). "Entering the Posthuman Collective in Philip K. Dick's "Do Androids Dream of Electric Sheep? " ".  Science Fiction Studies .  24  (3): 413–429.  JSTOR   4240644 . 
 
 
 AI textbooks 
 
 Hutter, Marcus  (2005).  Universal  Artificial   Intelligence . Berlin: Springer.  ISBN   978-3-540-22139-5 . CS1 maint: ref=harv ( link ) 
 Jackson, Philip  (1985).  Introduction to  Artificial   Intelligence  (2nd ed.). Dover.  ISBN   978-0-486-24864-6 . CS1 maint: ref=harv ( link ) 
 Luger, George ;  Stubblefield, William  (2004).  Artificial   Intelligence : Structures and Strategies for Complex Problem Solving  (5th ed.). Benjamin/Cummings.  ISBN   978-0-8053-4780-7 . CS1 maint: ref=harv ( link ) 
 Neapolitan, Richard ; Jiang, Xia (2018).  Artificial   Intelligence : With an Introduction to Machine Learning . Chapman & Hall/CRC.  ISBN   978-1-138-50238-3 . 
 Nilsson, Nils  (1998).  Artificial   Intelligence : A New Synthesis . Morgan Kaufmann.  ISBN   978-1-55860-467-4 . CS1 maint: ref=harv ( link ) 
 Russell, Stuart J. ;  Norvig, Peter  (2003),  Artificial   Intelligence : A Modern Approach  (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall,  ISBN   0-13-790395-2 . 
 Russell, Stuart J. ;  Norvig, Peter  (2009).  Artificial   Intelligence : A Modern Approach  (3rd ed.). Upper Saddle River, New Jersey: Prentice Hall.  ISBN   978-0-13-604259-4 . CS1 maint: ref=harv ( link ) . 
 Poole, David ;  Mackworth, Alan ;  Goebel, Randy  (1998).  Computational  Intelligence : A Logical Approach . New York: Oxford University Press.  ISBN   978-0-19-510270-3 . CS1 maint: ref=harv ( link ) 
 Winston, Patrick Henry  (1984).  Artificial   Intelligence . Reading, MA: Addison-Wesley.  ISBN   978-0-201-08259-3 . 
 Rich, Elaine  (1983).  Artificial   Intelligence . McGraw-Hill.  ISBN   978-0-07-052261-9 . 
 Bundy, Alan  (1980).  Artificial   Intelligence : An Introductory Course  (2nd ed.). Edinburgh University Press.  ISBN   978-0-85224-410-4 . 
 Poole, David ;  Mackworth, Alan  (2017).  Artificial   Intelligence : Foundations of Computational Agents  (2nd ed.). Cambridge University Press.  ISBN   978-1-107-19539-4 . CS1 maint: ref=harv ( link ) 
 
 History of AI 
 
 Crevier, Daniel  (1993),  AI: The Tumultuous Search for  Artificial   Intelligence , New York, NY: BasicBooks,  ISBN   0-465-02997-3 . 
 McCorduck, Pamela  (2004),  Machines Who Think  (2nd ed.), Natick, MA: A. K. Peters, Ltd.,  ISBN   1-56881-205-1 . 
 Newquist, HP  (1994).  The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think . New York: Macmillan/SAMS.  ISBN   978-0-672-30412-5 . CS1 maint: ref=harv ( link ) 
 Nilsson, Nils  (2009).  The Quest for  Artificial   Intelligence : A History of Ideas and Achievements . New York: Cambridge University Press.  ISBN   978-0-521-12293-1 . 
 
 Other sources 
 
 Asada, M.; Hosoda, K.; Kuniyoshi, Y.; Ishiguro, H.; Inui, T.; Yoshikawa, Y.; Ogino, M.; Yoshida, C. (2009). "Cognitive developmental robotics: a survey".  IEEE Transactions on Autonomous Mental Development .  1  (1): 12–34.  doi : 10.1109/tamd.2009.2021702 . CS1 maint: ref=harv ( link ) 
 "ACM Computing Classification System:  Artificial   intelligence " .  ACM . 1998. Archived from  the original  on 12 October 2007 . Retrieved  30 August  2007 . 
 Goodman, Joanna  (2016).  Robots in Law: How  Artificial   Intelligence  is Transforming Legal Services  (1st ed.). Ark Group.  ISBN   978-1-78358-264-8 . CS1 maint: ref=harv ( link ) 
 Albus, J. S. (2002).  "4-D/RCS: A Reference Model Architecture for Intelligent Unmanned Ground Vehicles"   (PDF) .  In Gerhart, G.; Gunderson, R.; Shoemaker, C. (eds.).  Proceedings of the SPIE AeroSense Session on Unmanned Ground Vehicle Technology . Unmanned Ground Vehicle Technology IV.  3693 . pp. 11–20.  Bibcode : 2002SPIE.4715..303A .  CiteSeerX   10.1.1.15.14 .  doi : 10.1117/12.474462 . Archived from  the original   (PDF)  on 25 July 2004. CS1 maint: ref=harv ( link ) 
 Aleksander, Igor  (1995).  Artificial  Neuroconsciousness: An Update . IWANN. Archived from  the original  on 2 March 1997. CS1 maint: ref=harv ( link )   BibTex   Archived  2 March 1997 at the  Wayback Machine . 
 Bach, Joscha (2008).  "Seven Principles of Synthetic  Intelligence " .  In Wang, Pei; Goertzel, Ben; Franklin, Stan (eds.).  Artificial  General  Intelligence , 2008: Proceedings of the First AGI Conference . IOS Press. pp. 63–74.  ISBN   978-1-58603-833-5 . CS1 maint: ref=harv ( link ) 
 "Robots could demand legal rights" .  BBC News . 21 December 2006 . Retrieved  3 February  2011 . 
 Brooks, Rodney  (1990).  "Elephants Don't Play Chess"   (PDF) .  Robotics and Autonomous Systems .  6  (1–2): 3–15.  CiteSeerX   10.1.1.588.7539 .  doi : 10.1016/S0921-8890(05)80025-9 .  Archived   (PDF)  from the original on 9 August 2007. CS1 maint: ref=harv ( link ) 
 Brooks, R. A. (1991). "How to build complete creatures rather than isolated cognitive simulators".  In VanLehn, K. (ed.).  Architectures for  Intelligence . Hillsdale, NJ: Lawrence Erlbaum Associates. pp. 225–239.  CiteSeerX   10.1.1.52.9510 . CS1 maint: ref=harv ( link ) 
 Buchanan, Bruce G. (2005).  "A (Very) Brief History of  Artificial   Intelligence "   (PDF) .  AI Magazine : 53–60. Archived from  the original   (PDF)  on 26 September 2007. CS1 maint: ref=harv ( link ) 
 Butler, Samuel  (13 June 1863).  "Darwin among the Machines" . Letters to the Editor.  The Press . Christchurch, New Zealand . Retrieved  16 October  2014  – via Victoria University of Wellington. CS1 maint: ref=harv ( link ) 
 Clark, Jack (8 December 2015).  "Why 2015 Was a Breakthrough Year in  Artificial   Intelligence " .  Bloomberg News .  Archived  from the original on 23 November 2016 . Retrieved  23 November  2016 .  After a half-decade of quiet breakthroughs in  artificial   intelligence , 2015 has been a landmark year. Computers are smarter and learning faster than ever. CS1 maint: ref=harv ( link ) 
 "AI set to exceed human brain power" .  CNN . 26 July 2006.  Archived  from the original on 19 February 2008. 
 Dennett, Daniel  (1991).  Consciousness Explained . The Penguin Press.  ISBN   978-0-7139-9037-9 . CS1 maint: ref=harv ( link ) 
 Domingos, Pedro  (2015).  The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World . Basic Books.  ISBN   978-0-465-06192-1 . CS1 maint: ref=harv ( link ) 
 Dowe, D. L.; Hajek, A. R. (1997).  "A computational extension to the Turing Test" .  Proceedings of the 4th Conference of the Australasian Cognitive Science Society . Archived from  the original  on 28 June 2011. CS1 maint: ref=harv ( link ) 
 Dreyfus, Hubert  (1972).  What Computers Can't Do . New York: MIT Press.  ISBN   978-0-06-011082-6 . CS1 maint: ref=harv ( link ) 
 Dreyfus, Hubert ; Dreyfus, Stuart (1986).  Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer . Oxford, UK: Blackwell.  ISBN   978-0-02-908060-3 . CS1 maint: ref=harv ( link ) 
 Dreyfus, Hubert  (1992).  What Computers  Still  Can't Do . New York: MIT Press.  ISBN   978-0-262-54067-4 . CS1 maint: ref=harv ( link ) 
 Dyson, George  (1998).  Darwin among the Machines . Allan Lane Science.  ISBN   978-0-7382-0030-9 . CS1 maint: ref=harv ( link ) 
 Edelman, Gerald  (23 November 2007).  "Gerald Edelman – Neural Darwinism and Brain-based Devices" . Talking Robots. Archived from  the original  on 8 October 2009. CS1 maint: ref=harv ( link ) 
 Edelson, Edward (1991).  The Nervous System . New York: Chelsea House.  ISBN   978-0-7910-0464-7 . CS1 maint: ref=harv ( link ) 
 Fearn, Nicholas (2007).  The Latest Answers to the Oldest Questions: A Philosophical Adventure with the World's Greatest Thinkers . New York: Grove Press.  ISBN   978-0-8021-1839-4 . CS1 maint: ref=harv ( link ) 
 Gladwell, Malcolm  (2005).  Blink . New York: Little, Brown and Co.  ISBN   978-0-316-17232-5 . CS1 maint: ref=harv ( link ) 
 Gödel, Kurt  (1951).  Some basic theorems on the foundations of mathematics and their implications . Gibbs Lecture. CS1 maint: ref=harv ( link )  In   Feferman, Solomon , ed. (1995).  Kurt Gödel: Collected Works, Vol. III: Unpublished Essays and Lectures . Oxford University Press. pp. 304–23.  ISBN   978-0-19-514722-3 . 
 Haugeland, John  (1985).  Artificial   Intelligence : The Very Idea . Cambridge, Mass.: MIT Press.  ISBN   978-0-262-08153-5 . CS1 maint: ref=harv ( link ) 
 Hawkins, Jeff ; Blakeslee, Sandra (2005).  On  Intelligence . New York, NY: Owl Books.  ISBN   978-0-8050-7853-4 . CS1 maint: ref=harv ( link ) 
 Henderson, Mark (24 April 2007).  "Human rights for robots? We're getting carried away" .  The Times Online . London. CS1 maint: ref=harv ( link ) 
 Hernandez-Orallo, Jose (2000). "Beyond the Turing Test".  Journal of Logic, Language and Information .  9  (4): 447–466.  doi : 10.1023/A:1008367325700 . CS1 maint: ref=harv ( link ) 
 Hernandez-Orallo, J.; Dowe, D. L. (2010). "Measuring Universal  Intelligence : Towards an Anytime  Intelligence  Test".  Artificial   Intelligence .  174  (18): 1508–1539.  CiteSeerX   10.1.1.295.9079 .  doi : 10.1016/j.artint.2010.09.006 . CS1 maint: ref=harv ( link ) 
 Hinton, G. E. (2007). "Learning multiple layers of representation".  Trends in Cognitive Sciences .  11  (10): 428–434.  doi : 10.1016/j.tics.2007.09.004 .  PMID   17921042 . CS1 maint: ref=harv ( link ) 
 Hofstadter, Douglas  (1979).  Gödel, Escher, Bach: an Eternal Golden Braid . New York, NY: Vintage Books.  ISBN   978-0-394-74502-2 . CS1 maint: ref=harv ( link ) 
 Holland, John H. (1975).  Adaptation in Natural and  Artificial  Systems . University of Michigan Press.  ISBN   978-0-262-58111-0 . CS1 maint: ref=harv ( link ) 
 Howe, J. (November 1994).  " Artificial   Intelligence  at Edinburgh University: a Perspective" . Retrieved  30 August  2007 . CS1 maint: ref=harv ( link ) 
 Hutter, M. (2012). "One Decade of Universal  Artificial   Intelligence ".  Theoretical Foundations of  Artificial  General  Intelligence . Atlantis Thinking Machines.  4 . pp. 67–88.  CiteSeerX   10.1.1.228.8725 .  doi : 10.2991/978-94-91216-62-6_5 .  ISBN   978-94-91216-61-9 . CS1 maint: ref=harv ( link ) 
 Kahneman, Daniel ; Slovic, D.;  Tversky, Amos  (1982).  Judgment under uncertainty: Heuristics and biases .  Science .  185 . New York: Cambridge University Press. pp. 1124–31.  doi : 10.1126/science.185.4157.1124 .  ISBN   978-0-521-28414-1 .  PMID   17835457 . CS1 maint: ref=harv ( link ) 
 Kaplan, Andreas; Haenlein, Michael (2019). "Siri, Siri in my Hand, who's the Fairest in the Land? On the Interpretations, Illustrations and Implications of  Artificial   Intelligence ".  Business Horizons .  62 : 15–25.  doi : 10.1016/j.bushor.2018.08.004 . CS1 maint: ref=harv ( link ) 
 Katz, Yarden (1 November 2012).  "Noam Chomsky on Where  Artificial   Intelligence  Went Wrong" .  The Atlantic . Retrieved  26 October  2014 . CS1 maint: ref=harv ( link ) 
 "Kismet" . MIT  Artificial   Intelligence  Laboratory, Humanoid Robotics Group . Retrieved  25 October  2014 . 
 Koza, John R. (1992).  Genetic Programming (On the Programming of Computers by Means of Natural Selection) . MIT Press.  Bibcode : 1992gppc.book.....K .  ISBN   978-0-262-11170-6 . CS1 maint: ref=harv ( link ) 
 Kolata, G. (1982). "How can computers get common sense?".  Science .  217  (4566): 1237–1238.  Bibcode : 1982Sci...217.1237K .  doi : 10.1126/science.217.4566.1237 .  PMID   17837639 . CS1 maint: ref=harv ( link ) 
 Kumar, Gulshan; Kumar, Krishan (2012).  "The Use of  Artificial - Intelligence -Based Ensembles for Intrusion Detection: A Review" .  Applied Computational  Intelligence  and Soft Computing .  2012 : 1–20.  doi : 10.1155/2012/850160 . CS1 maint: ref=harv ( link ) 
 Kurzweil, Ray  (1999).  The Age of Spiritual Machines . Penguin Books.  ISBN   978-0-670-88217-5 . CS1 maint: ref=harv ( link ) 
 Kurzweil, Ray  (2005).  The Singularity is Near . Penguin Books.  ISBN   978-0-670-03384-3 . CS1 maint: ref=harv ( link ) 
 Lakoff, George ;  Núñez, Rafael E.  (2000).  Where Mathematics Comes From: How the Embodied Mind Brings Mathematics into Being . Basic Books.  ISBN   978-0-465-03771-1 . CS1 maint: ref=harv ( link ) 
 Langley, Pat (2011).  "The changing science of machine learning" .  Machine Learning .  82  (3): 275–279.  doi : 10.1007/s10994-011-5242-y . CS1 maint: ref=harv ( link ) 
 Law, Diane (June 1994).  Searle, Subsymbolic Functionalism and Synthetic  Intelligence  (Technical report). University of Texas at Austin. p. AI94-222.  CiteSeerX   10.1.1.38.8384 . CS1 maint: ref=harv ( link ) 
 Legg, Shane; Hutter, Marcus (15 June 2007).  A Collection of Definitions of  Intelligence  (Technical report).  IDSIA .  arXiv : 0706.3639 .  Bibcode : 2007arXiv0706.3639L . 07-07. CS1 maint: ref=harv ( link ) 
 Lenat, Douglas ; Guha, R. V. (1989).  Building Large Knowledge-Based Systems . Addison-Wesley.  ISBN   978-0-201-51752-1 . CS1 maint: ref=harv ( link ) 
 Lighthill, James  (1973). " Artificial   Intelligence : A General Survey".  Artificial   Intelligence : a paper symposium . Science Research Council. CS1 maint: ref=harv ( link ) 
 Lucas, John  (1961). "Minds, Machines and Gödel".  In Anderson, A.R. (ed.).  Minds and Machines .  Archived  from the original on 19 August 2007 . Retrieved  30 August  2007 . CS1 maint: ref=harv ( link ) 
 Lungarella, M.; Metta, G.; Pfeifer, R.; Sandini, G. (2003). "Developmental robotics: a survey".  Connection Science .  15  (4): 151–190.  CiteSeerX   10.1.1.83.7615 .  doi : 10.1080/09540090310001655110 . CS1 maint: ref=harv ( link ) 
 Maker, Meg Houston (2006).  "AI@50: AI Past, Present, Future" . Dartmouth College. Archived from  the original  on 3 January 2007 . Retrieved  16 October  2008 . CS1 maint: ref=harv ( link ) 
 Markoff, John (16 February 2011).  "Computer Wins on 'Jeopardy!': Trivial, It's Not" .  The New York Times . Retrieved  25 October  2014 . CS1 maint: ref=harv ( link ) 
 McCarthy, John ;  Minsky, Marvin ;  Rochester, Nathan ;  Shannon, Claude  (1955).  "A Proposal for the Dartmouth Summer Research Project on  Artificial   Intelligence " . Archived from  the original  on 26 August 2007 . Retrieved  30 August  2007 . CS1 maint: ref=harv ( link ) . 
 McCarthy, John ; Hayes, P. J. (1969).  "Some philosophical problems from the standpoint of  artificial   intelligence " .  Machine  Intelligence .  4 : 463–502.  CiteSeerX   10.1.1.85.5082 .  Archived  from the original on 10 August 2007 . Retrieved  30 August  2007 . CS1 maint: ref=harv ( link ) 
 McCarthy, John  (12 November 2007).  "What Is  Artificial   Intelligence ?" . Archived from  the original  on 18 November 2015. CS1 maint: ref=harv ( link ) 
 Minsky, Marvin  (1967).  Computation: Finite and Infinite Machines . Englewood Cliffs, N.J.: Prentice-Hall.  ISBN   978-0-13-165449-5 . CS1 maint: ref=harv ( link ) 
 Minsky, Marvin  (2006).  The Emotion Machine . New York, NY: Simon & Schusterl.  ISBN   978-0-7432-7663-4 . CS1 maint: ref=harv ( link ) 
 Moravec, Hans  (1988).  Mind Children . Harvard University Press.  ISBN   978-0-674-57616-2 . CS1 maint: ref=harv ( link ) 
 Norvig, Peter  (25 June 2012).  "On Chomsky and the Two Cultures of Statistical Learning" . Peter Norvig.  Archived  from the original on 19 October 2014. CS1 maint: ref=harv ( link ) 
 NRC (United States National Research Council)  (1999). "Developments in  Artificial   Intelligence ".  Funding a Revolution: Government Support for Computing Research . National Academy Press. 
 Needham, Joseph  (1986).  Science and Civilization in China: Volume 2 . Caves Books Ltd. CS1 maint: ref=harv ( link ) 
 Newell, Allen ;  Simon, H. A.  (1976).  "Computer Science as Empirical Inquiry: Symbols and Search" .  Communications of the ACM .  19  (3): 113–126.  doi : 10.1145/360018.360022 . CS1 maint: ref=harv ( link ) . 
 Nilsson, Nils  (1983).  " Artificial   Intelligence  Prepares for 2001"   (PDF) .  AI Magazine .  1  (1). CS1 maint: ref=harv ( link )  Presidential Address to the  Association for the Advancement of  Artificial   Intelligence . 
 O'Brien, James; Marakas, George (2011).  Management Information Systems  (10th ed.). McGraw-Hill/Irwin.  ISBN   978-0-07-337681-3 . CS1 maint: ref=harv ( link ) 
 O'Connor, Kathleen Malone (1994).  "The alchemical creation of life (takwin) and other concepts of Genesis in medieval Islam" . University of Pennsylvania: 1–435.   Cite journal requires  |journal=  ( help ) CS1 maint: ref=harv ( link ) 
 Oudeyer, P-Y. (2010).  "On the impact of robotics in behavioral and cognitive sciences: from insect navigation to human cognitive development"   (PDF) .  IEEE Transactions on Autonomous Mental Development .  2  (1): 2–16.  doi : 10.1109/tamd.2009.2039057 . CS1 maint: ref=harv ( link ) 
 Penrose, Roger  (1989).  The Emperor's New Mind: Concerning Computer, Minds and The Laws of Physics .  Oxford University Press .  ISBN   978-0-19-851973-7 . CS1 maint: ref=harv ( link ) 
 Poli, R.; Langdon, W. B.; McPhee, N. F. (2008).  A Field Guide to Genetic Programming . Lulu.com.  ISBN   978-1-4092-0073-4  – via gp-field-guide.org.uk. CS1 maint: ref=harv ( link ) 
 Rajani, Sandeep (2011).  " Artificial   Intelligence  – Man or Machine"   (PDF) .  International Journal of Information Technology and Knowledge Management .  4  (1): 173–176. Archived from  the original   (PDF)  on 18 January 2013. CS1 maint: ref=harv ( link ) 
 Ronald, E. M. A.  and Sipper, M.   Intelligence  is not enough: On the socialization of talking machines, Minds and Machines , vol. 11, no. 4, pp. 567–576, November 2001. 
 Ronald, E. M. A.  and Sipper, M.   What use is a Turing chatterbox? , Communications of the ACM, vol. 43, no. 10, pp. 21–23, October 2000. 
 Searle, John  (1980).  "Minds, Brains and Programs"   (PDF) .  Behavioral and Brain Sciences .  3  (3): 417–457.  doi : 10.1017/S0140525X00005756 . CS1 maint: ref=harv ( link ) 
 Searle, John  (1999).  Mind, language and society . New York, NY: Basic Books.  ISBN   978-0-465-04521-1 .  OCLC   231867665 . CS1 maint: ref=harv ( link ) 
 Shapiro, Stuart C. (1992). " Artificial   Intelligence ".  In Shapiro, Stuart C. (ed.).  Encyclopedia of  Artificial   Intelligence   (PDF)  (2nd ed.). New York: John Wiley. pp. 54–57.  ISBN   978-0-471-50306-4 . CS1 maint: ref=harv ( link ) 
 Simon, H. A.  (1965).  The Shape of Automation for Men and Management . New York: Harper & Row. CS1 maint: ref=harv ( link ) 
 Skillings, Jonathan (3 July 2006).  "Getting Machines to Think Like Us" .  cnet . Retrieved  3 February  2011 . CS1 maint: ref=harv ( link ) 
 Solomonoff, Ray  (1956).  An Inductive Inference Machine   (PDF) . Dartmouth Summer Research Conference on  Artificial   Intelligence  – via std.com, pdf scanned copy of the original. CS1 maint: ref=harv ( link )  Later published as Solomonoff, Ray (1957). "An Inductive Inference Machine".  IRE Convention Record . Section on Information Theory, part 2. pp. 56–62. 
 Tao, Jianhua; Tan, Tieniu (2005).  Affective Computing and Intelligent Interaction . Affective Computing: A Review.  LNCS  3784. Springer. pp. 981–995.  doi : 10.1007/11573548 . CS1 maint: ref=harv ( link ) 
 Tecuci, Gheorghe (March–April 2012). " Artificial   Intelligence ".  Wiley Interdisciplinary Reviews: Computational Statistics .  4  (2): 168–180.  doi : 10.1002/wics.200 . CS1 maint: ref=harv ( link ) 
 Thro, Ellen (1993).  Robotics: The Marriage of Computers and Machines . New York: Facts on File.  ISBN   978-0-8160-2628-9 . CS1 maint: ref=harv ( link ) 
 Turing, Alan  (October 1950), "Computing Machinery and  Intelligence ",  Mind ,  LIX  (236): 433–460,  doi : 10.1093/mind/LIX.236.433 ,  ISSN   0026-4423 . 
 van der Walt, Christiaan; Bernard, Etienne (2006).  "Data characteristics that determine classifier performance"   (PDF) . Archived from  the original   (PDF)  on 25 March 2009 . Retrieved  5 August  2009 . CS1 maint: ref=harv ( link ) 
 Vinge, Vernor  (1993).  "The Coming Technological Singularity: How to Survive in the Post-Human Era" .  Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace : 11.  Bibcode : 1993vise.nasa...11V . CS1 maint: ref=harv ( link ) 
 Wason, P. C. ; Shapiro, D. (1966).  "Reasoning" .  In Foss, B. M. (ed.).  New horizons in psychology . Harmondsworth: Penguin. CS1 maint: ref=harv ( link ) 
 Weizenbaum, Joseph  (1976).  Computer Power and Human Reason . San Francisco: W.H. Freeman & Company.  ISBN   978-0-7167-0464-5 . CS1 maint: ref=harv ( link ) 
 Weng, J.; McClelland; Pentland, A.; Sporns, O.; Stockman, I.; Sur, M.; Thelen, E. (2001).  "Autonomous mental development by robots and animals"   (PDF) .  Science .  291  (5504): 599–600.  doi : 10.1126/science.291.5504.599 .  PMID   11229402  – via msu.edu. CS1 maint: ref=harv ( link ) 
 "Applications of AI" .  www-formal.stanford.edu . Retrieved  25 September  2016 . CS1 maint: ref=harv ( link ) 
 
 Further reading 
 
 DH Author, 'Why Are There Still So Many Jobs? The History and Future of Workplace Automation' (2015) 29(3) Journal of Economic Perspectives 3. 
 Boden, Margaret ,  Mind As Machine ,  Oxford University Press , 2006. 
 Cukier, Kenneth , "Ready for Robots?  How to Think about the Future of AI",  Foreign Affairs , vol. 98, no. 4 (July/August 2019), pp. 192–98.   George Dyson , historian of computing, writes (in what might be called "Dyson's Law") that "Any system simple enough to be understandable will not be complicated enough to behave intelligently, while any system complicated enough to behave intelligently will be too complicated to understand." (p. 197.)  Computer scientist  Alex Pentland  writes:  "Current  AI machine-learning   algorithms  are, at their core, dead simple stupid.  They work, but they work by brute force." (p. 198.) 
 Domingos, Pedro , "Our Digital Doubles:  AI will serve our species, not control it",  Scientific American , vol. 319, no. 3 (September 2018), pp. 88–93. 
 Gopnik, Alison , "Making AI More Human:   Artificial   intelligence  has staged a revival by starting to incorporate what we know about how children learn",  Scientific American , vol. 316, no. 6 (June 2017), pp. 60–65. 
 Johnston, John (2008)  The Allure of Machinic Life: Cybernetics,  Artificial  Life, and the New AI , MIT Press. 
 Koch, Christof , "Proust among the Machines",  Scientific American , vol. 321, no. 6 (December 2019), pp. 46–49.  Christof Koch  doubts the possibility of "intelligent" machines attaining  consciousness , because "[e]ven the most sophisticated  brain simulations  are unlikely to produce conscious  feelings ." (p. 48.) According to Koch, "Whether machines can become  sentient  [is important] for  ethical  reasons. If computers experience life through their own senses, they cease to be purely a means to an end determined by their usefulness to... humans. Per GNW [the  Global Neuronal Workspace  theory], they turn from mere objects into subjects... with a  point of view .... Once computers'  cognitive abilities  rival those of humanity, their impulse to push for legal and political  rights  will become irresistible – the right not to be deleted, not to have their memories wiped clean, not to suffer  pain  and degradation. The alternative, embodied by IIT [Integrated Information Theory], is that computers will remain only supersophisticated machinery, ghostlike empty shells, devoid of what we value most: the feeling of life itself." (p. 49.) 
 Marcus, Gary , "Am I Human?: Researchers need new ways to distinguish  artificial   intelligence  from the natural kind",  Scientific American , vol. 316, no. 3 (March 2017), pp. 58–63.  A stumbling block to AI has been an incapacity for reliable  disambiguation .  An example is the "pronoun disambiguation problem":  a machine has no way of determining to whom or what a  pronoun  in a sentence refers. (p. 61.) 
 E McGaughey, 'Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy' (2018)  SSRN, part 2(3) . 
 George Musser , " Artificial  Imagination :  How machines could learn  creativity  and  common sense , among other human qualities",  Scientific American , vol. 320, no. 5 (May 2019), pp. 58–63. 
 Myers, Courtney Boyd ed. (2009).  "The AI Report" .  Forbes  June 2009 
 Raphael, Bertram  (1976).  The Thinking Computer . W.H.Freeman and Company.  ISBN   978-0-7167-0723-3 . 
 Scharre, Paul, "Killer Apps:  The Real Dangers of an AI Arms Race",  Foreign Affairs , vol. 98, no. 3 (May/June 2019), pp. 135–44.  "Today's AI technologies are powerful but unreliable.  Rules-based systems cannot deal with circumstances their programmers did not anticipate.  Learning systems are limited by the data on which they were trained.  AI failures have already led to tragedy.  Advanced autopilot features in cars, although they perform well in some circumstances, have driven cars without warning into trucks, concrete barriers, and parked cars.  In the wrong situation, AI systems go from supersmart to superdumb in an instant.  When an enemy is trying to manipulate and hack an AI system, the risks are even greater."  (p. 140.) 
 Serenko, Alexander (2010).  "The development of an AI journal ranking based on the revealed preference approach"   (PDF) .  Journal of Informetrics .  4  (4): 447–459.  doi : 10.1016/j.joi.2010.04.001 . 
 Serenko, Alexander; Michael Dohan (2011).  "Comparing the expert survey and citation impact journal ranking methods: Example from the field of  Artificial   Intelligence "   (PDF) .  Journal of Informetrics .  5  (4): 629–649.  doi : 10.1016/j.joi.2011.06.002 . 
 Sun, R. & Bookman, L. (eds.),  Computational Architectures: Integrating Neural and Symbolic Processes . Kluwer Academic Publishers, Needham, MA. 1994. 
 Tom Simonite (29 December 2014).  "2014 in Computing: Breakthroughs in  Artificial   Intelligence " .  MIT Technology Review . 
 Tooze, Adam , "Democracy and Its Discontents",  The New York Review of Books , vol. LXVI, no. 10 (6 June 2019), pp. 52–53, 56–57.  "Democracy has no clear answer for the mindless operation of  bureaucratic  and  technological power .  We may indeed be witnessing its extension in the form of  artificial   intelligence  and  robotics .  Likewise, after decades of dire warning, the  environmental problem  remains fundamentally unaddressed.... Bureaucratic overreach and environmental catastrophe are precisely the kinds of slow-moving existential challenges that democracies deal with very badly.... Finally, there is the threat du jour:   corporations  and the technologies they promote."  (pp. 56–57.) 
 
 External links 
 Artificial   intelligence at Wikipedia's  sister projects Definitions  from Wiktionary 
 Media  from Wikimedia Commons 
 Quotations  from Wikiquote 
 Textbooks  from Wikibooks 
 Resources  from Wikiversity 
 Data  from Wikidata 
 
 
 " Artificial   Intelligence " .  Internet Encyclopedia of Philosophy . 
 Thomason, Richmond.  "Logic and  Artificial   Intelligence " .  In  Zalta, Edward N.  (ed.).  Stanford Encyclopedia of Philosophy . 
 Artificial   Intelligence , BBC Radio 4 discussion with John Agar, Alison Adam & Igor Aleksander ( In Our Time , Dec. 8, 2005) 
 Articles related to  Artificial   intelligence 
 v t e John McCarthy 
 Artificial   intelligence 
 Circumscription 
 Dartmouth workshop 
 Frame problem 
 Garbage collection 
 Lisp 
 McCarthy Formalism 
 McCarthy 91 function 
 Situation calculus 
 Space fountain 
 
 v t e Philosophy of mind Theories 
 Behaviorism  ( Radical ) 
 Biological naturalism 
 Cognitive psychology 
 Computationalism 
 Mind–body dualism 
 Eliminative materialism 
 Emergent materialism 
 Emergentism 
 Epiphenomenalism 
 Functionalism 
 Idealism 
 Interactionism 
 Materialism 
 Monism 
 Naïve realism 
 Neurophenomenology 
 Neutral monism 
 Occasionalism 
 Panpsychism 
 Psychoanalysis 
 Parallelism 
 Phenomenalism 
 Phenomenology 
 Physicalism 
 identity theory 
 Property dualism 
 Representational 
 Solipsism 
 Substance dualism 
 Concepts 
 Abstract object 
 Artificial   intelligence 
 Chinese room 
 Cognition 
 Cognitive closure 
 Concept 
 Concept and object 
 Consciousness 
 Hard problem of consciousness 
 Hypostatic abstraction 
 Idea 
 Identity 
 Ingenuity 
 Intelligence 
 Intentionality 
 Introspection 
 Intuition 
 Language of thought 
 Materialism 
 Mental event 
 Mental image 
 Mental property 
 Mental representation 
 Mind 
 Mind–body problem 
 Non-physical entity 
 New mysterianism 
 Pain 
 Privileged access 
 Problem of other minds 
 Propositional attitude 
 Qualia 
 Tabula rasa 
 Understanding 
 Zombie 
 more... 
 Related topics 
 Metaphysics 
 Philosophy of  artificial   intelligence  /  information  /  perception  /  self 
 
 Category 
 Philosophers category 
 Project 
 Task Force 
   Philosophy portal 
 
 v t e Philosophy of science Concepts 
 Analysis 
 Analytic–synthetic distinction 
 A priori  and  a posteriori 
 Causality 
 Commensurability 
 Consilience 
 Construct 
 Creative synthesis 
 Demarcation problem 
 Empirical evidence 
 Explanatory power 
 Fact 
 Falsifiability 
 Feminist method 
 Functional contextualism 
 Ignoramus et ignorabimus 
 Inductive reasoning 
 Intertheoretic reduction 
 Inquiry 
 Nature 
 Objectivity 
 Observation 
 Paradigm 
 Problem of induction 
 Scientific law 
 Scientific method 
 Scientific revolution 
 Scientific theory 
 Testability 
 Theory choice 
 Theory-ladenness 
 Underdetermination 
 Unity of science 
 Metatheory of science 
 Coherentism 
 Confirmation holism 
 Constructive empiricism 
 Constructive realism 
 Constructivist epistemology 
 Contextualism 
 Conventionalism 
 Deductive-nomological model 
 Hypothetico-deductive model 
 Inductionism 
 Epistemological anarchism 
 Evolutionism 
 Fallibilism 
 Foundationalism 
 Instrumentalism 
 Pragmatism 
 Model-dependent realism 
 Naturalism 
 Physicalism 
 Positivism  /  Reductionism  /  Determinism 
 Rationalism  /  Empiricism 
 Received view  /  Semantic view of theories 
 Scientific realism  /  Anti-realism 
 Scientific essentialism 
 Scientific formalism 
 Scientific skepticism 
 Scientism 
 Structuralism 
 Uniformitarianism 
 Vitalism 
 Philosophy of 
 Physics 
 thermal and statistical 
 Motion 
 Chemistry 
 Biology 
 Geography 
 Social science 
 Technology 
 Engineering 
 Artificial   intelligence 
 Computer science 
 Information 
 Mind 
 Psychiatry 
 Psychology 
 Perception 
 Space and time 
 Related topics 
 Alchemy 
 Criticism of science 
 Descriptive science 
 Epistemology 
 Faith and rationality 
 Hard and soft science 
 History and philosophy of science 
 History of science 
 History of evolutionary thought 
 Logic 
 Metaphysics 
 Normative science 
 Pseudoscience 
 Relationship between religion and science 
 Rhetoric of science 
 Science studies 
 Sociology of scientific knowledge 
 Sociology of scientific ignorance 
 Philosophers of science  by era Ancient 
 Plato 
 Aristotle 
 Stoicism 
 Epicureans 
 Medieval 
 Averroes 
 Avicenna 
 Roger Bacon 
 William of Ockham 
 Hugh of Saint Victor 
 Dominicus Gundissalinus 
 Robert Kilwardby 
 Early modern 
 Francis Bacon 
 Thomas Hobbes 
 René Descartes 
 Galileo Galilei 
 Pierre Gassendi 
 Isaac Newton 
 David Hume 
 Late modern 
 Immanuel Kant 
 Friedrich Schelling 
 William Whewell 
 Auguste Comte 
 John Stuart Mill 
 Herbert Spencer 
 Wilhelm Wundt 
 Charles Sanders Peirce 
 Wilhelm Windelband 
 Henri Poincaré 
 Pierre Duhem 
 Rudolf Steiner 
 Karl Pearson 
 Contemporary 
 Alfred North Whitehead 
 Bertrand Russell 
 Albert Einstein 
 Otto Neurath 
 C. D. Broad 
 Michael Polanyi 
 Hans Reichenbach 
 Rudolf Carnap 
 Karl Popper 
 Carl Gustav Hempel 
 W. V. O. Quine 
 Thomas Kuhn 
 Imre Lakatos 
 Paul Feyerabend 
 Jürgen Habermas 
 Ian Hacking 
 Bas van Fraassen 
 Larry Laudan 
 Daniel Dennett 
 
 Category 
   Philosophy portal 
   Science portal 
 
 v t e Evolutionary computation Main Topics 
 Convergence (evolutionary computing) 
 Evolutionary algorithm 
 Evolutionary data mining 
 Evolutionary multimodal optimization 
 Human-based evolutionary computation 
 Interactive evolutionary computation 
 Algorithms 
 Cellular evolutionary algorithm 
 Covariance Matrix Adaptation Evolution Strategy (CMA-ES) 
 Differential evolution 
 Evolutionary programming 
 Genetic algorithm 
 Genetic programming 
 Gene expression programming 
 Evolution strategy 
 Natural evolution strategy 
 Neuroevolution 
 Learning classifier system 
 Related techniques 
 Swarm  intelligence 
 Ant colony optimization 
 Bees algorithm 
 Cuckoo search 
 Particle swarm optimization 
 Bacterial Colony Optimization 
 Metaheuristic methods 
 Grey Wolf Optimizer 
 Firefly algorithm 
 Harmony search 
 Gaussian adaptation 
 Memetic algorithm 
 Related topics 
 Artificial  development 
 Artificial   intelligence 
 Artificial  life 
 Digital organism 
 Evolutionary robotics 
 Fitness function 
 Fitness landscape 
 Fitness approximation 
 Genetic operators 
 Interactive evolutionary computation 
 No free lunch in search and optimization 
 Machine learning 
 Mating pool 
 Program synthesis 
 Journals 
 Evolutionary Computation (journal) 
 
 v t e Differentiable computing General 
 Differentiable programming 
 Neural Turing machine 
 Differentiable neural computer 
 Automatic differentiation 
 Neuromorphic engineering 
 Concepts 
 Gradient descent 
 Cable theory 
 Cluster analysis 
 Regression analysis 
 Pattern recognition 
 Adversarial machine learning 
 Computational learning theory 
 Programming languages 
 Python 
 Julia 
 Application 
 Machine learning 
 Artificial  neural network 
 Scientific computing 
 Artificial   Intelligence 
 Hardware 
 TPU 
 VPU 
 Memristor 
 SpiNNaker 
 Software library 
 TensorFlow 
 PyTorch 
 Implementation Audio-visual 
 AlexNet 
 WaveNet 
 Human image synthesis 
 HWR 
 OCR 
 Speech synthesis 
 Speech recognition 
 Facial recognition system 
 Verbal 
 Word2vec 
 Transformer 
 BERT 
 NMT 
 Project Debater 
 Watson 
 Decisional 
 AlphaGo 
 Q-learning 
 SARSA 
 OpenAI Five 
 People 
 Alex Graves 
 Ian Goodfellow 
 Yoshua Bengio 
 Geoffrey Hinton 
 Yann LeCun 
 Andrew Ng 
 Demis Hassabis 
 
  Portals
 Computer programming 
 Technology 
  Category
 Artificial  neural networks 
 Machine learning 
 
 v t e Computable knowledge Topics and concepts 
 Alphabet of human thought 
 Authority control 
 Automated reasoning 
 Commonsense knowledge 
 Commonsense reasoning 
 Computability 
 Discovery system 
 Formal system 
 Inference engine 
 Knowledge base 
 Knowledge-based systems 
 Knowledge engineering 
 Knowledge extraction 
 Knowledge graph 
 Knowledge representation 
 Knowledge retrieval 
 Library classification 
 Logic programming 
 Ontology 
 Personal knowledge base 
 Question answering 
 Semantic reasoner 
 Proposals and implementations 
 Zairja 
 Ars Magna   (1300) 
 An Essay towards a Real Character, and a Philosophical Language   (1688) 
 Calculus ratiocinator  and  characteristica universalis   (1700) 
 Dewey Decimal Classification   (1876) 
 Begriffsschrift   (1879) 
 Mundaneum   (1910) 
 Logical atomism   (1918) 
 Tractatus Logico-Philosophicus   (1921) 
 Hilbert's program   (1920s) 
 Incompleteness theorem   (1931) 
 World Brain   (1938) 
 Memex   (1945) 
 General Problem Solver   (1959) 
 Prolog   (1972) 
 Cyc   (1984) 
 Semantic Web   (2001) 
 Evi   (2007) 
 Wolfram Alpha   (2009) 
 Watson   (2011) 
 Siri   (2011) 
 Google Knowledge Graph   (2012) 
 Wikidata   (2012) 
 Cortana   (2014) 
 Viv   (2016) 
 In fiction 
 The Engine  ( Gulliver's Travels , 1726) 
 Joe (" A Logic Named Joe ", 1946) 
 The Librarian ( Snow Crash , 1992) 
 Dr. Know ( A.I. (film) , 2001) 
 Waterhouse ( The Baroque Cycle , 2003) 
 See also:  Logic machines in fiction  and  List of fictional computers 
 
 
 v t e Computer science Note: This template roughly follows the 2012  ACM Computing Classification System . Hardware 
 Printed circuit board 
 Peripheral 
 Integrated circuit 
 Very Large Scale Integration 
 Systems on Chip (SoCs) 
 Energy consumption (Green computing) 
 Electronic design automation 
 Hardware acceleration 
 Computer systems organization 
 Computer architecture 
 Embedded system 
 Real-time computing 
 Dependability 
 Networks 
 Network architecture 
 Network protocol 
 Network components 
 Network scheduler 
 Network performance evaluation 
 Network service 
 Software organization 
 Interpreter 
 Middleware 
 Virtual machine 
 Operating system 
 Software quality 
 Software notations and  tools 
 Programming paradigm 
 Programming language 
 Compiler 
 Domain-specific language 
 Modeling language 
 Software framework 
 Integrated development environment 
 Software configuration management 
 Software library 
 Software repository 
 Software development 
 Software development process 
 Requirements analysis 
 Software design 
 Software construction 
 Software deployment 
 Software maintenance 
 Programming team 
 Open-source model 
 Theory of computation 
 Model of computation 
 Formal language 
 Automata theory 
 Computability theory 
 Computational complexity theory 
 Logic 
 Semantics 
 Algorithms 
 Algorithm design 
 Analysis of algorithms 
 Algorithmic efficiency 
 Randomized algorithm 
 Computational geometry 
 Mathematics of computing 
 Discrete mathematics 
 Probability 
 Statistics 
 Mathematical software 
 Information theory 
 Mathematical analysis 
 Numerical analysis 
 Information systems 
 Database management system 
 Information storage systems 
 Enterprise information system 
 Social information systems 
 Geographic information system 
 Decision support system 
 Process control system 
 Multimedia information system 
 Data mining 
 Digital library 
 Computing platform 
 Digital marketing 
 World Wide Web 
 Information retrieval 
 Security 
 Cryptography 
 Formal methods 
 Security services 
 Intrusion detection system 
 Hardware security 
 Network security 
 Information security 
 Application security 
 Human–computer interaction 
 Interaction design 
 Social computing 
 Ubiquitous computing 
 Visualization 
 Accessibility 
 Concurrency 
 Concurrent computing 
 Parallel computing 
 Distributed computing 
 Multithreading 
 Multiprocessing 
 Artificial intelligence 
 Natural language processing 
 Knowledge representation and reasoning 
 Computer vision 
 Automated planning and scheduling 
 Search methodology 
 Control method 
 Philosophy of  artificial   intelligence 
 Distributed  artificial   intelligence 
 Machine learning 
 Supervised learning 
 Unsupervised learning 
 Reinforcement learning 
 Multi-task learning 
 Cross-validation 
 Graphics 
 Animation 
 Rendering 
 Image manipulation 
 Graphics processing unit 
 Mixed reality 
 Virtual reality 
 Image compression 
 Solid modeling 
 Applied computing 
 E-commerce 
 Enterprise software 
 Computational mathematics 
 Computational physics 
 Computational chemistry 
 Computational biology 
 Computational social science 
 Computational engineering 
 Computational healthcare 
 Digital art 
 Electronic publishing 
 Cyberwarfare 
 Electronic voting 
 Video games 
 Word processing 
 Operations research 
 Educational technology 
 Document management 
 
   Book 
   Category 
   Outline 
 WikiProject 
   Commons 
 
 v t e Emerging technologies Fields Information and communications 
 Ambient  intelligence 
 Internet of things 
 Artificial   intelligence 
 Applications of  artificial   intelligence 
 Progress in  artificial   intelligence 
 Machine translation 
 Mobile translation 
 Machine vision 
 Semantic Web 
 Speech recognition 
 Atomtronics 
 Carbon nanotube field-effect transistor 
 Cybermethodology 
 Fourth-generation optical discs 
 3D optical data storage 
 Holographic data storage 
 GPGPU 
 Memory
 CBRAM 
 FRAM 
 Millipede 
 MRAM 
 NRAM 
 PRAM 
 Racetrack memory 
 RRAM 
 SONOS 
 ECRAM 
 Optical computing 
 RFID 
 Chipless RFID 
 Software-defined radio 
 Three-dimensional integrated circuit 
 Topics 
 Collingridge dilemma 
 Differential technological development 
 Disruptive innovation 
 Ephemeralization 
 Ethics 
 Bioethics 
 Cyberethics 
 Neuroethics 
 Robot ethics 
 Exploratory engineering 
 Fictional technology 
 Proactionary principle 
 Technological change 
 Technological unemployment 
 Technological convergence 
 Technological evolution 
 Technological paradigm 
 Technology forecasting 
 Accelerating change 
 Moore's law 
 Technological singularity 
 Technology scouting 
 Technology readiness level 
 Technology roadmap 
 Transhumanism 
 
   Category 
   List 
 
 v t e Robotics Main articles 
 Outline 
 Glossary 
 Index 
 History 
 Geography 
 Hall of Fame 
 Ethics 
 Laws 
 Competitions 
 AI competitions 
 Types 
 Anthropomorphic
 Humanoid 
 Android 
 Cyborg 
 Claytronics 
 Companion 
 Animatronic 
 Audio-Animatronics 
 Industrial 
 Articulated 
 arm 
 Domestic 
 Educational 
 Entertainment 
 Juggling 
 Military 
 Medical 
 Service 
 Disability 
 Agricultural 
 Food service 
 Retail 
 BEAM robotics 
 Soft robotics 
 Classifications 
 Biorobotics 
 Unmanned vehicle 
 aerial 
 ground 
 Mobile robot 
 Microbotics 
 Nanorobotics 
 Robotic spacecraft 
 Space probe 
 Swarm 
 Underwater 
 remotely-operated 
 Locomotion 
 Tracks 
 Walking 
 Hexapod 
 Climbing 
 Electric unicycle 
 Robot navigation 
 Research 
 Evolutionary 
 Kits 
 Simulator 
 Suite 
 Open-source 
 Software 
 Adaptable 
 Developmental 
 Paradigms 
 Ubiquitous 
 Related 
 Technological unemployment 
 Terrainability 
 Fictional robots 
 
   Category 
   Outline 
 
 v t e Existential risk  from  artificial   intelligence Concepts 
 Accelerating change 
 AI box 
 AI takeover 
 Control problem 
 Existential risk from  artificial  general  intelligence 
 Friendly  artificial   intelligence 
 Instrumental convergence 
 Intelligence  explosion 
 Machine ethics 
 Superintelligence 
 Technological singularity 
 Organizations 
 Allen Institute for AI 
 Center for Applied Rationality 
 Center for Human-Compatible  Artificial   Intelligence 
 Center for Security and Emerging Technology 
 Centre for the Study of Existential Risk 
 DeepMind 
 Foundational Questions Institute 
 Future of Humanity Institute 
 Future of Life Institute 
 Humanity+ 
 Institute for Ethics and Emerging Technologies 
 Leverhulme Centre for the Future of  Intelligence 
 Machine  Intelligence  Research Institute 
 OpenAI 
 People 
 Nick Bostrom 
 Eric Drexler 
 Sam Harris 
 Stephen Hawking 
 Bill Hibbard 
 Bill Joy 
 Elon Musk 
 Steve Omohundro 
 Huw Price 
 Martin Rees 
 Stuart J. Russell 
 Jaan Tallinn 
 Max Tegmark 
 Frank Wilczek 
 Roman Yampolskiy 
 Andrew Yang 
 Eliezer Yudkowsky 
 Other 
 Artificial   intelligence  as a global catastrophic risk 
 Controversies and dangers of  artificial  general  intelligence 
 Ethics of  artificial   intelligence 
 Human Compatible 
 Open Letter on  Artificial   Intelligence 
 Our Final Invention 
 The Precipice 
 Superintelligence: Paths, Dangers, Strategies 
   Category 
 v t e Subfields of and cyberneticians involved in  cybernetics Subfields 
 Artificial   intelligence 
 Biological cybernetics 
 Biomedical cybernetics 
 Biorobotics 
 Biosemiotics 
 Neurocybernetics 
 Catastrophe theory 
 Computational neuroscience 
 Connectionism 
 Control theory 
 Cybernetics in the Soviet Union 
 Decision theory 
 Emergence 
 Engineering cybernetics 
 Homeostasis 
 Information theory 
 Management cybernetics 
 Medical cybernetics 
 Second-order cybernetics 
 Semiotics 
 Sociocybernetics 
 Polycontexturality 
 Synergetics 
 Cyberneticians 
 Alexander Lerner 
 Alexey Lyapunov 
 Alfred Radcliffe-Brown 
 Allenna Leonard 
 Anthony Wilden 
 Buckminster Fuller 
 Charles François 
 Claude Bernard 
 Cliff Joslyn 
 Erich von Holst 
 Ernst von Glasersfeld 
 Francis Heylighen 
 Francisco Varela 
 Frederic Vester 
 Charles Geoffrey Vickers 
 Gordon Pask 
 Gordon S. Brown 
 Gregory Bateson 
 Heinz von Foerster 
 Humberto Maturana 
 I. A. Richards 
 Igor Aleksander 
 Jacque Fresco 
 Jakob von Uexküll 
 Jason Jixuan Hu 
 Jay Wright Forrester 
 Jennifer Wilby 
 John N. Warfield 
 Kevin Warwick 
 Ludwig von Bertalanffy 
 Maleyka Abbaszadeh 
 Manfred Clynes 
 Margaret Mead 
 Marian Mazur 
 N. Katherine Hayles 
 Natalia Bekhtereva 
 Niklas Luhmann 
 Norbert Wiener 
 Pyotr Grigorenko 
 Qian Xuesen 
 Ranulph Glanville 
 Robert Trappl 
 Sergei P. Kurdyumov 
 Anthony Stafford Beer 
 Stuart Kauffman 
 Stuart Umpleby 
 Talcott Parsons 
 Ulla Mitzdorf 
 Valentin Turchin 
 Valentin Braitenberg 
 William Ross Ashby 
 Walter Bradford Cannon 
 Walter Pitts 
 Warren McCulloch 
 William Grey Walter 
 
 v t e Glossaries of science and engineering 
 Aerospace engineering 
 Agriculture 
 Archaeology 
 Architecture 
 Artificial   intelligence 
 Astronomy 
 Biology 
 Botany 
 Calculus 
 Chemistry 
 Civil engineering 
 Clinical research 
 Computer hardware 
 Computer science 
 Ecology 
 Economics 
 Electrical and electronics engineering 
 Engineering 
 Entomology 
 Environmental science 
 Evolutionary biology 
 Genetics 
 Geography 
 Geology 
 Ichthyology 
 Machine vision 
 Mathematics 
 Mechanical engineering 
 Medicine 
 Meteorology 
 Nanotechnology 
 Ornithology 
 Physics 
 Probability and statistics 
 Psychiatry 
 Robotics 
 Scientific naming 
 Structural engineering 
 Virology 
 
 Authority control   
 BNF :  cb11932084t   (data) 
 GND :  4033447-8 
 LCCN :  sh85008180 
 NDL :  00574798 
 
  
NewPP limit report
Parsed by mw1375
Cached time: 20200730145007
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 4.652 seconds
Real time usage: 5.358 seconds
Preprocessor visited node count: 27053/1000000
Post‐expand include size: 1137355/2097152 bytes
Template argument size: 142408/2097152 bytes
Highest expansion depth: 17/40
Expensive parser function count: 23/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 1295317/5000000 bytes
Lua time usage: 2.571/10.000 seconds
Lua memory usage: 11.3 MB/50 MB
Lua Profile:
    ?                                                                340 ms       12.4%
    dataWrapper <mw.lua:661>                                         300 ms       10.9%
    recursiveClone <mwInit.lua:41>                                   300 ms       10.9%
    Scribunto_LuaSandboxCallback::callParserFunction                 220 ms        8.0%
    Scribunto_LuaSandboxCallback::match                              180 ms        6.6%
    Scribunto_LuaSandboxCallback::gsub                               140 ms        5.1%
    Scribunto_LuaSandboxCallback::getExpandedArgument                120 ms        4.4%
    Scribunto_LuaSandboxCallback::plain                              120 ms        4.4%
    Scribunto_LuaSandboxCallback::anchorEncode                       100 ms        3.6%
    type                                                              80 ms        2.9%
    [others]                                                         840 ms       30.7%
Number of Wikibase entities loaded: 1/400
 
 
Transclusion expansion time report (%,ms,calls,template)
100.00% 4465.453      1 -total
 52.03% 2323.434      2 Template:Reflist
 11.17%  499.003     82 Template:Cite_web
  9.90%  441.958     78 Template:Cite_journal
  9.19%  410.457    329 Template:Harvnb
  8.88%  396.501     71 Template:Cite_book
  5.61%  250.357     44 Template:Sfn
  5.55%  248.044     53 Template:Cite_news
  5.51%  246.097      1 Template:Navboxes
  5.21%  232.437      1 Template:Cite_arxiv
 
  Saved in parser cache with key enwiki:pcache:idhash:1164-0!canonical and timestamp 20200730145021 and revision id 970306997
  
 Retrieved from " https://en.wikipedia.org/w/index.php?title= Artificial _ intelligence &oldid=970306997 " 
 Categories :  Artificial   intelligence Cybernetics Formal sciences Technology in society Computational neuroscience Emerging technologies Unsolved problems in computer science Computational fields of study Hidden categories:  Wikipedia articles needing page number citations from December 2016 Harv and Sfn no-target errors Harv and Sfn multiple-target errors CS1 Chinese-language sources (zh) Wikipedia articles needing page number citations from February 2011 Webarchive template wayback links All articles with dead external links Articles with dead external links from October 2019 Articles with permanently dead external links CS1 errors: dates Articles with dead external links from July 2020 Articles with short description Wikipedia indefinitely semi-protected pages Use dmy dates from January 2018 All articles with unsourced statements Articles with unsourced statements from June 2019 Articles with unsourced statements from July 2019 Wikipedia articles needing clarification from July 2019 Articles containing potentially dated statements from 2016 All articles containing potentially dated statements Articles needing additional references from January 2020 All articles needing additional references Articles with unsourced statements from December 2019 Articles with unsourced statements from June 2020 CS1 maint: ref=harv CS1: Julian–Gregorian uncertainty CS1 errors: missing periodical CS1: long volume value Articles with Internet Encyclopedia of Philosophy links Wikipedia articles with BNF identifiers Wikipedia articles with GND identifiers Wikipedia articles with LCCN identifiers Wikipedia articles with NDL identifiers 
 
 
 
 
 
 
 Navigation menu 
 
  Please do not use role attribute as CSS selector, it is deprecated.  
 
 
 Personal tools 
 
  Please do not use the .body class, it is deprecated.  
 
  Please do not use the .menu class, it is deprecated.  
 Not logged in Talk Contributions Create account Log in 
 
 
 
  Please do not use role attribute as CSS selector, it is deprecated.  
 
 
 Namespaces 
 
  Please do not use the .body class, it is deprecated.  
 
  Please do not use the .menu class, it is deprecated.  
 Article Talk 
 
 
  Please do not use role attribute as CSS selector, it is deprecated.  
 
 
 
 Variants 
 
  Please do not use the .body class, it is deprecated.  
 
  Please do not use the .menu class, it is deprecated.  
 
 
 
 
 
  Please do not use role attribute as CSS selector, it is deprecated.  
 
 
 Views 
 
  Please do not use the .body class, it is deprecated.  
 
  Please do not use the .menu class, it is deprecated.  
 Read View source View history 
 
 
  Please do not use role attribute as CSS selector, it is deprecated.  
 
 
 
 More 
 
  Please do not use the .body class, it is deprecated.  
 
  Please do not use the .menu class, it is deprecated.  
 
 
 
 
 
 Search 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  Please do not use role attribute as CSS selector, it is deprecated.  
 
 
 Navigation 
 
  Please do not use the .body class, it is deprecated.  
 
  Please do not use the .menu class, it is deprecated.  
 Main page Contents Current events Random article About Wikipedia Contact us Donate Wikipedia store 
 
 
  Please do not use role attribute as CSS selector, it is deprecated.  
 
 
 Contribute 
 
  Please do not use the .body class, it is deprecated.  
 
  Please do not use the .menu class, it is deprecated.  
 Help Community portal Recent changes Upload file 
 
 
  Please do not use role attribute as CSS selector, it is deprecated.  
 
 
 Tools 
 
  Please do not use the .body class, it is deprecated.  
 
  Please do not use the .menu class, it is deprecated.  
 What links here Related changes Upload file Special pages Permanent link Page information Cite this page Wikidata item 
 
 
  Please do not use role attribute as CSS selector, it is deprecated.  
 
 
 Print/export 
 
  Please do not use the .body class, it is deprecated.  
 
  Please do not use the .menu class, it is deprecated.  
 Download as PDF Printable version 
 
 
  Please do not use role attribute as CSS selector, it is deprecated.  
 
 
 In other projects 
 
  Please do not use the .body class, it is deprecated.  
 
  Please do not use the .menu class, it is deprecated.  
 Wikimedia Commons Wikibooks Wikiquote Wikiversity 
 
 
  Please do not use role attribute as CSS selector, it is deprecated.  
 
 
 Languages 
 
  Please do not use the .body class, it is deprecated.  
 
  Please do not use the .menu class, it is deprecated.  
 Afrikaans Alemannisch አማርኛ العربية Aragonés অসমীয়া Asturianu Avañe'ẽ Azərbaycanca বাংলা Bân-lâm-gú Башҡортса Беларуская Беларуская (тарашкевіца)‎ Български Bosanski Буряад Català Чӑвашла Čeština Cymraeg Dansk Deutsch Eesti Ελληνικά Español Esperanto Euskara فارسی Français Furlan Gaeilge Galego 贛語 한국어 Հայերեն हिन्दी Hrvatski Ido Ilokano Bahasa Indonesia Interlingua Íslenska Italiano עברית Jawa ಕನ್ನಡ ქართული Қазақша Kiswahili Kreyòl ayisyen Kriyòl gwiyannen Кыргызча Latina Latviešu Lietuvių Limburgs La .lojban. Magyar Македонски Malagasy മലയാളം मराठी مصرى Bahasa Melayu Minangkabau Монгол မြန်မာဘာသာ Nederlands Nedersaksies नेपाली नेपाल भाषा 日本語 Norsk bokmål Norsk nynorsk Occitan ଓଡ଼ିଆ ਪੰਜਾਬੀ پنجابی Patois Polski Português Ripoarisch Română Русиньскый Русский Саха тыла Scots Shqip සිංහල Simple English Slovenčina Slovenščina کوردی Српски / srpski Srpskohrvatski / српскохрватски Suomi Svenska Tagalog தமிழ் Татарча/tatarça తెలుగు ไทย Тоҷикӣ Türkçe Türkmençe Українська اردو ئۇيغۇرچە / Uyghurche Vèneto Tiếng Việt Võro Winaray 吴语 ייִדיש 粵語 Zazaki Žemaitėška 中文 
 Edit links 
 
 
 
 
 
 
  This page was last edited on 30 July 2020, at 14:50  (UTC) . 
 Text is available under the  Creative Commons Attribution-ShareAlike License ;
additional terms may apply.  By using this site, you agree to the  Terms of Use  and  Privacy Policy . Wikipedia® is a registered trademark of the  Wikimedia Foundation, Inc. , a non-profit organization. 
 
 
 Privacy policy 
 About Wikipedia 
 Disclaimers 
 Contact Wikipedia 
 Developers 
 Statistics 
 Cookie statement 
 Mobile view 
 
 
 
 
 
 
 
 
 
 
 